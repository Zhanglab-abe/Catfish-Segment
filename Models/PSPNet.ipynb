{"cells":[{"cell_type":"markdown","metadata":{"id":"uJsACIiL4zWx"},"source":["# Prepare the environment"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":247,"status":"ok","timestamp":1672894210665,"user":{"displayName":"Lab Zhang","userId":"02753311727466830892"},"user_tz":360},"id":"028EGhGAf_n1"},"outputs":[],"source":["# ! tar -xvf /content/drive/MyDrive/catfish/tianqi/code/mmsegmentation/data/ade/ADEChallengeData2016/data.tar"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20408,"status":"ok","timestamp":1672894231597,"user":{"displayName":"Lab Zhang","userId":"02753311727466830892"},"user_tz":360},"id":"NkecJSQpWUvv","outputId":"14f89887-6c2f-4cc3-d2e9-211eb8236411"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting openmim\n","  Downloading openmim-0.3.4-py2.py3-none-any.whl (50 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 KB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: Click in /usr/local/lib/python3.8/dist-packages (from openmim) (7.1.2)\n","Collecting model-index\n","  Downloading model_index-0.1.11-py3-none-any.whl (34 kB)\n","Collecting colorama\n","  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from openmim) (1.3.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from openmim) (2.25.1)\n","Collecting rich\n","  Downloading rich-13.0.0-py3-none-any.whl (238 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m238.1/238.1 KB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.8/dist-packages (from openmim) (0.8.10)\n","Requirement already satisfied: pip>=19.3 in /usr/local/lib/python3.8/dist-packages (from openmim) (22.0.4)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from model-index->openmim) (6.0)\n","Requirement already satisfied: markdown in /usr/local/lib/python3.8/dist-packages (from model-index->openmim) (3.4.1)\n","Collecting ordered-set\n","  Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from pandas->openmim) (1.21.6)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->openmim) (2022.7)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->openmim) (2.8.2)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->openmim) (4.0.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->openmim) (2022.12.7)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->openmim) (2.10)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->openmim) (1.24.3)\n","Requirement already satisfied: typing-extensions<5.0,>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from rich->openmim) (4.4.0)\n","Collecting commonmark<0.10.0,>=0.9.0\n","  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.1/51.1 KB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.8/dist-packages (from rich->openmim) (2.6.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->openmim) (1.15.0)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown->model-index->openmim) (5.2.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown->model-index->openmim) (3.11.0)\n","Installing collected packages: commonmark, rich, ordered-set, colorama, model-index, openmim\n","Successfully installed colorama-0.4.6 commonmark-0.9.1 model-index-0.1.11 openmim-0.3.4 ordered-set-4.1.0 rich-13.0.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Looking in links: https://download.openmmlab.com/mmcv/dist/cu116/torch1.13.0/index.html\n","Collecting mmcv-full\n","  Downloading https://download.openmmlab.com/mmcv/dist/cu116/torch1.13.0/mmcv_full-1.7.1-cp38-cp38-manylinux1_x86_64.whl (46.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.1/46.1 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting yapf\n","  Downloading yapf-0.32.0-py2.py3-none-any.whl (190 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.2/190.2 KB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from mmcv-full) (7.1.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from mmcv-full) (1.21.6)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from mmcv-full) (21.3)\n","Collecting addict\n","  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from mmcv-full) (6.0)\n","Requirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.8/dist-packages (from mmcv-full) (4.6.0.66)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->mmcv-full) (3.0.9)\n","Installing collected packages: yapf, addict, mmcv-full\n","Successfully installed addict-2.4.0 mmcv-full-1.7.1 yapf-0.32.0\n"]}],"source":["!pip3 install openmim\n","!mim install mmcv-full"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":257,"status":"ok","timestamp":1672894231848,"user":{"displayName":"Lab Zhang","userId":"02753311727466830892"},"user_tz":360},"id":"IGIg8TkFZJDW","outputId":"1a1f808b-0ffb-4cc5-b512-18dc8c2c52ba"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/catfish/tianqi/code\n"]}],"source":["%cd /content/drive/MyDrive/catfish/tianqi/code"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":46896,"status":"ok","timestamp":1672894278742,"user":{"displayName":"Lab Zhang","userId":"02753311727466830892"},"user_tz":360},"id":"jK3d7Qr2cGc1","outputId":"5a0fbe92-5e63-455b-95d0-0da7818db9f6"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/catfish/tianqi/code/mmsegmentation\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Obtaining file:///content/drive/MyDrive/catfish/tianqi/code/mmsegmentation\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from mmsegmentation==0.29.1) (3.2.2)\n","Collecting mmcls>=0.20.1\n","  Downloading mmcls-0.25.0-py2.py3-none-any.whl (648 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m648.8/648.8 KB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from mmsegmentation==0.29.1) (1.21.6)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from mmsegmentation==0.29.1) (21.3)\n","Requirement already satisfied: prettytable in /usr/local/lib/python3.8/dist-packages (from mmsegmentation==0.29.1) (3.5.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->mmsegmentation==0.29.1) (0.11.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->mmsegmentation==0.29.1) (1.4.4)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->mmsegmentation==0.29.1) (2.8.2)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->mmsegmentation==0.29.1) (3.0.9)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prettytable->mmsegmentation==0.29.1) (0.2.5)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib->mmsegmentation==0.29.1) (1.15.0)\n","Installing collected packages: mmcls, mmsegmentation\n","  Running setup.py develop for mmsegmentation\n","Successfully installed mmcls-0.25.0 mmsegmentation-0.29.1\n"]}],"source":["# !git clone https://github.com/open-mmlab/mmsegmentation.git\n","%cd mmsegmentation\n","!pip install -e ."]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4947,"status":"ok","timestamp":1672894283674,"user":{"displayName":"Lab Zhang","userId":"02753311727466830892"},"user_tz":360},"id":"bCnOW5NmcIN6","outputId":"d6a55225-df35-4b06-f5f7-057f4b4920e0"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["0.29.1\n"]}],"source":["import mmseg\n","print(mmseg.__version__)\n","# 预期输出：0.24.1 或其他版本号"]},{"cell_type":"markdown","metadata":{"id":"oMqr6Em-4wzS"},"source":["# train\n"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"w8ObbSRTeBcZ","executionInfo":{"status":"ok","timestamp":1672894283674,"user_tz":360,"elapsed":3,"user":{"displayName":"Lab Zhang","userId":"02753311727466830892"}}},"outputs":[],"source":["# !bash tools/dist_train.sh \\\n","#     /content/drive/MyDrive/catfish/tianqi/code/mmsegmentation/configs/pspnet/pspnet_r101-d8_512x512_80k_ade20k.py  1 \\\n","#     --work-dir /content/drive/MyDrive/catfish/tianqi/code/mmsegmentation/checkpoints_pspnet --seed 0  --deterministic \\\n","#     --options model.pretrained=https://download.openmmlab.com/mmsegmentation/v0.5/pspnet/pspnet_r101-d8_512x512_80k_ade20k/pspnet_r101-d8_512x512_80k_ade20k_20200614_031423-b6e782f0.pth"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"TuZ2DlTARzfc","executionInfo":{"status":"ok","timestamp":1672894283674,"user_tz":360,"elapsed":3,"user":{"displayName":"Lab Zhang","userId":"02753311727466830892"}}},"outputs":[],"source":["\n","# !bash /content/drive/MyDrive/catfish/tianqi/code/mmsegmentation/tools/dist_train.sh \\\n","#     /content/drive/MyDrive/catfish/tianqi/code/mmsegmentation/configs/pspnet/my_pspnet_r101-d8_512x512_80k_ade20k.py 1 \\\n","#     --work-dir /content/drive/MyDrive/catfish/tianqi/code/mmsegmentation/checkpoints_pspnet --seed 0  --deterministic \\\n","#     --options model.pretrained=https://download.openmmlab.com/mmsegmentation/v0.5/pspnet/pspnet_r101-d8_512x512_80k_ade20k/pspnet_r101-d8_512x512_80k_ade20k_20200614_031423-b6e782f0.pth"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":29329853,"status":"ok","timestamp":1672923613524,"user":{"displayName":"Lab Zhang","userId":"02753311727466830892"},"user_tz":360},"id":"vKofNQsv2S_v","colab":{"base_uri":"https://localhost:8080/"},"outputId":"3d75b313-3fa8-481b-d59c-b89998f0be58"},"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.8/dist-packages/torch/distributed/launch.py:180: FutureWarning: The module torch.distributed.launch is deprecated\n","and will be removed in future. Use torchrun.\n","Note that --use_env is set by default in torchrun.\n","If your script expects `--local_rank` argument to be set, please\n","change it to read from `os.environ['LOCAL_RANK']` instead. See \n","https://pytorch.org/docs/stable/distributed.html#launch-utility for \n","further instructions\n","\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n","  warnings.warn(\n","2023-01-05 04:52:19,850 - mmseg - INFO - Multi-processing start method is `None`\n","2023-01-05 04:52:19,858 - mmseg - INFO - OpenCV num_threads is `2\n","2023-01-05 04:52:21,312 - mmseg - INFO - Environment info:\n","------------------------------------------------------------\n","sys.platform: linux\n","Python: 3.8.16 (default, Dec  7 2022, 01:12:13) [GCC 7.5.0]\n","CUDA available: True\n","GPU 0: Tesla T4\n","CUDA_HOME: /usr/local/cuda\n","NVCC: Cuda compilation tools, release 11.2, V11.2.152\n","GCC: x86_64-linux-gnu-gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n","PyTorch: 1.13.0+cu116\n","PyTorch compiling details: PyTorch built with:\n","  - GCC 9.3\n","  - C++ Version: 201402\n","  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n","  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)\n","  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n","  - LAPACK is enabled (usually provided by MKL)\n","  - NNPACK is enabled\n","  - CPU capability usage: AVX2\n","  - CUDA Runtime 11.6\n","  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n","  - CuDNN 8.3.2  (built against CUDA 11.5)\n","  - Magma 2.6.1\n","  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.6, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n","\n","TorchVision: 0.14.0+cu116\n","OpenCV: 4.6.0\n","MMCV: 1.7.1\n","MMCV Compiler: GCC 9.3\n","MMCV CUDA Compiler: 11.6\n","MMSegmentation: 0.29.1+1bb58de\n","------------------------------------------------------------\n","\n","2023-01-05 04:52:21,313 - mmseg - INFO - Distributed training: True\n","2023-01-05 04:52:21,554 - mmseg - INFO - Config:\n","norm_cfg = dict(type='SyncBN', requires_grad=True)\n","model = dict(\n","    type='EncoderDecoder',\n","    pretrained=\n","    'https://download.openmmlab.com/mmsegmentation/v0.5/pspnet/pspnet_r101-d8_512x512_80k_ade20k/pspnet_r101-d8_512x512_80k_ade20k_20200614_031423-b6e782f0.pth',\n","    backbone=dict(\n","        type='ResNetV1c',\n","        depth=101,\n","        num_stages=4,\n","        out_indices=(0, 1, 2, 3),\n","        dilations=(1, 1, 2, 4),\n","        strides=(1, 2, 1, 1),\n","        norm_cfg=dict(type='SyncBN', requires_grad=True),\n","        norm_eval=False,\n","        style='pytorch',\n","        contract_dilation=True),\n","    decode_head=dict(\n","        type='PSPHead',\n","        in_channels=2048,\n","        in_index=3,\n","        channels=512,\n","        pool_scales=(1, 2, 3, 6),\n","        dropout_ratio=0.1,\n","        num_classes=5,\n","        norm_cfg=dict(type='SyncBN', requires_grad=True),\n","        align_corners=False,\n","        loss_decode=dict(\n","            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0)),\n","    auxiliary_head=dict(\n","        type='FCNHead',\n","        in_channels=1024,\n","        in_index=2,\n","        channels=256,\n","        num_convs=1,\n","        concat_input=False,\n","        dropout_ratio=0.1,\n","        num_classes=5,\n","        norm_cfg=dict(type='SyncBN', requires_grad=True),\n","        align_corners=False,\n","        loss_decode=dict(\n","            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=0.4)),\n","    train_cfg=dict(),\n","    test_cfg=dict(mode='whole'))\n","dataset_type = 'ADE20KDataset'\n","data_root = 'data/ade/ADEChallengeData2016'\n","img_norm_cfg = dict(\n","    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n","crop_size = (512, 512)\n","train_pipeline = [\n","    dict(type='LoadImageFromFile'),\n","    dict(type='LoadAnnotations', reduce_zero_label=True),\n","    dict(type='Resize', img_scale=(2048, 512), ratio_range=(0.5, 2.0)),\n","    dict(type='RandomCrop', crop_size=(512, 512), cat_max_ratio=0.75),\n","    dict(type='RandomFlip', prob=0.5),\n","    dict(type='PhotoMetricDistortion'),\n","    dict(\n","        type='Normalize',\n","        mean=[123.675, 116.28, 103.53],\n","        std=[58.395, 57.12, 57.375],\n","        to_rgb=True),\n","    dict(type='Pad', size=(512, 512), pad_val=0, seg_pad_val=255),\n","    dict(type='DefaultFormatBundle'),\n","    dict(type='Collect', keys=['img', 'gt_semantic_seg'])\n","]\n","test_pipeline = [\n","    dict(type='LoadImageFromFile'),\n","    dict(\n","        type='MultiScaleFlipAug',\n","        img_scale=(2048, 512),\n","        flip=False,\n","        transforms=[\n","            dict(type='Resize', keep_ratio=True),\n","            dict(type='RandomFlip'),\n","            dict(\n","                type='Normalize',\n","                mean=[123.675, 116.28, 103.53],\n","                std=[58.395, 57.12, 57.375],\n","                to_rgb=True),\n","            dict(type='ImageToTensor', keys=['img']),\n","            dict(type='Collect', keys=['img'])\n","        ])\n","]\n","data = dict(\n","    samples_per_gpu=4,\n","    workers_per_gpu=4,\n","    train=dict(\n","        type='ADE20KDataset',\n","        data_root='data/ade/ADEChallengeData2016',\n","        img_dir='images/training',\n","        ann_dir='annotations/training',\n","        pipeline=[\n","            dict(type='LoadImageFromFile'),\n","            dict(type='LoadAnnotations', reduce_zero_label=True),\n","            dict(type='Resize', img_scale=(2048, 512), ratio_range=(0.5, 2.0)),\n","            dict(type='RandomCrop', crop_size=(512, 512), cat_max_ratio=0.75),\n","            dict(type='RandomFlip', prob=0.5),\n","            dict(type='PhotoMetricDistortion'),\n","            dict(\n","                type='Normalize',\n","                mean=[123.675, 116.28, 103.53],\n","                std=[58.395, 57.12, 57.375],\n","                to_rgb=True),\n","            dict(type='Pad', size=(512, 512), pad_val=0, seg_pad_val=255),\n","            dict(type='DefaultFormatBundle'),\n","            dict(type='Collect', keys=['img', 'gt_semantic_seg'])\n","        ]),\n","    val=dict(\n","        type='ADE20KDataset',\n","        data_root='data/ade/ADEChallengeData2016',\n","        img_dir='images/validation',\n","        ann_dir='annotations/validation',\n","        pipeline=[\n","            dict(type='LoadImageFromFile'),\n","            dict(\n","                type='MultiScaleFlipAug',\n","                img_scale=(2048, 512),\n","                flip=False,\n","                transforms=[\n","                    dict(type='Resize', keep_ratio=True),\n","                    dict(type='RandomFlip'),\n","                    dict(\n","                        type='Normalize',\n","                        mean=[123.675, 116.28, 103.53],\n","                        std=[58.395, 57.12, 57.375],\n","                        to_rgb=True),\n","                    dict(type='ImageToTensor', keys=['img']),\n","                    dict(type='Collect', keys=['img'])\n","                ])\n","        ]),\n","    test=dict(\n","        type='ADE20KDataset',\n","        data_root='data/ade/ADEChallengeData2016',\n","        img_dir='images/validation',\n","        ann_dir='annotations/validation',\n","        pipeline=[\n","            dict(type='LoadImageFromFile'),\n","            dict(\n","                type='MultiScaleFlipAug',\n","                img_scale=(2048, 512),\n","                flip=False,\n","                transforms=[\n","                    dict(type='Resize', keep_ratio=True),\n","                    dict(type='RandomFlip'),\n","                    dict(\n","                        type='Normalize',\n","                        mean=[123.675, 116.28, 103.53],\n","                        std=[58.395, 57.12, 57.375],\n","                        to_rgb=True),\n","                    dict(type='ImageToTensor', keys=['img']),\n","                    dict(type='Collect', keys=['img'])\n","                ])\n","        ]))\n","log_config = dict(\n","    interval=50, hooks=[dict(type='TextLoggerHook', by_epoch=False)])\n","dist_params = dict(backend='nccl')\n","log_level = 'INFO'\n","load_from = None\n","resume_from = '/content/drive/MyDrive/catfish/tianqi/code/mmsegmentation/checkpoints_pspnet/iter_68000.pth'\n","workflow = [('train', 1)]\n","cudnn_benchmark = True\n","optimizer = dict(type='SGD', lr=0.01, momentum=0.9, weight_decay=0.0005)\n","optimizer_config = dict()\n","lr_config = dict(policy='poly', power=0.9, min_lr=0.0001, by_epoch=False)\n","runner = dict(type='IterBasedRunner', max_iters=80000)\n","checkpoint_config = dict(by_epoch=False, interval=1000)\n","evaluation = dict(\n","    interval=1000, metric=['mIoU', 'mDice', 'mFscore'], pre_eval=True)\n","work_dir = '/content/drive/MyDrive/catfish/tianqi/code/mmsegmentation/checkpoints_pspnet'\n","gpu_ids = range(0, 1)\n","auto_resume = False\n","\n","2023-01-05 04:52:21,555 - mmseg - INFO - Set random seed to 1166870166, deterministic: True\n","/content/drive/MyDrive/catfish/tianqi/code/mmsegmentation/mmseg/models/backbones/resnet.py:431: UserWarning: DeprecationWarning: pretrained is a deprecated, please use \"init_cfg\" instead\n","  warnings.warn('DeprecationWarning: pretrained is a deprecated, '\n","/content/drive/MyDrive/catfish/tianqi/code/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:235: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n","  warnings.warn(\n","2023-01-05 04:52:23,683 - mmcv - INFO - initialize ResNetV1c with init_cfg {'type': 'Pretrained', 'checkpoint': 'https://download.openmmlab.com/mmsegmentation/v0.5/pspnet/pspnet_r101-d8_512x512_80k_ade20k/pspnet_r101-d8_512x512_80k_ade20k_20200614_031423-b6e782f0.pth'}\n","2023-01-05 04:52:23,683 - mmcv - INFO - load model from: https://download.openmmlab.com/mmsegmentation/v0.5/pspnet/pspnet_r101-d8_512x512_80k_ade20k/pspnet_r101-d8_512x512_80k_ade20k_20200614_031423-b6e782f0.pth\n","2023-01-05 04:52:23,684 - mmcv - INFO - load checkpoint from http path: https://download.openmmlab.com/mmsegmentation/v0.5/pspnet/pspnet_r101-d8_512x512_80k_ade20k/pspnet_r101-d8_512x512_80k_ade20k_20200614_031423-b6e782f0.pth\n","Downloading: \"https://download.openmmlab.com/mmsegmentation/v0.5/pspnet/pspnet_r101-d8_512x512_80k_ade20k/pspnet_r101-d8_512x512_80k_ade20k_20200614_031423-b6e782f0.pth\" to /root/.cache/torch/hub/checkpoints/pspnet_r101-d8_512x512_80k_ade20k_20200614_031423-b6e782f0.pth\n","100% 260M/260M [00:26<00:00, 10.2MB/s]\n","2023-01-05 04:52:54,550 - mmcv - WARNING - The model and loaded state dict do not match exactly\n","\n","unexpected key in source state_dict: backbone.stem.0.weight, backbone.stem.1.weight, backbone.stem.1.bias, backbone.stem.1.running_mean, backbone.stem.1.running_var, backbone.stem.1.num_batches_tracked, backbone.stem.3.weight, backbone.stem.4.weight, backbone.stem.4.bias, backbone.stem.4.running_mean, backbone.stem.4.running_var, backbone.stem.4.num_batches_tracked, backbone.stem.6.weight, backbone.stem.7.weight, backbone.stem.7.bias, backbone.stem.7.running_mean, backbone.stem.7.running_var, backbone.stem.7.num_batches_tracked, backbone.layer1.0.conv1.weight, backbone.layer1.0.bn1.weight, backbone.layer1.0.bn1.bias, backbone.layer1.0.bn1.running_mean, backbone.layer1.0.bn1.running_var, backbone.layer1.0.bn1.num_batches_tracked, backbone.layer1.0.conv2.weight, backbone.layer1.0.bn2.weight, backbone.layer1.0.bn2.bias, backbone.layer1.0.bn2.running_mean, backbone.layer1.0.bn2.running_var, backbone.layer1.0.bn2.num_batches_tracked, backbone.layer1.0.conv3.weight, backbone.layer1.0.bn3.weight, backbone.layer1.0.bn3.bias, backbone.layer1.0.bn3.running_mean, backbone.layer1.0.bn3.running_var, backbone.layer1.0.bn3.num_batches_tracked, backbone.layer1.0.downsample.0.weight, backbone.layer1.0.downsample.1.weight, backbone.layer1.0.downsample.1.bias, backbone.layer1.0.downsample.1.running_mean, backbone.layer1.0.downsample.1.running_var, backbone.layer1.0.downsample.1.num_batches_tracked, backbone.layer1.1.conv1.weight, backbone.layer1.1.bn1.weight, backbone.layer1.1.bn1.bias, backbone.layer1.1.bn1.running_mean, backbone.layer1.1.bn1.running_var, backbone.layer1.1.bn1.num_batches_tracked, backbone.layer1.1.conv2.weight, backbone.layer1.1.bn2.weight, backbone.layer1.1.bn2.bias, backbone.layer1.1.bn2.running_mean, backbone.layer1.1.bn2.running_var, backbone.layer1.1.bn2.num_batches_tracked, backbone.layer1.1.conv3.weight, backbone.layer1.1.bn3.weight, backbone.layer1.1.bn3.bias, backbone.layer1.1.bn3.running_mean, backbone.layer1.1.bn3.running_var, backbone.layer1.1.bn3.num_batches_tracked, backbone.layer1.2.conv1.weight, backbone.layer1.2.bn1.weight, backbone.layer1.2.bn1.bias, backbone.layer1.2.bn1.running_mean, backbone.layer1.2.bn1.running_var, backbone.layer1.2.bn1.num_batches_tracked, backbone.layer1.2.conv2.weight, backbone.layer1.2.bn2.weight, backbone.layer1.2.bn2.bias, backbone.layer1.2.bn2.running_mean, backbone.layer1.2.bn2.running_var, backbone.layer1.2.bn2.num_batches_tracked, backbone.layer1.2.conv3.weight, backbone.layer1.2.bn3.weight, backbone.layer1.2.bn3.bias, backbone.layer1.2.bn3.running_mean, backbone.layer1.2.bn3.running_var, backbone.layer1.2.bn3.num_batches_tracked, backbone.layer2.0.conv1.weight, backbone.layer2.0.bn1.weight, backbone.layer2.0.bn1.bias, backbone.layer2.0.bn1.running_mean, backbone.layer2.0.bn1.running_var, backbone.layer2.0.bn1.num_batches_tracked, backbone.layer2.0.conv2.weight, backbone.layer2.0.bn2.weight, backbone.layer2.0.bn2.bias, backbone.layer2.0.bn2.running_mean, backbone.layer2.0.bn2.running_var, backbone.layer2.0.bn2.num_batches_tracked, backbone.layer2.0.conv3.weight, backbone.layer2.0.bn3.weight, backbone.layer2.0.bn3.bias, backbone.layer2.0.bn3.running_mean, backbone.layer2.0.bn3.running_var, backbone.layer2.0.bn3.num_batches_tracked, backbone.layer2.0.downsample.0.weight, backbone.layer2.0.downsample.1.weight, backbone.layer2.0.downsample.1.bias, backbone.layer2.0.downsample.1.running_mean, backbone.layer2.0.downsample.1.running_var, backbone.layer2.0.downsample.1.num_batches_tracked, backbone.layer2.1.conv1.weight, backbone.layer2.1.bn1.weight, backbone.layer2.1.bn1.bias, backbone.layer2.1.bn1.running_mean, backbone.layer2.1.bn1.running_var, backbone.layer2.1.bn1.num_batches_tracked, backbone.layer2.1.conv2.weight, backbone.layer2.1.bn2.weight, backbone.layer2.1.bn2.bias, backbone.layer2.1.bn2.running_mean, backbone.layer2.1.bn2.running_var, backbone.layer2.1.bn2.num_batches_tracked, backbone.layer2.1.conv3.weight, backbone.layer2.1.bn3.weight, backbone.layer2.1.bn3.bias, backbone.layer2.1.bn3.running_mean, backbone.layer2.1.bn3.running_var, backbone.layer2.1.bn3.num_batches_tracked, backbone.layer2.2.conv1.weight, backbone.layer2.2.bn1.weight, backbone.layer2.2.bn1.bias, backbone.layer2.2.bn1.running_mean, backbone.layer2.2.bn1.running_var, backbone.layer2.2.bn1.num_batches_tracked, backbone.layer2.2.conv2.weight, backbone.layer2.2.bn2.weight, backbone.layer2.2.bn2.bias, backbone.layer2.2.bn2.running_mean, backbone.layer2.2.bn2.running_var, backbone.layer2.2.bn2.num_batches_tracked, backbone.layer2.2.conv3.weight, backbone.layer2.2.bn3.weight, backbone.layer2.2.bn3.bias, backbone.layer2.2.bn3.running_mean, backbone.layer2.2.bn3.running_var, backbone.layer2.2.bn3.num_batches_tracked, backbone.layer2.3.conv1.weight, backbone.layer2.3.bn1.weight, backbone.layer2.3.bn1.bias, backbone.layer2.3.bn1.running_mean, backbone.layer2.3.bn1.running_var, backbone.layer2.3.bn1.num_batches_tracked, backbone.layer2.3.conv2.weight, backbone.layer2.3.bn2.weight, backbone.layer2.3.bn2.bias, backbone.layer2.3.bn2.running_mean, backbone.layer2.3.bn2.running_var, backbone.layer2.3.bn2.num_batches_tracked, backbone.layer2.3.conv3.weight, backbone.layer2.3.bn3.weight, backbone.layer2.3.bn3.bias, backbone.layer2.3.bn3.running_mean, backbone.layer2.3.bn3.running_var, backbone.layer2.3.bn3.num_batches_tracked, backbone.layer3.0.conv1.weight, backbone.layer3.0.bn1.weight, backbone.layer3.0.bn1.bias, backbone.layer3.0.bn1.running_mean, backbone.layer3.0.bn1.running_var, backbone.layer3.0.bn1.num_batches_tracked, backbone.layer3.0.conv2.weight, backbone.layer3.0.bn2.weight, backbone.layer3.0.bn2.bias, backbone.layer3.0.bn2.running_mean, backbone.layer3.0.bn2.running_var, backbone.layer3.0.bn2.num_batches_tracked, backbone.layer3.0.conv3.weight, backbone.layer3.0.bn3.weight, backbone.layer3.0.bn3.bias, backbone.layer3.0.bn3.running_mean, backbone.layer3.0.bn3.running_var, backbone.layer3.0.bn3.num_batches_tracked, backbone.layer3.0.downsample.0.weight, backbone.layer3.0.downsample.1.weight, backbone.layer3.0.downsample.1.bias, backbone.layer3.0.downsample.1.running_mean, backbone.layer3.0.downsample.1.running_var, backbone.layer3.0.downsample.1.num_batches_tracked, backbone.layer3.1.conv1.weight, backbone.layer3.1.bn1.weight, backbone.layer3.1.bn1.bias, backbone.layer3.1.bn1.running_mean, backbone.layer3.1.bn1.running_var, backbone.layer3.1.bn1.num_batches_tracked, backbone.layer3.1.conv2.weight, backbone.layer3.1.bn2.weight, backbone.layer3.1.bn2.bias, backbone.layer3.1.bn2.running_mean, backbone.layer3.1.bn2.running_var, backbone.layer3.1.bn2.num_batches_tracked, backbone.layer3.1.conv3.weight, backbone.layer3.1.bn3.weight, backbone.layer3.1.bn3.bias, backbone.layer3.1.bn3.running_mean, backbone.layer3.1.bn3.running_var, backbone.layer3.1.bn3.num_batches_tracked, backbone.layer3.2.conv1.weight, backbone.layer3.2.bn1.weight, backbone.layer3.2.bn1.bias, backbone.layer3.2.bn1.running_mean, backbone.layer3.2.bn1.running_var, backbone.layer3.2.bn1.num_batches_tracked, backbone.layer3.2.conv2.weight, backbone.layer3.2.bn2.weight, backbone.layer3.2.bn2.bias, backbone.layer3.2.bn2.running_mean, backbone.layer3.2.bn2.running_var, backbone.layer3.2.bn2.num_batches_tracked, backbone.layer3.2.conv3.weight, backbone.layer3.2.bn3.weight, backbone.layer3.2.bn3.bias, backbone.layer3.2.bn3.running_mean, backbone.layer3.2.bn3.running_var, backbone.layer3.2.bn3.num_batches_tracked, backbone.layer3.3.conv1.weight, backbone.layer3.3.bn1.weight, backbone.layer3.3.bn1.bias, backbone.layer3.3.bn1.running_mean, backbone.layer3.3.bn1.running_var, backbone.layer3.3.bn1.num_batches_tracked, backbone.layer3.3.conv2.weight, backbone.layer3.3.bn2.weight, backbone.layer3.3.bn2.bias, backbone.layer3.3.bn2.running_mean, backbone.layer3.3.bn2.running_var, backbone.layer3.3.bn2.num_batches_tracked, backbone.layer3.3.conv3.weight, backbone.layer3.3.bn3.weight, backbone.layer3.3.bn3.bias, backbone.layer3.3.bn3.running_mean, backbone.layer3.3.bn3.running_var, backbone.layer3.3.bn3.num_batches_tracked, backbone.layer3.4.conv1.weight, backbone.layer3.4.bn1.weight, backbone.layer3.4.bn1.bias, backbone.layer3.4.bn1.running_mean, backbone.layer3.4.bn1.running_var, backbone.layer3.4.bn1.num_batches_tracked, backbone.layer3.4.conv2.weight, backbone.layer3.4.bn2.weight, backbone.layer3.4.bn2.bias, backbone.layer3.4.bn2.running_mean, backbone.layer3.4.bn2.running_var, backbone.layer3.4.bn2.num_batches_tracked, backbone.layer3.4.conv3.weight, backbone.layer3.4.bn3.weight, backbone.layer3.4.bn3.bias, backbone.layer3.4.bn3.running_mean, backbone.layer3.4.bn3.running_var, backbone.layer3.4.bn3.num_batches_tracked, backbone.layer3.5.conv1.weight, backbone.layer3.5.bn1.weight, backbone.layer3.5.bn1.bias, backbone.layer3.5.bn1.running_mean, backbone.layer3.5.bn1.running_var, backbone.layer3.5.bn1.num_batches_tracked, backbone.layer3.5.conv2.weight, backbone.layer3.5.bn2.weight, backbone.layer3.5.bn2.bias, backbone.layer3.5.bn2.running_mean, backbone.layer3.5.bn2.running_var, backbone.layer3.5.bn2.num_batches_tracked, backbone.layer3.5.conv3.weight, backbone.layer3.5.bn3.weight, backbone.layer3.5.bn3.bias, backbone.layer3.5.bn3.running_mean, backbone.layer3.5.bn3.running_var, backbone.layer3.5.bn3.num_batches_tracked, backbone.layer3.6.conv1.weight, backbone.layer3.6.bn1.weight, backbone.layer3.6.bn1.bias, backbone.layer3.6.bn1.running_mean, backbone.layer3.6.bn1.running_var, backbone.layer3.6.bn1.num_batches_tracked, backbone.layer3.6.conv2.weight, backbone.layer3.6.bn2.weight, backbone.layer3.6.bn2.bias, backbone.layer3.6.bn2.running_mean, backbone.layer3.6.bn2.running_var, backbone.layer3.6.bn2.num_batches_tracked, backbone.layer3.6.conv3.weight, backbone.layer3.6.bn3.weight, backbone.layer3.6.bn3.bias, backbone.layer3.6.bn3.running_mean, backbone.layer3.6.bn3.running_var, backbone.layer3.6.bn3.num_batches_tracked, backbone.layer3.7.conv1.weight, backbone.layer3.7.bn1.weight, backbone.layer3.7.bn1.bias, backbone.layer3.7.bn1.running_mean, backbone.layer3.7.bn1.running_var, backbone.layer3.7.bn1.num_batches_tracked, backbone.layer3.7.conv2.weight, backbone.layer3.7.bn2.weight, backbone.layer3.7.bn2.bias, backbone.layer3.7.bn2.running_mean, backbone.layer3.7.bn2.running_var, backbone.layer3.7.bn2.num_batches_tracked, backbone.layer3.7.conv3.weight, backbone.layer3.7.bn3.weight, backbone.layer3.7.bn3.bias, backbone.layer3.7.bn3.running_mean, backbone.layer3.7.bn3.running_var, backbone.layer3.7.bn3.num_batches_tracked, backbone.layer3.8.conv1.weight, backbone.layer3.8.bn1.weight, backbone.layer3.8.bn1.bias, backbone.layer3.8.bn1.running_mean, backbone.layer3.8.bn1.running_var, backbone.layer3.8.bn1.num_batches_tracked, backbone.layer3.8.conv2.weight, backbone.layer3.8.bn2.weight, backbone.layer3.8.bn2.bias, backbone.layer3.8.bn2.running_mean, backbone.layer3.8.bn2.running_var, backbone.layer3.8.bn2.num_batches_tracked, backbone.layer3.8.conv3.weight, backbone.layer3.8.bn3.weight, backbone.layer3.8.bn3.bias, backbone.layer3.8.bn3.running_mean, backbone.layer3.8.bn3.running_var, backbone.layer3.8.bn3.num_batches_tracked, backbone.layer3.9.conv1.weight, backbone.layer3.9.bn1.weight, backbone.layer3.9.bn1.bias, backbone.layer3.9.bn1.running_mean, backbone.layer3.9.bn1.running_var, backbone.layer3.9.bn1.num_batches_tracked, backbone.layer3.9.conv2.weight, backbone.layer3.9.bn2.weight, backbone.layer3.9.bn2.bias, backbone.layer3.9.bn2.running_mean, backbone.layer3.9.bn2.running_var, backbone.layer3.9.bn2.num_batches_tracked, backbone.layer3.9.conv3.weight, backbone.layer3.9.bn3.weight, backbone.layer3.9.bn3.bias, backbone.layer3.9.bn3.running_mean, backbone.layer3.9.bn3.running_var, backbone.layer3.9.bn3.num_batches_tracked, backbone.layer3.10.conv1.weight, backbone.layer3.10.bn1.weight, backbone.layer3.10.bn1.bias, backbone.layer3.10.bn1.running_mean, backbone.layer3.10.bn1.running_var, backbone.layer3.10.bn1.num_batches_tracked, backbone.layer3.10.conv2.weight, backbone.layer3.10.bn2.weight, backbone.layer3.10.bn2.bias, backbone.layer3.10.bn2.running_mean, backbone.layer3.10.bn2.running_var, backbone.layer3.10.bn2.num_batches_tracked, backbone.layer3.10.conv3.weight, backbone.layer3.10.bn3.weight, backbone.layer3.10.bn3.bias, backbone.layer3.10.bn3.running_mean, backbone.layer3.10.bn3.running_var, backbone.layer3.10.bn3.num_batches_tracked, backbone.layer3.11.conv1.weight, backbone.layer3.11.bn1.weight, backbone.layer3.11.bn1.bias, backbone.layer3.11.bn1.running_mean, backbone.layer3.11.bn1.running_var, backbone.layer3.11.bn1.num_batches_tracked, backbone.layer3.11.conv2.weight, backbone.layer3.11.bn2.weight, backbone.layer3.11.bn2.bias, backbone.layer3.11.bn2.running_mean, backbone.layer3.11.bn2.running_var, backbone.layer3.11.bn2.num_batches_tracked, backbone.layer3.11.conv3.weight, backbone.layer3.11.bn3.weight, backbone.layer3.11.bn3.bias, backbone.layer3.11.bn3.running_mean, backbone.layer3.11.bn3.running_var, backbone.layer3.11.bn3.num_batches_tracked, backbone.layer3.12.conv1.weight, backbone.layer3.12.bn1.weight, backbone.layer3.12.bn1.bias, backbone.layer3.12.bn1.running_mean, backbone.layer3.12.bn1.running_var, backbone.layer3.12.bn1.num_batches_tracked, backbone.layer3.12.conv2.weight, backbone.layer3.12.bn2.weight, backbone.layer3.12.bn2.bias, backbone.layer3.12.bn2.running_mean, backbone.layer3.12.bn2.running_var, backbone.layer3.12.bn2.num_batches_tracked, backbone.layer3.12.conv3.weight, backbone.layer3.12.bn3.weight, backbone.layer3.12.bn3.bias, backbone.layer3.12.bn3.running_mean, backbone.layer3.12.bn3.running_var, backbone.layer3.12.bn3.num_batches_tracked, backbone.layer3.13.conv1.weight, backbone.layer3.13.bn1.weight, backbone.layer3.13.bn1.bias, backbone.layer3.13.bn1.running_mean, backbone.layer3.13.bn1.running_var, backbone.layer3.13.bn1.num_batches_tracked, backbone.layer3.13.conv2.weight, backbone.layer3.13.bn2.weight, backbone.layer3.13.bn2.bias, backbone.layer3.13.bn2.running_mean, backbone.layer3.13.bn2.running_var, backbone.layer3.13.bn2.num_batches_tracked, backbone.layer3.13.conv3.weight, backbone.layer3.13.bn3.weight, backbone.layer3.13.bn3.bias, backbone.layer3.13.bn3.running_mean, backbone.layer3.13.bn3.running_var, backbone.layer3.13.bn3.num_batches_tracked, backbone.layer3.14.conv1.weight, backbone.layer3.14.bn1.weight, backbone.layer3.14.bn1.bias, backbone.layer3.14.bn1.running_mean, backbone.layer3.14.bn1.running_var, backbone.layer3.14.bn1.num_batches_tracked, backbone.layer3.14.conv2.weight, backbone.layer3.14.bn2.weight, backbone.layer3.14.bn2.bias, backbone.layer3.14.bn2.running_mean, backbone.layer3.14.bn2.running_var, backbone.layer3.14.bn2.num_batches_tracked, backbone.layer3.14.conv3.weight, backbone.layer3.14.bn3.weight, backbone.layer3.14.bn3.bias, backbone.layer3.14.bn3.running_mean, backbone.layer3.14.bn3.running_var, backbone.layer3.14.bn3.num_batches_tracked, backbone.layer3.15.conv1.weight, backbone.layer3.15.bn1.weight, backbone.layer3.15.bn1.bias, backbone.layer3.15.bn1.running_mean, backbone.layer3.15.bn1.running_var, backbone.layer3.15.bn1.num_batches_tracked, backbone.layer3.15.conv2.weight, backbone.layer3.15.bn2.weight, backbone.layer3.15.bn2.bias, backbone.layer3.15.bn2.running_mean, backbone.layer3.15.bn2.running_var, backbone.layer3.15.bn2.num_batches_tracked, backbone.layer3.15.conv3.weight, backbone.layer3.15.bn3.weight, backbone.layer3.15.bn3.bias, backbone.layer3.15.bn3.running_mean, backbone.layer3.15.bn3.running_var, backbone.layer3.15.bn3.num_batches_tracked, backbone.layer3.16.conv1.weight, backbone.layer3.16.bn1.weight, backbone.layer3.16.bn1.bias, backbone.layer3.16.bn1.running_mean, backbone.layer3.16.bn1.running_var, backbone.layer3.16.bn1.num_batches_tracked, backbone.layer3.16.conv2.weight, backbone.layer3.16.bn2.weight, backbone.layer3.16.bn2.bias, backbone.layer3.16.bn2.running_mean, backbone.layer3.16.bn2.running_var, backbone.layer3.16.bn2.num_batches_tracked, backbone.layer3.16.conv3.weight, backbone.layer3.16.bn3.weight, backbone.layer3.16.bn3.bias, backbone.layer3.16.bn3.running_mean, backbone.layer3.16.bn3.running_var, backbone.layer3.16.bn3.num_batches_tracked, backbone.layer3.17.conv1.weight, backbone.layer3.17.bn1.weight, backbone.layer3.17.bn1.bias, backbone.layer3.17.bn1.running_mean, backbone.layer3.17.bn1.running_var, backbone.layer3.17.bn1.num_batches_tracked, backbone.layer3.17.conv2.weight, backbone.layer3.17.bn2.weight, backbone.layer3.17.bn2.bias, backbone.layer3.17.bn2.running_mean, backbone.layer3.17.bn2.running_var, backbone.layer3.17.bn2.num_batches_tracked, backbone.layer3.17.conv3.weight, backbone.layer3.17.bn3.weight, backbone.layer3.17.bn3.bias, backbone.layer3.17.bn3.running_mean, backbone.layer3.17.bn3.running_var, backbone.layer3.17.bn3.num_batches_tracked, backbone.layer3.18.conv1.weight, backbone.layer3.18.bn1.weight, backbone.layer3.18.bn1.bias, backbone.layer3.18.bn1.running_mean, backbone.layer3.18.bn1.running_var, backbone.layer3.18.bn1.num_batches_tracked, backbone.layer3.18.conv2.weight, backbone.layer3.18.bn2.weight, backbone.layer3.18.bn2.bias, backbone.layer3.18.bn2.running_mean, backbone.layer3.18.bn2.running_var, backbone.layer3.18.bn2.num_batches_tracked, backbone.layer3.18.conv3.weight, backbone.layer3.18.bn3.weight, backbone.layer3.18.bn3.bias, backbone.layer3.18.bn3.running_mean, backbone.layer3.18.bn3.running_var, backbone.layer3.18.bn3.num_batches_tracked, backbone.layer3.19.conv1.weight, backbone.layer3.19.bn1.weight, backbone.layer3.19.bn1.bias, backbone.layer3.19.bn1.running_mean, backbone.layer3.19.bn1.running_var, backbone.layer3.19.bn1.num_batches_tracked, backbone.layer3.19.conv2.weight, backbone.layer3.19.bn2.weight, backbone.layer3.19.bn2.bias, backbone.layer3.19.bn2.running_mean, backbone.layer3.19.bn2.running_var, backbone.layer3.19.bn2.num_batches_tracked, backbone.layer3.19.conv3.weight, backbone.layer3.19.bn3.weight, backbone.layer3.19.bn3.bias, backbone.layer3.19.bn3.running_mean, backbone.layer3.19.bn3.running_var, backbone.layer3.19.bn3.num_batches_tracked, backbone.layer3.20.conv1.weight, backbone.layer3.20.bn1.weight, backbone.layer3.20.bn1.bias, backbone.layer3.20.bn1.running_mean, backbone.layer3.20.bn1.running_var, backbone.layer3.20.bn1.num_batches_tracked, backbone.layer3.20.conv2.weight, backbone.layer3.20.bn2.weight, backbone.layer3.20.bn2.bias, backbone.layer3.20.bn2.running_mean, backbone.layer3.20.bn2.running_var, backbone.layer3.20.bn2.num_batches_tracked, backbone.layer3.20.conv3.weight, backbone.layer3.20.bn3.weight, backbone.layer3.20.bn3.bias, backbone.layer3.20.bn3.running_mean, backbone.layer3.20.bn3.running_var, backbone.layer3.20.bn3.num_batches_tracked, backbone.layer3.21.conv1.weight, backbone.layer3.21.bn1.weight, backbone.layer3.21.bn1.bias, backbone.layer3.21.bn1.running_mean, backbone.layer3.21.bn1.running_var, backbone.layer3.21.bn1.num_batches_tracked, backbone.layer3.21.conv2.weight, backbone.layer3.21.bn2.weight, backbone.layer3.21.bn2.bias, backbone.layer3.21.bn2.running_mean, backbone.layer3.21.bn2.running_var, backbone.layer3.21.bn2.num_batches_tracked, backbone.layer3.21.conv3.weight, backbone.layer3.21.bn3.weight, backbone.layer3.21.bn3.bias, backbone.layer3.21.bn3.running_mean, backbone.layer3.21.bn3.running_var, backbone.layer3.21.bn3.num_batches_tracked, backbone.layer3.22.conv1.weight, backbone.layer3.22.bn1.weight, backbone.layer3.22.bn1.bias, backbone.layer3.22.bn1.running_mean, backbone.layer3.22.bn1.running_var, backbone.layer3.22.bn1.num_batches_tracked, backbone.layer3.22.conv2.weight, backbone.layer3.22.bn2.weight, backbone.layer3.22.bn2.bias, backbone.layer3.22.bn2.running_mean, backbone.layer3.22.bn2.running_var, backbone.layer3.22.bn2.num_batches_tracked, backbone.layer3.22.conv3.weight, backbone.layer3.22.bn3.weight, backbone.layer3.22.bn3.bias, backbone.layer3.22.bn3.running_mean, backbone.layer3.22.bn3.running_var, backbone.layer3.22.bn3.num_batches_tracked, backbone.layer4.0.conv1.weight, backbone.layer4.0.bn1.weight, backbone.layer4.0.bn1.bias, backbone.layer4.0.bn1.running_mean, backbone.layer4.0.bn1.running_var, backbone.layer4.0.bn1.num_batches_tracked, backbone.layer4.0.conv2.weight, backbone.layer4.0.bn2.weight, backbone.layer4.0.bn2.bias, backbone.layer4.0.bn2.running_mean, backbone.layer4.0.bn2.running_var, backbone.layer4.0.bn2.num_batches_tracked, backbone.layer4.0.conv3.weight, backbone.layer4.0.bn3.weight, backbone.layer4.0.bn3.bias, backbone.layer4.0.bn3.running_mean, backbone.layer4.0.bn3.running_var, backbone.layer4.0.bn3.num_batches_tracked, backbone.layer4.0.downsample.0.weight, backbone.layer4.0.downsample.1.weight, backbone.layer4.0.downsample.1.bias, backbone.layer4.0.downsample.1.running_mean, backbone.layer4.0.downsample.1.running_var, backbone.layer4.0.downsample.1.num_batches_tracked, backbone.layer4.1.conv1.weight, backbone.layer4.1.bn1.weight, backbone.layer4.1.bn1.bias, backbone.layer4.1.bn1.running_mean, backbone.layer4.1.bn1.running_var, backbone.layer4.1.bn1.num_batches_tracked, backbone.layer4.1.conv2.weight, backbone.layer4.1.bn2.weight, backbone.layer4.1.bn2.bias, backbone.layer4.1.bn2.running_mean, backbone.layer4.1.bn2.running_var, backbone.layer4.1.bn2.num_batches_tracked, backbone.layer4.1.conv3.weight, backbone.layer4.1.bn3.weight, backbone.layer4.1.bn3.bias, backbone.layer4.1.bn3.running_mean, backbone.layer4.1.bn3.running_var, backbone.layer4.1.bn3.num_batches_tracked, backbone.layer4.2.conv1.weight, backbone.layer4.2.bn1.weight, backbone.layer4.2.bn1.bias, backbone.layer4.2.bn1.running_mean, backbone.layer4.2.bn1.running_var, backbone.layer4.2.bn1.num_batches_tracked, backbone.layer4.2.conv2.weight, backbone.layer4.2.bn2.weight, backbone.layer4.2.bn2.bias, backbone.layer4.2.bn2.running_mean, backbone.layer4.2.bn2.running_var, backbone.layer4.2.bn2.num_batches_tracked, backbone.layer4.2.conv3.weight, backbone.layer4.2.bn3.weight, backbone.layer4.2.bn3.bias, backbone.layer4.2.bn3.running_mean, backbone.layer4.2.bn3.running_var, backbone.layer4.2.bn3.num_batches_tracked, decode_head.conv_seg.weight, decode_head.conv_seg.bias, decode_head.psp_modules.0.1.conv.weight, decode_head.psp_modules.0.1.bn.weight, decode_head.psp_modules.0.1.bn.bias, decode_head.psp_modules.0.1.bn.running_mean, decode_head.psp_modules.0.1.bn.running_var, decode_head.psp_modules.0.1.bn.num_batches_tracked, decode_head.psp_modules.1.1.conv.weight, decode_head.psp_modules.1.1.bn.weight, decode_head.psp_modules.1.1.bn.bias, decode_head.psp_modules.1.1.bn.running_mean, decode_head.psp_modules.1.1.bn.running_var, decode_head.psp_modules.1.1.bn.num_batches_tracked, decode_head.psp_modules.2.1.conv.weight, decode_head.psp_modules.2.1.bn.weight, decode_head.psp_modules.2.1.bn.bias, decode_head.psp_modules.2.1.bn.running_mean, decode_head.psp_modules.2.1.bn.running_var, decode_head.psp_modules.2.1.bn.num_batches_tracked, decode_head.psp_modules.3.1.conv.weight, decode_head.psp_modules.3.1.bn.weight, decode_head.psp_modules.3.1.bn.bias, decode_head.psp_modules.3.1.bn.running_mean, decode_head.psp_modules.3.1.bn.running_var, decode_head.psp_modules.3.1.bn.num_batches_tracked, decode_head.bottleneck.conv.weight, decode_head.bottleneck.bn.weight, decode_head.bottleneck.bn.bias, decode_head.bottleneck.bn.running_mean, decode_head.bottleneck.bn.running_var, decode_head.bottleneck.bn.num_batches_tracked, auxiliary_head.conv_seg.weight, auxiliary_head.conv_seg.bias, auxiliary_head.convs.0.conv.weight, auxiliary_head.convs.0.bn.weight, auxiliary_head.convs.0.bn.bias, auxiliary_head.convs.0.bn.running_mean, auxiliary_head.convs.0.bn.running_var, auxiliary_head.convs.0.bn.num_batches_tracked\n","\n","missing keys in source state_dict: stem.0.weight, stem.1.weight, stem.1.bias, stem.1.running_mean, stem.1.running_var, stem.3.weight, stem.4.weight, stem.4.bias, stem.4.running_mean, stem.4.running_var, stem.6.weight, stem.7.weight, stem.7.bias, stem.7.running_mean, stem.7.running_var, layer1.0.conv1.weight, layer1.0.bn1.weight, layer1.0.bn1.bias, layer1.0.bn1.running_mean, layer1.0.bn1.running_var, layer1.0.conv2.weight, layer1.0.bn2.weight, layer1.0.bn2.bias, layer1.0.bn2.running_mean, layer1.0.bn2.running_var, layer1.0.conv3.weight, layer1.0.bn3.weight, layer1.0.bn3.bias, layer1.0.bn3.running_mean, layer1.0.bn3.running_var, layer1.0.downsample.0.weight, layer1.0.downsample.1.weight, layer1.0.downsample.1.bias, layer1.0.downsample.1.running_mean, layer1.0.downsample.1.running_var, layer1.1.conv1.weight, layer1.1.bn1.weight, layer1.1.bn1.bias, layer1.1.bn1.running_mean, layer1.1.bn1.running_var, layer1.1.conv2.weight, layer1.1.bn2.weight, layer1.1.bn2.bias, layer1.1.bn2.running_mean, layer1.1.bn2.running_var, layer1.1.conv3.weight, layer1.1.bn3.weight, layer1.1.bn3.bias, layer1.1.bn3.running_mean, layer1.1.bn3.running_var, layer1.2.conv1.weight, layer1.2.bn1.weight, layer1.2.bn1.bias, layer1.2.bn1.running_mean, layer1.2.bn1.running_var, layer1.2.conv2.weight, layer1.2.bn2.weight, layer1.2.bn2.bias, layer1.2.bn2.running_mean, layer1.2.bn2.running_var, layer1.2.conv3.weight, layer1.2.bn3.weight, layer1.2.bn3.bias, layer1.2.bn3.running_mean, layer1.2.bn3.running_var, layer2.0.conv1.weight, layer2.0.bn1.weight, layer2.0.bn1.bias, layer2.0.bn1.running_mean, layer2.0.bn1.running_var, layer2.0.conv2.weight, layer2.0.bn2.weight, layer2.0.bn2.bias, layer2.0.bn2.running_mean, layer2.0.bn2.running_var, layer2.0.conv3.weight, layer2.0.bn3.weight, layer2.0.bn3.bias, layer2.0.bn3.running_mean, layer2.0.bn3.running_var, layer2.0.downsample.0.weight, layer2.0.downsample.1.weight, layer2.0.downsample.1.bias, layer2.0.downsample.1.running_mean, layer2.0.downsample.1.running_var, layer2.1.conv1.weight, layer2.1.bn1.weight, layer2.1.bn1.bias, layer2.1.bn1.running_mean, layer2.1.bn1.running_var, layer2.1.conv2.weight, layer2.1.bn2.weight, layer2.1.bn2.bias, layer2.1.bn2.running_mean, layer2.1.bn2.running_var, layer2.1.conv3.weight, layer2.1.bn3.weight, layer2.1.bn3.bias, layer2.1.bn3.running_mean, layer2.1.bn3.running_var, layer2.2.conv1.weight, layer2.2.bn1.weight, layer2.2.bn1.bias, layer2.2.bn1.running_mean, layer2.2.bn1.running_var, layer2.2.conv2.weight, layer2.2.bn2.weight, layer2.2.bn2.bias, layer2.2.bn2.running_mean, layer2.2.bn2.running_var, layer2.2.conv3.weight, layer2.2.bn3.weight, layer2.2.bn3.bias, layer2.2.bn3.running_mean, layer2.2.bn3.running_var, layer2.3.conv1.weight, layer2.3.bn1.weight, layer2.3.bn1.bias, layer2.3.bn1.running_mean, layer2.3.bn1.running_var, layer2.3.conv2.weight, layer2.3.bn2.weight, layer2.3.bn2.bias, layer2.3.bn2.running_mean, layer2.3.bn2.running_var, layer2.3.conv3.weight, layer2.3.bn3.weight, layer2.3.bn3.bias, layer2.3.bn3.running_mean, layer2.3.bn3.running_var, layer3.0.conv1.weight, layer3.0.bn1.weight, layer3.0.bn1.bias, layer3.0.bn1.running_mean, layer3.0.bn1.running_var, layer3.0.conv2.weight, layer3.0.bn2.weight, layer3.0.bn2.bias, layer3.0.bn2.running_mean, layer3.0.bn2.running_var, layer3.0.conv3.weight, layer3.0.bn3.weight, layer3.0.bn3.bias, layer3.0.bn3.running_mean, layer3.0.bn3.running_var, layer3.0.downsample.0.weight, layer3.0.downsample.1.weight, layer3.0.downsample.1.bias, layer3.0.downsample.1.running_mean, layer3.0.downsample.1.running_var, layer3.1.conv1.weight, layer3.1.bn1.weight, layer3.1.bn1.bias, layer3.1.bn1.running_mean, layer3.1.bn1.running_var, layer3.1.conv2.weight, layer3.1.bn2.weight, layer3.1.bn2.bias, layer3.1.bn2.running_mean, layer3.1.bn2.running_var, layer3.1.conv3.weight, layer3.1.bn3.weight, layer3.1.bn3.bias, layer3.1.bn3.running_mean, layer3.1.bn3.running_var, layer3.2.conv1.weight, layer3.2.bn1.weight, layer3.2.bn1.bias, layer3.2.bn1.running_mean, layer3.2.bn1.running_var, layer3.2.conv2.weight, layer3.2.bn2.weight, layer3.2.bn2.bias, layer3.2.bn2.running_mean, layer3.2.bn2.running_var, layer3.2.conv3.weight, layer3.2.bn3.weight, layer3.2.bn3.bias, layer3.2.bn3.running_mean, layer3.2.bn3.running_var, layer3.3.conv1.weight, layer3.3.bn1.weight, layer3.3.bn1.bias, layer3.3.bn1.running_mean, layer3.3.bn1.running_var, layer3.3.conv2.weight, layer3.3.bn2.weight, layer3.3.bn2.bias, layer3.3.bn2.running_mean, layer3.3.bn2.running_var, layer3.3.conv3.weight, layer3.3.bn3.weight, layer3.3.bn3.bias, layer3.3.bn3.running_mean, layer3.3.bn3.running_var, layer3.4.conv1.weight, layer3.4.bn1.weight, layer3.4.bn1.bias, layer3.4.bn1.running_mean, layer3.4.bn1.running_var, layer3.4.conv2.weight, layer3.4.bn2.weight, layer3.4.bn2.bias, layer3.4.bn2.running_mean, layer3.4.bn2.running_var, layer3.4.conv3.weight, layer3.4.bn3.weight, layer3.4.bn3.bias, layer3.4.bn3.running_mean, layer3.4.bn3.running_var, layer3.5.conv1.weight, layer3.5.bn1.weight, layer3.5.bn1.bias, layer3.5.bn1.running_mean, layer3.5.bn1.running_var, layer3.5.conv2.weight, layer3.5.bn2.weight, layer3.5.bn2.bias, layer3.5.bn2.running_mean, layer3.5.bn2.running_var, layer3.5.conv3.weight, layer3.5.bn3.weight, layer3.5.bn3.bias, layer3.5.bn3.running_mean, layer3.5.bn3.running_var, layer3.6.conv1.weight, layer3.6.bn1.weight, layer3.6.bn1.bias, layer3.6.bn1.running_mean, layer3.6.bn1.running_var, layer3.6.conv2.weight, layer3.6.bn2.weight, layer3.6.bn2.bias, layer3.6.bn2.running_mean, layer3.6.bn2.running_var, layer3.6.conv3.weight, layer3.6.bn3.weight, layer3.6.bn3.bias, layer3.6.bn3.running_mean, layer3.6.bn3.running_var, layer3.7.conv1.weight, layer3.7.bn1.weight, layer3.7.bn1.bias, layer3.7.bn1.running_mean, layer3.7.bn1.running_var, layer3.7.conv2.weight, layer3.7.bn2.weight, layer3.7.bn2.bias, layer3.7.bn2.running_mean, layer3.7.bn2.running_var, layer3.7.conv3.weight, layer3.7.bn3.weight, layer3.7.bn3.bias, layer3.7.bn3.running_mean, layer3.7.bn3.running_var, layer3.8.conv1.weight, layer3.8.bn1.weight, layer3.8.bn1.bias, layer3.8.bn1.running_mean, layer3.8.bn1.running_var, layer3.8.conv2.weight, layer3.8.bn2.weight, layer3.8.bn2.bias, layer3.8.bn2.running_mean, layer3.8.bn2.running_var, layer3.8.conv3.weight, layer3.8.bn3.weight, layer3.8.bn3.bias, layer3.8.bn3.running_mean, layer3.8.bn3.running_var, layer3.9.conv1.weight, layer3.9.bn1.weight, layer3.9.bn1.bias, layer3.9.bn1.running_mean, layer3.9.bn1.running_var, layer3.9.conv2.weight, layer3.9.bn2.weight, layer3.9.bn2.bias, layer3.9.bn2.running_mean, layer3.9.bn2.running_var, layer3.9.conv3.weight, layer3.9.bn3.weight, layer3.9.bn3.bias, layer3.9.bn3.running_mean, layer3.9.bn3.running_var, layer3.10.conv1.weight, layer3.10.bn1.weight, layer3.10.bn1.bias, layer3.10.bn1.running_mean, layer3.10.bn1.running_var, layer3.10.conv2.weight, layer3.10.bn2.weight, layer3.10.bn2.bias, layer3.10.bn2.running_mean, layer3.10.bn2.running_var, layer3.10.conv3.weight, layer3.10.bn3.weight, layer3.10.bn3.bias, layer3.10.bn3.running_mean, layer3.10.bn3.running_var, layer3.11.conv1.weight, layer3.11.bn1.weight, layer3.11.bn1.bias, layer3.11.bn1.running_mean, layer3.11.bn1.running_var, layer3.11.conv2.weight, layer3.11.bn2.weight, layer3.11.bn2.bias, layer3.11.bn2.running_mean, layer3.11.bn2.running_var, layer3.11.conv3.weight, layer3.11.bn3.weight, layer3.11.bn3.bias, layer3.11.bn3.running_mean, layer3.11.bn3.running_var, layer3.12.conv1.weight, layer3.12.bn1.weight, layer3.12.bn1.bias, layer3.12.bn1.running_mean, layer3.12.bn1.running_var, layer3.12.conv2.weight, layer3.12.bn2.weight, layer3.12.bn2.bias, layer3.12.bn2.running_mean, layer3.12.bn2.running_var, layer3.12.conv3.weight, layer3.12.bn3.weight, layer3.12.bn3.bias, layer3.12.bn3.running_mean, layer3.12.bn3.running_var, layer3.13.conv1.weight, layer3.13.bn1.weight, layer3.13.bn1.bias, layer3.13.bn1.running_mean, layer3.13.bn1.running_var, layer3.13.conv2.weight, layer3.13.bn2.weight, layer3.13.bn2.bias, layer3.13.bn2.running_mean, layer3.13.bn2.running_var, layer3.13.conv3.weight, layer3.13.bn3.weight, layer3.13.bn3.bias, layer3.13.bn3.running_mean, layer3.13.bn3.running_var, layer3.14.conv1.weight, layer3.14.bn1.weight, layer3.14.bn1.bias, layer3.14.bn1.running_mean, layer3.14.bn1.running_var, layer3.14.conv2.weight, layer3.14.bn2.weight, layer3.14.bn2.bias, layer3.14.bn2.running_mean, layer3.14.bn2.running_var, layer3.14.conv3.weight, layer3.14.bn3.weight, layer3.14.bn3.bias, layer3.14.bn3.running_mean, layer3.14.bn3.running_var, layer3.15.conv1.weight, layer3.15.bn1.weight, layer3.15.bn1.bias, layer3.15.bn1.running_mean, layer3.15.bn1.running_var, layer3.15.conv2.weight, layer3.15.bn2.weight, layer3.15.bn2.bias, layer3.15.bn2.running_mean, layer3.15.bn2.running_var, layer3.15.conv3.weight, layer3.15.bn3.weight, layer3.15.bn3.bias, layer3.15.bn3.running_mean, layer3.15.bn3.running_var, layer3.16.conv1.weight, layer3.16.bn1.weight, layer3.16.bn1.bias, layer3.16.bn1.running_mean, layer3.16.bn1.running_var, layer3.16.conv2.weight, layer3.16.bn2.weight, layer3.16.bn2.bias, layer3.16.bn2.running_mean, layer3.16.bn2.running_var, layer3.16.conv3.weight, layer3.16.bn3.weight, layer3.16.bn3.bias, layer3.16.bn3.running_mean, layer3.16.bn3.running_var, layer3.17.conv1.weight, layer3.17.bn1.weight, layer3.17.bn1.bias, layer3.17.bn1.running_mean, layer3.17.bn1.running_var, layer3.17.conv2.weight, layer3.17.bn2.weight, layer3.17.bn2.bias, layer3.17.bn2.running_mean, layer3.17.bn2.running_var, layer3.17.conv3.weight, layer3.17.bn3.weight, layer3.17.bn3.bias, layer3.17.bn3.running_mean, layer3.17.bn3.running_var, layer3.18.conv1.weight, layer3.18.bn1.weight, layer3.18.bn1.bias, layer3.18.bn1.running_mean, layer3.18.bn1.running_var, layer3.18.conv2.weight, layer3.18.bn2.weight, layer3.18.bn2.bias, layer3.18.bn2.running_mean, layer3.18.bn2.running_var, layer3.18.conv3.weight, layer3.18.bn3.weight, layer3.18.bn3.bias, layer3.18.bn3.running_mean, layer3.18.bn3.running_var, layer3.19.conv1.weight, layer3.19.bn1.weight, layer3.19.bn1.bias, layer3.19.bn1.running_mean, layer3.19.bn1.running_var, layer3.19.conv2.weight, layer3.19.bn2.weight, layer3.19.bn2.bias, layer3.19.bn2.running_mean, layer3.19.bn2.running_var, layer3.19.conv3.weight, layer3.19.bn3.weight, layer3.19.bn3.bias, layer3.19.bn3.running_mean, layer3.19.bn3.running_var, layer3.20.conv1.weight, layer3.20.bn1.weight, layer3.20.bn1.bias, layer3.20.bn1.running_mean, layer3.20.bn1.running_var, layer3.20.conv2.weight, layer3.20.bn2.weight, layer3.20.bn2.bias, layer3.20.bn2.running_mean, layer3.20.bn2.running_var, layer3.20.conv3.weight, layer3.20.bn3.weight, layer3.20.bn3.bias, layer3.20.bn3.running_mean, layer3.20.bn3.running_var, layer3.21.conv1.weight, layer3.21.bn1.weight, layer3.21.bn1.bias, layer3.21.bn1.running_mean, layer3.21.bn1.running_var, layer3.21.conv2.weight, layer3.21.bn2.weight, layer3.21.bn2.bias, layer3.21.bn2.running_mean, layer3.21.bn2.running_var, layer3.21.conv3.weight, layer3.21.bn3.weight, layer3.21.bn3.bias, layer3.21.bn3.running_mean, layer3.21.bn3.running_var, layer3.22.conv1.weight, layer3.22.bn1.weight, layer3.22.bn1.bias, layer3.22.bn1.running_mean, layer3.22.bn1.running_var, layer3.22.conv2.weight, layer3.22.bn2.weight, layer3.22.bn2.bias, layer3.22.bn2.running_mean, layer3.22.bn2.running_var, layer3.22.conv3.weight, layer3.22.bn3.weight, layer3.22.bn3.bias, layer3.22.bn3.running_mean, layer3.22.bn3.running_var, layer4.0.conv1.weight, layer4.0.bn1.weight, layer4.0.bn1.bias, layer4.0.bn1.running_mean, layer4.0.bn1.running_var, layer4.0.conv2.weight, layer4.0.bn2.weight, layer4.0.bn2.bias, layer4.0.bn2.running_mean, layer4.0.bn2.running_var, layer4.0.conv3.weight, layer4.0.bn3.weight, layer4.0.bn3.bias, layer4.0.bn3.running_mean, layer4.0.bn3.running_var, layer4.0.downsample.0.weight, layer4.0.downsample.1.weight, layer4.0.downsample.1.bias, layer4.0.downsample.1.running_mean, layer4.0.downsample.1.running_var, layer4.1.conv1.weight, layer4.1.bn1.weight, layer4.1.bn1.bias, layer4.1.bn1.running_mean, layer4.1.bn1.running_var, layer4.1.conv2.weight, layer4.1.bn2.weight, layer4.1.bn2.bias, layer4.1.bn2.running_mean, layer4.1.bn2.running_var, layer4.1.conv3.weight, layer4.1.bn3.weight, layer4.1.bn3.bias, layer4.1.bn3.running_mean, layer4.1.bn3.running_var, layer4.2.conv1.weight, layer4.2.bn1.weight, layer4.2.bn1.bias, layer4.2.bn1.running_mean, layer4.2.bn1.running_var, layer4.2.conv2.weight, layer4.2.bn2.weight, layer4.2.bn2.bias, layer4.2.bn2.running_mean, layer4.2.bn2.running_var, layer4.2.conv3.weight, layer4.2.bn3.weight, layer4.2.bn3.bias, layer4.2.bn3.running_mean, layer4.2.bn3.running_var\n","\n","2023-01-05 04:52:54,676 - mmcv - INFO - initialize PSPHead with init_cfg {'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}\n","2023-01-05 04:52:54,855 - mmcv - INFO - initialize FCNHead with init_cfg {'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}\n","2023-01-05 04:52:54,858 - mmcv - INFO - \n","backbone.stem.0.weight - torch.Size([32, 3, 3, 3]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,858 - mmcv - INFO - \n","backbone.stem.1.weight - torch.Size([32]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,859 - mmcv - INFO - \n","backbone.stem.1.bias - torch.Size([32]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,859 - mmcv - INFO - \n","backbone.stem.3.weight - torch.Size([32, 32, 3, 3]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,859 - mmcv - INFO - \n","backbone.stem.4.weight - torch.Size([32]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,859 - mmcv - INFO - \n","backbone.stem.4.bias - torch.Size([32]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,859 - mmcv - INFO - \n","backbone.stem.6.weight - torch.Size([64, 32, 3, 3]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,859 - mmcv - INFO - \n","backbone.stem.7.weight - torch.Size([64]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,859 - mmcv - INFO - \n","backbone.stem.7.bias - torch.Size([64]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,859 - mmcv - INFO - \n","backbone.layer1.0.conv1.weight - torch.Size([64, 64, 1, 1]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,859 - mmcv - INFO - \n","backbone.layer1.0.bn1.weight - torch.Size([64]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,859 - mmcv - INFO - \n","backbone.layer1.0.bn1.bias - torch.Size([64]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,859 - mmcv - INFO - \n","backbone.layer1.0.conv2.weight - torch.Size([64, 64, 3, 3]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,859 - mmcv - INFO - \n","backbone.layer1.0.bn2.weight - torch.Size([64]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,859 - mmcv - INFO - \n","backbone.layer1.0.bn2.bias - torch.Size([64]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,859 - mmcv - INFO - \n","backbone.layer1.0.conv3.weight - torch.Size([256, 64, 1, 1]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,859 - mmcv - INFO - \n","backbone.layer1.0.bn3.weight - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,859 - mmcv - INFO - \n","backbone.layer1.0.bn3.bias - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,860 - mmcv - INFO - \n","backbone.layer1.0.downsample.0.weight - torch.Size([256, 64, 1, 1]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,860 - mmcv - INFO - \n","backbone.layer1.0.downsample.1.weight - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,860 - mmcv - INFO - \n","backbone.layer1.0.downsample.1.bias - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,860 - mmcv - INFO - \n","backbone.layer1.1.conv1.weight - torch.Size([64, 256, 1, 1]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,860 - mmcv - INFO - \n","backbone.layer1.1.bn1.weight - torch.Size([64]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,860 - mmcv - INFO - \n","backbone.layer1.1.bn1.bias - torch.Size([64]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,860 - mmcv - INFO - \n","backbone.layer1.1.conv2.weight - torch.Size([64, 64, 3, 3]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,860 - mmcv - INFO - \n","backbone.layer1.1.bn2.weight - torch.Size([64]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,860 - mmcv - INFO - \n","backbone.layer1.1.bn2.bias - torch.Size([64]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,860 - mmcv - INFO - \n","backbone.layer1.1.conv3.weight - torch.Size([256, 64, 1, 1]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,860 - mmcv - INFO - \n","backbone.layer1.1.bn3.weight - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,860 - mmcv - INFO - \n","backbone.layer1.1.bn3.bias - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,860 - mmcv - INFO - \n","backbone.layer1.2.conv1.weight - torch.Size([64, 256, 1, 1]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,860 - mmcv - INFO - \n","backbone.layer1.2.bn1.weight - torch.Size([64]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,860 - mmcv - INFO - \n","backbone.layer1.2.bn1.bias - torch.Size([64]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,860 - mmcv - INFO - \n","backbone.layer1.2.conv2.weight - torch.Size([64, 64, 3, 3]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,860 - mmcv - INFO - \n","backbone.layer1.2.bn2.weight - torch.Size([64]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,861 - mmcv - INFO - \n","backbone.layer1.2.bn2.bias - torch.Size([64]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,861 - mmcv - INFO - \n","backbone.layer1.2.conv3.weight - torch.Size([256, 64, 1, 1]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,861 - mmcv - INFO - \n","backbone.layer1.2.bn3.weight - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,861 - mmcv - INFO - \n","backbone.layer1.2.bn3.bias - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,861 - mmcv - INFO - \n","backbone.layer2.0.conv1.weight - torch.Size([128, 256, 1, 1]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,861 - mmcv - INFO - \n","backbone.layer2.0.bn1.weight - torch.Size([128]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,861 - mmcv - INFO - \n","backbone.layer2.0.bn1.bias - torch.Size([128]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,861 - mmcv - INFO - \n","backbone.layer2.0.conv2.weight - torch.Size([128, 128, 3, 3]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,861 - mmcv - INFO - \n","backbone.layer2.0.bn2.weight - torch.Size([128]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,861 - mmcv - INFO - \n","backbone.layer2.0.bn2.bias - torch.Size([128]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,861 - mmcv - INFO - \n","backbone.layer2.0.conv3.weight - torch.Size([512, 128, 1, 1]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,861 - mmcv - INFO - \n","backbone.layer2.0.bn3.weight - torch.Size([512]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,861 - mmcv - INFO - \n","backbone.layer2.0.bn3.bias - torch.Size([512]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,861 - mmcv - INFO - \n","backbone.layer2.0.downsample.0.weight - torch.Size([512, 256, 1, 1]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,861 - mmcv - INFO - \n","backbone.layer2.0.downsample.1.weight - torch.Size([512]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,861 - mmcv - INFO - \n","backbone.layer2.0.downsample.1.bias - torch.Size([512]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,861 - mmcv - INFO - \n","backbone.layer2.1.conv1.weight - torch.Size([128, 512, 1, 1]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,861 - mmcv - INFO - \n","backbone.layer2.1.bn1.weight - torch.Size([128]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,862 - mmcv - INFO - \n","backbone.layer2.1.bn1.bias - torch.Size([128]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,862 - mmcv - INFO - \n","backbone.layer2.1.conv2.weight - torch.Size([128, 128, 3, 3]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,862 - mmcv - INFO - \n","backbone.layer2.1.bn2.weight - torch.Size([128]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,862 - mmcv - INFO - \n","backbone.layer2.1.bn2.bias - torch.Size([128]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,862 - mmcv - INFO - \n","backbone.layer2.1.conv3.weight - torch.Size([512, 128, 1, 1]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,862 - mmcv - INFO - \n","backbone.layer2.1.bn3.weight - torch.Size([512]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,862 - mmcv - INFO - \n","backbone.layer2.1.bn3.bias - torch.Size([512]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,862 - mmcv - INFO - \n","backbone.layer2.2.conv1.weight - torch.Size([128, 512, 1, 1]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,862 - mmcv - INFO - \n","backbone.layer2.2.bn1.weight - torch.Size([128]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,862 - mmcv - INFO - \n","backbone.layer2.2.bn1.bias - torch.Size([128]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,862 - mmcv - INFO - \n","backbone.layer2.2.conv2.weight - torch.Size([128, 128, 3, 3]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,862 - mmcv - INFO - \n","backbone.layer2.2.bn2.weight - torch.Size([128]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,862 - mmcv - INFO - \n","backbone.layer2.2.bn2.bias - torch.Size([128]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,862 - mmcv - INFO - \n","backbone.layer2.2.conv3.weight - torch.Size([512, 128, 1, 1]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,862 - mmcv - INFO - \n","backbone.layer2.2.bn3.weight - torch.Size([512]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,862 - mmcv - INFO - \n","backbone.layer2.2.bn3.bias - torch.Size([512]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,862 - mmcv - INFO - \n","backbone.layer2.3.conv1.weight - torch.Size([128, 512, 1, 1]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,863 - mmcv - INFO - \n","backbone.layer2.3.bn1.weight - torch.Size([128]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,863 - mmcv - INFO - \n","backbone.layer2.3.bn1.bias - torch.Size([128]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,863 - mmcv - INFO - \n","backbone.layer2.3.conv2.weight - torch.Size([128, 128, 3, 3]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,863 - mmcv - INFO - \n","backbone.layer2.3.bn2.weight - torch.Size([128]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,863 - mmcv - INFO - \n","backbone.layer2.3.bn2.bias - torch.Size([128]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,863 - mmcv - INFO - \n","backbone.layer2.3.conv3.weight - torch.Size([512, 128, 1, 1]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,863 - mmcv - INFO - \n","backbone.layer2.3.bn3.weight - torch.Size([512]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,863 - mmcv - INFO - \n","backbone.layer2.3.bn3.bias - torch.Size([512]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,863 - mmcv - INFO - \n","backbone.layer3.0.conv1.weight - torch.Size([256, 512, 1, 1]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,863 - mmcv - INFO - \n","backbone.layer3.0.bn1.weight - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,863 - mmcv - INFO - \n","backbone.layer3.0.bn1.bias - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,863 - mmcv - INFO - \n","backbone.layer3.0.conv2.weight - torch.Size([256, 256, 3, 3]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,863 - mmcv - INFO - \n","backbone.layer3.0.bn2.weight - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,863 - mmcv - INFO - \n","backbone.layer3.0.bn2.bias - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,863 - mmcv - INFO - \n","backbone.layer3.0.conv3.weight - torch.Size([1024, 256, 1, 1]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,923 - mmcv - INFO - \n","backbone.layer3.0.bn3.weight - torch.Size([1024]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,923 - mmcv - INFO - \n","backbone.layer3.0.bn3.bias - torch.Size([1024]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,923 - mmcv - INFO - \n","backbone.layer3.0.downsample.0.weight - torch.Size([1024, 512, 1, 1]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,923 - mmcv - INFO - \n","backbone.layer3.0.downsample.1.weight - torch.Size([1024]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,924 - mmcv - INFO - \n","backbone.layer3.0.downsample.1.bias - torch.Size([1024]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,924 - mmcv - INFO - \n","backbone.layer3.1.conv1.weight - torch.Size([256, 1024, 1, 1]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,924 - mmcv - INFO - \n","backbone.layer3.1.bn1.weight - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,924 - mmcv - INFO - \n","backbone.layer3.1.bn1.bias - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,924 - mmcv - INFO - \n","backbone.layer3.1.conv2.weight - torch.Size([256, 256, 3, 3]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,924 - mmcv - INFO - \n","backbone.layer3.1.bn2.weight - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,924 - mmcv - INFO - \n","backbone.layer3.1.bn2.bias - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,924 - mmcv - INFO - \n","backbone.layer3.1.conv3.weight - torch.Size([1024, 256, 1, 1]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,924 - mmcv - INFO - \n","backbone.layer3.1.bn3.weight - torch.Size([1024]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,924 - mmcv - INFO - \n","backbone.layer3.1.bn3.bias - torch.Size([1024]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,924 - mmcv - INFO - \n","backbone.layer3.2.conv1.weight - torch.Size([256, 1024, 1, 1]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,924 - mmcv - INFO - \n","backbone.layer3.2.bn1.weight - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,924 - mmcv - INFO - \n","backbone.layer3.2.bn1.bias - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,924 - mmcv - INFO - \n","backbone.layer3.2.conv2.weight - torch.Size([256, 256, 3, 3]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,925 - mmcv - INFO - \n","backbone.layer3.2.bn2.weight - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,925 - mmcv - INFO - \n","backbone.layer3.2.bn2.bias - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,925 - mmcv - INFO - \n","backbone.layer3.2.conv3.weight - torch.Size([1024, 256, 1, 1]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,925 - mmcv - INFO - \n","backbone.layer3.2.bn3.weight - torch.Size([1024]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,925 - mmcv - INFO - \n","backbone.layer3.2.bn3.bias - torch.Size([1024]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,925 - mmcv - INFO - \n","backbone.layer3.3.conv1.weight - torch.Size([256, 1024, 1, 1]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,925 - mmcv - INFO - \n","backbone.layer3.3.bn1.weight - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,925 - mmcv - INFO - \n","backbone.layer3.3.bn1.bias - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,925 - mmcv - INFO - \n","backbone.layer3.3.conv2.weight - torch.Size([256, 256, 3, 3]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,925 - mmcv - INFO - \n","backbone.layer3.3.bn2.weight - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,925 - mmcv - INFO - \n","backbone.layer3.3.bn2.bias - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,925 - mmcv - INFO - \n","backbone.layer3.3.conv3.weight - torch.Size([1024, 256, 1, 1]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,925 - mmcv - INFO - \n","backbone.layer3.3.bn3.weight - torch.Size([1024]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,925 - mmcv - INFO - \n","backbone.layer3.3.bn3.bias - torch.Size([1024]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,925 - mmcv - INFO - \n","backbone.layer3.4.conv1.weight - torch.Size([256, 1024, 1, 1]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,926 - mmcv - INFO - \n","backbone.layer3.4.bn1.weight - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,926 - mmcv - INFO - \n","backbone.layer3.4.bn1.bias - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,926 - mmcv - INFO - \n","backbone.layer3.4.conv2.weight - torch.Size([256, 256, 3, 3]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,926 - mmcv - INFO - \n","backbone.layer3.4.bn2.weight - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,926 - mmcv - INFO - \n","backbone.layer3.4.bn2.bias - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,926 - mmcv - INFO - \n","backbone.layer3.4.conv3.weight - torch.Size([1024, 256, 1, 1]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,926 - mmcv - INFO - \n","backbone.layer3.4.bn3.weight - torch.Size([1024]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,926 - mmcv - INFO - \n","backbone.layer3.4.bn3.bias - torch.Size([1024]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,926 - mmcv - INFO - \n","backbone.layer3.5.conv1.weight - torch.Size([256, 1024, 1, 1]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,926 - mmcv - INFO - \n","backbone.layer3.5.bn1.weight - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,926 - mmcv - INFO - \n","backbone.layer3.5.bn1.bias - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,926 - mmcv - INFO - \n","backbone.layer3.5.conv2.weight - torch.Size([256, 256, 3, 3]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,926 - mmcv - INFO - \n","backbone.layer3.5.bn2.weight - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,926 - mmcv - INFO - \n","backbone.layer3.5.bn2.bias - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,927 - mmcv - INFO - \n","backbone.layer3.5.conv3.weight - torch.Size([1024, 256, 1, 1]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,927 - mmcv - INFO - \n","backbone.layer3.5.bn3.weight - torch.Size([1024]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,927 - mmcv - INFO - \n","backbone.layer3.5.bn3.bias - torch.Size([1024]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,927 - mmcv - INFO - \n","backbone.layer3.6.conv1.weight - torch.Size([256, 1024, 1, 1]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,927 - mmcv - INFO - \n","backbone.layer3.6.bn1.weight - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,927 - mmcv - INFO - \n","backbone.layer3.6.bn1.bias - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,927 - mmcv - INFO - \n","backbone.layer3.6.conv2.weight - torch.Size([256, 256, 3, 3]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,927 - mmcv - INFO - \n","backbone.layer3.6.bn2.weight - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,927 - mmcv - INFO - \n","backbone.layer3.6.bn2.bias - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,927 - mmcv - INFO - \n","backbone.layer3.6.conv3.weight - torch.Size([1024, 256, 1, 1]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,927 - mmcv - INFO - \n","backbone.layer3.6.bn3.weight - torch.Size([1024]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,927 - mmcv - INFO - \n","backbone.layer3.6.bn3.bias - torch.Size([1024]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,927 - mmcv - INFO - \n","backbone.layer3.7.conv1.weight - torch.Size([256, 1024, 1, 1]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,927 - mmcv - INFO - \n","backbone.layer3.7.bn1.weight - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,927 - mmcv - INFO - \n","backbone.layer3.7.bn1.bias - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,927 - mmcv - INFO - \n","backbone.layer3.7.conv2.weight - torch.Size([256, 256, 3, 3]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,928 - mmcv - INFO - \n","backbone.layer3.7.bn2.weight - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,928 - mmcv - INFO - \n","backbone.layer3.7.bn2.bias - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,928 - mmcv - INFO - \n","backbone.layer3.7.conv3.weight - torch.Size([1024, 256, 1, 1]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,928 - mmcv - INFO - \n","backbone.layer3.7.bn3.weight - torch.Size([1024]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,928 - mmcv - INFO - \n","backbone.layer3.7.bn3.bias - torch.Size([1024]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,928 - mmcv - INFO - \n","backbone.layer3.8.conv1.weight - torch.Size([256, 1024, 1, 1]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,928 - mmcv - INFO - \n","backbone.layer3.8.bn1.weight - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,928 - mmcv - INFO - \n","backbone.layer3.8.bn1.bias - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,928 - mmcv - INFO - \n","backbone.layer3.8.conv2.weight - torch.Size([256, 256, 3, 3]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,928 - mmcv - INFO - \n","backbone.layer3.8.bn2.weight - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,928 - mmcv - INFO - \n","backbone.layer3.8.bn2.bias - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,928 - mmcv - INFO - \n","backbone.layer3.8.conv3.weight - torch.Size([1024, 256, 1, 1]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,928 - mmcv - INFO - \n","backbone.layer3.8.bn3.weight - torch.Size([1024]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,928 - mmcv - INFO - \n","backbone.layer3.8.bn3.bias - torch.Size([1024]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,928 - mmcv - INFO - \n","backbone.layer3.9.conv1.weight - torch.Size([256, 1024, 1, 1]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,929 - mmcv - INFO - \n","backbone.layer3.9.bn1.weight - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,929 - mmcv - INFO - \n","backbone.layer3.9.bn1.bias - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,929 - mmcv - INFO - \n","backbone.layer3.9.conv2.weight - torch.Size([256, 256, 3, 3]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,929 - mmcv - INFO - \n","backbone.layer3.9.bn2.weight - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,929 - mmcv - INFO - \n","backbone.layer3.9.bn2.bias - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:54,929 - mmcv - INFO - \n","backbone.layer3.9.conv3.weight - torch.Size([1024, 256, 1, 1]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,022 - mmcv - INFO - \n","backbone.layer3.9.bn3.weight - torch.Size([1024]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,022 - mmcv - INFO - \n","backbone.layer3.9.bn3.bias - torch.Size([1024]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,022 - mmcv - INFO - \n","backbone.layer3.10.conv1.weight - torch.Size([256, 1024, 1, 1]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,022 - mmcv - INFO - \n","backbone.layer3.10.bn1.weight - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,022 - mmcv - INFO - \n","backbone.layer3.10.bn1.bias - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,022 - mmcv - INFO - \n","backbone.layer3.10.conv2.weight - torch.Size([256, 256, 3, 3]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,023 - mmcv - INFO - \n","backbone.layer3.10.bn2.weight - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,023 - mmcv - INFO - \n","backbone.layer3.10.bn2.bias - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,023 - mmcv - INFO - \n","backbone.layer3.10.conv3.weight - torch.Size([1024, 256, 1, 1]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,023 - mmcv - INFO - \n","backbone.layer3.10.bn3.weight - torch.Size([1024]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,023 - mmcv - INFO - \n","backbone.layer3.10.bn3.bias - torch.Size([1024]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,023 - mmcv - INFO - \n","backbone.layer3.11.conv1.weight - torch.Size([256, 1024, 1, 1]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,023 - mmcv - INFO - \n","backbone.layer3.11.bn1.weight - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,023 - mmcv - INFO - \n","backbone.layer3.11.bn1.bias - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,023 - mmcv - INFO - \n","backbone.layer3.11.conv2.weight - torch.Size([256, 256, 3, 3]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,023 - mmcv - INFO - \n","backbone.layer3.11.bn2.weight - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,023 - mmcv - INFO - \n","backbone.layer3.11.bn2.bias - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,023 - mmcv - INFO - \n","backbone.layer3.11.conv3.weight - torch.Size([1024, 256, 1, 1]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,023 - mmcv - INFO - \n","backbone.layer3.11.bn3.weight - torch.Size([1024]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,023 - mmcv - INFO - \n","backbone.layer3.11.bn3.bias - torch.Size([1024]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,024 - mmcv - INFO - \n","backbone.layer3.12.conv1.weight - torch.Size([256, 1024, 1, 1]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,024 - mmcv - INFO - \n","backbone.layer3.12.bn1.weight - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,024 - mmcv - INFO - \n","backbone.layer3.12.bn1.bias - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,024 - mmcv - INFO - \n","backbone.layer3.12.conv2.weight - torch.Size([256, 256, 3, 3]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,024 - mmcv - INFO - \n","backbone.layer3.12.bn2.weight - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,024 - mmcv - INFO - \n","backbone.layer3.12.bn2.bias - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,024 - mmcv - INFO - \n","backbone.layer3.12.conv3.weight - torch.Size([1024, 256, 1, 1]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,024 - mmcv - INFO - \n","backbone.layer3.12.bn3.weight - torch.Size([1024]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,024 - mmcv - INFO - \n","backbone.layer3.12.bn3.bias - torch.Size([1024]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,024 - mmcv - INFO - \n","backbone.layer3.13.conv1.weight - torch.Size([256, 1024, 1, 1]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,024 - mmcv - INFO - \n","backbone.layer3.13.bn1.weight - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,024 - mmcv - INFO - \n","backbone.layer3.13.bn1.bias - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,025 - mmcv - INFO - \n","backbone.layer3.13.conv2.weight - torch.Size([256, 256, 3, 3]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,025 - mmcv - INFO - \n","backbone.layer3.13.bn2.weight - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,025 - mmcv - INFO - \n","backbone.layer3.13.bn2.bias - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,025 - mmcv - INFO - \n","backbone.layer3.13.conv3.weight - torch.Size([1024, 256, 1, 1]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,025 - mmcv - INFO - \n","backbone.layer3.13.bn3.weight - torch.Size([1024]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,025 - mmcv - INFO - \n","backbone.layer3.13.bn3.bias - torch.Size([1024]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,025 - mmcv - INFO - \n","backbone.layer3.14.conv1.weight - torch.Size([256, 1024, 1, 1]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,025 - mmcv - INFO - \n","backbone.layer3.14.bn1.weight - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,025 - mmcv - INFO - \n","backbone.layer3.14.bn1.bias - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,025 - mmcv - INFO - \n","backbone.layer3.14.conv2.weight - torch.Size([256, 256, 3, 3]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,025 - mmcv - INFO - \n","backbone.layer3.14.bn2.weight - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,025 - mmcv - INFO - \n","backbone.layer3.14.bn2.bias - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,025 - mmcv - INFO - \n","backbone.layer3.14.conv3.weight - torch.Size([1024, 256, 1, 1]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,026 - mmcv - INFO - \n","backbone.layer3.14.bn3.weight - torch.Size([1024]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,026 - mmcv - INFO - \n","backbone.layer3.14.bn3.bias - torch.Size([1024]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,026 - mmcv - INFO - \n","backbone.layer3.15.conv1.weight - torch.Size([256, 1024, 1, 1]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,026 - mmcv - INFO - \n","backbone.layer3.15.bn1.weight - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,026 - mmcv - INFO - \n","backbone.layer3.15.bn1.bias - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,026 - mmcv - INFO - \n","backbone.layer3.15.conv2.weight - torch.Size([256, 256, 3, 3]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,026 - mmcv - INFO - \n","backbone.layer3.15.bn2.weight - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,026 - mmcv - INFO - \n","backbone.layer3.15.bn2.bias - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,026 - mmcv - INFO - \n","backbone.layer3.15.conv3.weight - torch.Size([1024, 256, 1, 1]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,026 - mmcv - INFO - \n","backbone.layer3.15.bn3.weight - torch.Size([1024]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,026 - mmcv - INFO - \n","backbone.layer3.15.bn3.bias - torch.Size([1024]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,026 - mmcv - INFO - \n","backbone.layer3.16.conv1.weight - torch.Size([256, 1024, 1, 1]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,027 - mmcv - INFO - \n","backbone.layer3.16.bn1.weight - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,027 - mmcv - INFO - \n","backbone.layer3.16.bn1.bias - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,027 - mmcv - INFO - \n","backbone.layer3.16.conv2.weight - torch.Size([256, 256, 3, 3]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,027 - mmcv - INFO - \n","backbone.layer3.16.bn2.weight - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,027 - mmcv - INFO - \n","backbone.layer3.16.bn2.bias - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,027 - mmcv - INFO - \n","backbone.layer3.16.conv3.weight - torch.Size([1024, 256, 1, 1]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,027 - mmcv - INFO - \n","backbone.layer3.16.bn3.weight - torch.Size([1024]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,027 - mmcv - INFO - \n","backbone.layer3.16.bn3.bias - torch.Size([1024]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,027 - mmcv - INFO - \n","backbone.layer3.17.conv1.weight - torch.Size([256, 1024, 1, 1]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,027 - mmcv - INFO - \n","backbone.layer3.17.bn1.weight - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,027 - mmcv - INFO - \n","backbone.layer3.17.bn1.bias - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,030 - mmcv - INFO - \n","backbone.layer3.17.conv2.weight - torch.Size([256, 256, 3, 3]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,030 - mmcv - INFO - \n","backbone.layer3.17.bn2.weight - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,030 - mmcv - INFO - \n","backbone.layer3.17.bn2.bias - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,030 - mmcv - INFO - \n","backbone.layer3.17.conv3.weight - torch.Size([1024, 256, 1, 1]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,030 - mmcv - INFO - \n","backbone.layer3.17.bn3.weight - torch.Size([1024]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,030 - mmcv - INFO - \n","backbone.layer3.17.bn3.bias - torch.Size([1024]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,031 - mmcv - INFO - \n","backbone.layer3.18.conv1.weight - torch.Size([256, 1024, 1, 1]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,031 - mmcv - INFO - \n","backbone.layer3.18.bn1.weight - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,031 - mmcv - INFO - \n","backbone.layer3.18.bn1.bias - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,031 - mmcv - INFO - \n","backbone.layer3.18.conv2.weight - torch.Size([256, 256, 3, 3]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,031 - mmcv - INFO - \n","backbone.layer3.18.bn2.weight - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,031 - mmcv - INFO - \n","backbone.layer3.18.bn2.bias - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,031 - mmcv - INFO - \n","backbone.layer3.18.conv3.weight - torch.Size([1024, 256, 1, 1]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,031 - mmcv - INFO - \n","backbone.layer3.18.bn3.weight - torch.Size([1024]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,031 - mmcv - INFO - \n","backbone.layer3.18.bn3.bias - torch.Size([1024]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,031 - mmcv - INFO - \n","backbone.layer3.19.conv1.weight - torch.Size([256, 1024, 1, 1]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,031 - mmcv - INFO - \n","backbone.layer3.19.bn1.weight - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,031 - mmcv - INFO - \n","backbone.layer3.19.bn1.bias - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,032 - mmcv - INFO - \n","backbone.layer3.19.conv2.weight - torch.Size([256, 256, 3, 3]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,032 - mmcv - INFO - \n","backbone.layer3.19.bn2.weight - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,032 - mmcv - INFO - \n","backbone.layer3.19.bn2.bias - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,032 - mmcv - INFO - \n","backbone.layer3.19.conv3.weight - torch.Size([1024, 256, 1, 1]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,032 - mmcv - INFO - \n","backbone.layer3.19.bn3.weight - torch.Size([1024]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,032 - mmcv - INFO - \n","backbone.layer3.19.bn3.bias - torch.Size([1024]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,032 - mmcv - INFO - \n","backbone.layer3.20.conv1.weight - torch.Size([256, 1024, 1, 1]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,032 - mmcv - INFO - \n","backbone.layer3.20.bn1.weight - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,032 - mmcv - INFO - \n","backbone.layer3.20.bn1.bias - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,032 - mmcv - INFO - \n","backbone.layer3.20.conv2.weight - torch.Size([256, 256, 3, 3]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,032 - mmcv - INFO - \n","backbone.layer3.20.bn2.weight - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,032 - mmcv - INFO - \n","backbone.layer3.20.bn2.bias - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,032 - mmcv - INFO - \n","backbone.layer3.20.conv3.weight - torch.Size([1024, 256, 1, 1]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,033 - mmcv - INFO - \n","backbone.layer3.20.bn3.weight - torch.Size([1024]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,033 - mmcv - INFO - \n","backbone.layer3.20.bn3.bias - torch.Size([1024]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,033 - mmcv - INFO - \n","backbone.layer3.21.conv1.weight - torch.Size([256, 1024, 1, 1]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,033 - mmcv - INFO - \n","backbone.layer3.21.bn1.weight - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,033 - mmcv - INFO - \n","backbone.layer3.21.bn1.bias - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,033 - mmcv - INFO - \n","backbone.layer3.21.conv2.weight - torch.Size([256, 256, 3, 3]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,033 - mmcv - INFO - \n","backbone.layer3.21.bn2.weight - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,033 - mmcv - INFO - \n","backbone.layer3.21.bn2.bias - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,033 - mmcv - INFO - \n","backbone.layer3.21.conv3.weight - torch.Size([1024, 256, 1, 1]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,033 - mmcv - INFO - \n","backbone.layer3.21.bn3.weight - torch.Size([1024]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,033 - mmcv - INFO - \n","backbone.layer3.21.bn3.bias - torch.Size([1024]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,033 - mmcv - INFO - \n","backbone.layer3.22.conv1.weight - torch.Size([256, 1024, 1, 1]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,033 - mmcv - INFO - \n","backbone.layer3.22.bn1.weight - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,034 - mmcv - INFO - \n","backbone.layer3.22.bn1.bias - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,034 - mmcv - INFO - \n","backbone.layer3.22.conv2.weight - torch.Size([256, 256, 3, 3]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,034 - mmcv - INFO - \n","backbone.layer3.22.bn2.weight - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,034 - mmcv - INFO - \n","backbone.layer3.22.bn2.bias - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,034 - mmcv - INFO - \n","backbone.layer3.22.conv3.weight - torch.Size([1024, 256, 1, 1]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,034 - mmcv - INFO - \n","backbone.layer3.22.bn3.weight - torch.Size([1024]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,034 - mmcv - INFO - \n","backbone.layer3.22.bn3.bias - torch.Size([1024]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,034 - mmcv - INFO - \n","backbone.layer4.0.conv1.weight - torch.Size([512, 1024, 1, 1]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,034 - mmcv - INFO - \n","backbone.layer4.0.bn1.weight - torch.Size([512]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,034 - mmcv - INFO - \n","backbone.layer4.0.bn1.bias - torch.Size([512]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,034 - mmcv - INFO - \n","backbone.layer4.0.conv2.weight - torch.Size([512, 512, 3, 3]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,034 - mmcv - INFO - \n","backbone.layer4.0.bn2.weight - torch.Size([512]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,034 - mmcv - INFO - \n","backbone.layer4.0.bn2.bias - torch.Size([512]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,035 - mmcv - INFO - \n","backbone.layer4.0.conv3.weight - torch.Size([2048, 512, 1, 1]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,035 - mmcv - INFO - \n","backbone.layer4.0.bn3.weight - torch.Size([2048]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,035 - mmcv - INFO - \n","backbone.layer4.0.bn3.bias - torch.Size([2048]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,035 - mmcv - INFO - \n","backbone.layer4.0.downsample.0.weight - torch.Size([2048, 1024, 1, 1]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,035 - mmcv - INFO - \n","backbone.layer4.0.downsample.1.weight - torch.Size([2048]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,035 - mmcv - INFO - \n","backbone.layer4.0.downsample.1.bias - torch.Size([2048]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,035 - mmcv - INFO - \n","backbone.layer4.1.conv1.weight - torch.Size([512, 2048, 1, 1]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,035 - mmcv - INFO - \n","backbone.layer4.1.bn1.weight - torch.Size([512]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,035 - mmcv - INFO - \n","backbone.layer4.1.bn1.bias - torch.Size([512]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,035 - mmcv - INFO - \n","backbone.layer4.1.conv2.weight - torch.Size([512, 512, 3, 3]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,035 - mmcv - INFO - \n","backbone.layer4.1.bn2.weight - torch.Size([512]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,035 - mmcv - INFO - \n","backbone.layer4.1.bn2.bias - torch.Size([512]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,036 - mmcv - INFO - \n","backbone.layer4.1.conv3.weight - torch.Size([2048, 512, 1, 1]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,036 - mmcv - INFO - \n","backbone.layer4.1.bn3.weight - torch.Size([2048]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,036 - mmcv - INFO - \n","backbone.layer4.1.bn3.bias - torch.Size([2048]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,036 - mmcv - INFO - \n","backbone.layer4.2.conv1.weight - torch.Size([512, 2048, 1, 1]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,036 - mmcv - INFO - \n","backbone.layer4.2.bn1.weight - torch.Size([512]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,036 - mmcv - INFO - \n","backbone.layer4.2.bn1.bias - torch.Size([512]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,036 - mmcv - INFO - \n","backbone.layer4.2.conv2.weight - torch.Size([512, 512, 3, 3]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,036 - mmcv - INFO - \n","backbone.layer4.2.bn2.weight - torch.Size([512]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,036 - mmcv - INFO - \n","backbone.layer4.2.bn2.bias - torch.Size([512]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,036 - mmcv - INFO - \n","backbone.layer4.2.conv3.weight - torch.Size([2048, 512, 1, 1]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,036 - mmcv - INFO - \n","backbone.layer4.2.bn3.weight - torch.Size([2048]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,036 - mmcv - INFO - \n","backbone.layer4.2.bn3.bias - torch.Size([2048]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,036 - mmcv - INFO - \n","decode_head.conv_seg.weight - torch.Size([5, 512, 1, 1]): \n","NormalInit: mean=0, std=0.01, bias=0 \n"," \n","2023-01-05 04:52:55,036 - mmcv - INFO - \n","decode_head.conv_seg.bias - torch.Size([5]): \n","NormalInit: mean=0, std=0.01, bias=0 \n"," \n","2023-01-05 04:52:55,036 - mmcv - INFO - \n","decode_head.psp_modules.0.1.conv.weight - torch.Size([512, 2048, 1, 1]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,036 - mmcv - INFO - \n","decode_head.psp_modules.0.1.bn.weight - torch.Size([512]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,037 - mmcv - INFO - \n","decode_head.psp_modules.0.1.bn.bias - torch.Size([512]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,037 - mmcv - INFO - \n","decode_head.psp_modules.1.1.conv.weight - torch.Size([512, 2048, 1, 1]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,038 - mmcv - INFO - \n","decode_head.psp_modules.1.1.bn.weight - torch.Size([512]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,038 - mmcv - INFO - \n","decode_head.psp_modules.1.1.bn.bias - torch.Size([512]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,038 - mmcv - INFO - \n","decode_head.psp_modules.2.1.conv.weight - torch.Size([512, 2048, 1, 1]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,038 - mmcv - INFO - \n","decode_head.psp_modules.2.1.bn.weight - torch.Size([512]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,038 - mmcv - INFO - \n","decode_head.psp_modules.2.1.bn.bias - torch.Size([512]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,038 - mmcv - INFO - \n","decode_head.psp_modules.3.1.conv.weight - torch.Size([512, 2048, 1, 1]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,038 - mmcv - INFO - \n","decode_head.psp_modules.3.1.bn.weight - torch.Size([512]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,038 - mmcv - INFO - \n","decode_head.psp_modules.3.1.bn.bias - torch.Size([512]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,038 - mmcv - INFO - \n","decode_head.bottleneck.conv.weight - torch.Size([512, 4096, 3, 3]): \n","Initialized by user-defined `init_weights` in ConvModule  \n"," \n","2023-01-05 04:52:55,038 - mmcv - INFO - \n","decode_head.bottleneck.bn.weight - torch.Size([512]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,039 - mmcv - INFO - \n","decode_head.bottleneck.bn.bias - torch.Size([512]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,039 - mmcv - INFO - \n","auxiliary_head.conv_seg.weight - torch.Size([5, 256, 1, 1]): \n","NormalInit: mean=0, std=0.01, bias=0 \n"," \n","2023-01-05 04:52:55,039 - mmcv - INFO - \n","auxiliary_head.conv_seg.bias - torch.Size([5]): \n","NormalInit: mean=0, std=0.01, bias=0 \n"," \n","2023-01-05 04:52:55,039 - mmcv - INFO - \n","auxiliary_head.convs.0.conv.weight - torch.Size([256, 1024, 3, 3]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,039 - mmcv - INFO - \n","auxiliary_head.convs.0.bn.weight - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,040 - mmcv - INFO - \n","auxiliary_head.convs.0.bn.bias - torch.Size([256]): \n","The value is the same before and after calling `init_weights` of EncoderDecoder  \n"," \n","2023-01-05 04:52:55,043 - mmseg - INFO - EncoderDecoder(\n","  (backbone): ResNetV1c(\n","    (stem): Sequential(\n","      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (1): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU(inplace=True)\n","      (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (4): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (5): ReLU(inplace=True)\n","      (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (7): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (8): ReLU(inplace=True)\n","    )\n","    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","    (layer1): ResLayer(\n","      (0): Bottleneck(\n","        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): Bottleneck(\n","        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (2): Bottleneck(\n","        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","    )\n","    (layer2): ResLayer(\n","      (0): Bottleneck(\n","        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (2): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (3): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","    )\n","    (layer3): ResLayer(\n","      (0): Bottleneck(\n","        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (2): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (3): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (4): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (5): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (6): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (7): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (8): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (9): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (10): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (11): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (12): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (13): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (14): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (15): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (16): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (17): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (18): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (19): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (20): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (21): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (22): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","    )\n","    (layer4): ResLayer(\n","      (0): Bottleneck(\n","        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): Bottleneck(\n","        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n","        (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (2): Bottleneck(\n","        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n","        (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","    )\n","  )\n","  init_cfg={'type': 'Pretrained', 'checkpoint': 'https://download.openmmlab.com/mmsegmentation/v0.5/pspnet/pspnet_r101-d8_512x512_80k_ade20k/pspnet_r101-d8_512x512_80k_ade20k_20200614_031423-b6e782f0.pth'}\n","  (decode_head): PSPHead(\n","    input_transform=None, ignore_index=255, align_corners=False\n","    (loss_decode): CrossEntropyLoss(avg_non_ignore=False)\n","    (conv_seg): Conv2d(512, 5, kernel_size=(1, 1), stride=(1, 1))\n","    (dropout): Dropout2d(p=0.1, inplace=False)\n","    (psp_modules): PPM(\n","      (0): Sequential(\n","        (0): AdaptiveAvgPool2d(output_size=1)\n","        (1): ConvModule(\n","          (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (activate): ReLU(inplace=True)\n","        )\n","      )\n","      (1): Sequential(\n","        (0): AdaptiveAvgPool2d(output_size=2)\n","        (1): ConvModule(\n","          (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (activate): ReLU(inplace=True)\n","        )\n","      )\n","      (2): Sequential(\n","        (0): AdaptiveAvgPool2d(output_size=3)\n","        (1): ConvModule(\n","          (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (activate): ReLU(inplace=True)\n","        )\n","      )\n","      (3): Sequential(\n","        (0): AdaptiveAvgPool2d(output_size=6)\n","        (1): ConvModule(\n","          (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (activate): ReLU(inplace=True)\n","        )\n","      )\n","    )\n","    (bottleneck): ConvModule(\n","      (conv): Conv2d(4096, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (activate): ReLU(inplace=True)\n","    )\n","  )\n","  init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}\n","  (auxiliary_head): FCNHead(\n","    input_transform=None, ignore_index=255, align_corners=False\n","    (loss_decode): CrossEntropyLoss(avg_non_ignore=False)\n","    (conv_seg): Conv2d(256, 5, kernel_size=(1, 1), stride=(1, 1))\n","    (dropout): Dropout2d(p=0.1, inplace=False)\n","    (convs): Sequential(\n","      (0): ConvModule(\n","        (conv): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (activate): ReLU(inplace=True)\n","      )\n","    )\n","  )\n","  init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}\n",")\n","2023-01-05 04:52:58,197 - mmseg - INFO - Loaded 288 images\n","/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","2023-01-05 04:53:03,786 - mmseg - INFO - Loaded 36 images\n","2023-01-05 04:53:03,787 - mmseg - INFO - load checkpoint from local path: /content/drive/MyDrive/catfish/tianqi/code/mmsegmentation/checkpoints_pspnet/iter_68000.pth\n","2023-01-05 04:53:27,147 - mmseg - INFO - resumed from epoch: 487, iter 67999\n","2023-01-05 04:53:27,149 - mmseg - INFO - Start running, host: root@5a129970329c, work_dir: /content/drive/MyDrive/catfish/tianqi/code/mmsegmentation/checkpoints_pspnet\n","2023-01-05 04:53:27,149 - mmseg - INFO - Hooks will be executed in the following order:\n","before_run:\n","(VERY_HIGH   ) PolyLrUpdaterHook                  \n","(NORMAL      ) CheckpointHook                     \n","(LOW         ) DistEvalHook                       \n","(VERY_LOW    ) TextLoggerHook                     \n"," -------------------- \n","before_train_epoch:\n","(VERY_HIGH   ) PolyLrUpdaterHook                  \n","(LOW         ) IterTimerHook                      \n","(LOW         ) DistEvalHook                       \n","(VERY_LOW    ) TextLoggerHook                     \n"," -------------------- \n","before_train_iter:\n","(VERY_HIGH   ) PolyLrUpdaterHook                  \n","(LOW         ) IterTimerHook                      \n","(LOW         ) DistEvalHook                       \n"," -------------------- \n","after_train_iter:\n","(ABOVE_NORMAL) OptimizerHook                      \n","(NORMAL      ) CheckpointHook                     \n","(LOW         ) IterTimerHook                      \n","(LOW         ) DistEvalHook                       \n","(VERY_LOW    ) TextLoggerHook                     \n"," -------------------- \n","after_train_epoch:\n","(NORMAL      ) CheckpointHook                     \n","(LOW         ) DistEvalHook                       \n","(VERY_LOW    ) TextLoggerHook                     \n"," -------------------- \n","before_val_epoch:\n","(LOW         ) IterTimerHook                      \n","(VERY_LOW    ) TextLoggerHook                     \n"," -------------------- \n","before_val_iter:\n","(LOW         ) IterTimerHook                      \n"," -------------------- \n","after_val_iter:\n","(LOW         ) IterTimerHook                      \n"," -------------------- \n","after_val_epoch:\n","(VERY_LOW    ) TextLoggerHook                     \n"," -------------------- \n","after_run:\n","(VERY_LOW    ) TextLoggerHook                     \n"," -------------------- \n","2023-01-05 04:53:27,149 - mmseg - INFO - workflow: [('train', 1)], max: 80000 iters\n","2023-01-05 04:53:27,150 - mmseg - INFO - Checkpoints will be saved to /content/drive/MyDrive/catfish/tianqi/code/mmsegmentation/checkpoints_pspnet by HardDiskBackend.\n","/usr/local/lib/python3.8/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n","  warnings.warn(\n","2023-01-05 04:53:56,203 - mmseg - INFO - Saving checkpoint at 68000 iterations\n","2023-01-05 04:54:00,488 - mmseg - INFO - Exp name: my_pspnet_r101-d8_512x512_80k_ade20k.py\n","2023-01-05 04:54:00,488 - mmseg - INFO - Iter [68000/80000]\tlr: 1.895e-03, eta: 230 days, 4:24:33, time: 33.146, data_time: 18.257, memory: 8914, decode.loss_ce: 0.0158, decode.acc_seg: 99.2143, aux.loss_ce: 0.0069, aux.acc_seg: 99.1996, loss: 0.0227\n","[                                                  ] 0/36, elapsed: 0s, ETA:/usr/local/lib/python3.8/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n","  warnings.warn(\n","[>>] 36/36, 0.9 task/s, elapsed: 41s, ETA:     0s\n","\n","2023-01-05 04:54:41,059 - mmseg - INFO - per class results:\n","2023-01-05 04:54:41,060 - mmseg - INFO - \n","+------------+-------+-------+-------+--------+-----------+--------+\n","|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |\n","+------------+-------+-------+-------+--------+-----------+--------+\n","| Background | 99.27 | 99.71 | 99.63 | 99.63  |   99.56   | 99.71  |\n","|    Head    | 91.59 | 96.01 | 95.61 | 95.61  |   95.22   | 96.01  |\n","|    Body    |  94.3 | 96.81 | 97.07 | 97.07  |   97.32   | 96.81  |\n","|    Fins    | 79.16 | 86.85 | 88.37 | 88.37  |   89.94   | 86.85  |\n","|    Tail    | 83.58 |  90.1 | 91.05 | 91.05  |   92.03   |  90.1  |\n","+------------+-------+-------+-------+--------+-----------+--------+\n","2023-01-05 04:54:41,061 - mmseg - INFO - Summary:\n","2023-01-05 04:54:41,061 - mmseg - INFO - \n","+-------+-------+------+-------+---------+------------+---------+\n","|  aAcc |  mIoU | mAcc | mDice | mFscore | mPrecision | mRecall |\n","+-------+-------+------+-------+---------+------------+---------+\n","| 98.96 | 89.58 | 93.9 | 94.35 |  94.35  |   94.81    |   93.9  |\n","+-------+-------+------+-------+---------+------------+---------+\n","2023-01-05 04:54:41,062 - mmseg - INFO - Exp name: my_pspnet_r101-d8_512x512_80k_ade20k.py\n","2023-01-05 04:54:41,062 - mmseg - INFO - Iter(val) [36]\taAcc: 0.9896, mIoU: 0.8958, mAcc: 0.9390, mDice: 0.9435, mFscore: 0.9435, mPrecision: 0.9481, mRecall: 0.9390, IoU.Background: 0.9927, IoU.Head: 0.9159, IoU.Body: 0.9430, IoU.Fins: 0.7916, IoU.Tail: 0.8358, Acc.Background: 0.9971, Acc.Head: 0.9601, Acc.Body: 0.9681, Acc.Fins: 0.8685, Acc.Tail: 0.9010, Dice.Background: 0.9963, Dice.Head: 0.9561, Dice.Body: 0.9707, Dice.Fins: 0.8837, Dice.Tail: 0.9105, Fscore.Background: 0.9963, Fscore.Head: 0.9561, Fscore.Body: 0.9707, Fscore.Fins: 0.8837, Fscore.Tail: 0.9105, Precision.Background: 0.9956, Precision.Head: 0.9522, Precision.Body: 0.9732, Precision.Fins: 0.8994, Precision.Tail: 0.9203, Recall.Background: 0.9971, Recall.Head: 0.9601, Recall.Body: 0.9681, Recall.Fins: 0.8685, Recall.Tail: 0.9010\n","2023-01-05 04:54:41,077 - mmcv - INFO - Reducer buckets have been rebuilt in this iteration.\n","2023-01-05 04:56:38,493 - mmseg - INFO - Iter [68050/80000]\tlr: 1.889e-03, eta: 4 days, 22:09:13, time: 3.160, data_time: 0.818, memory: 9169, decode.loss_ce: 0.0152, decode.acc_seg: 99.3370, aux.loss_ce: 0.0072, aux.acc_seg: 99.2837, loss: 0.0223\n","2023-01-05 04:58:40,557 - mmseg - INFO - Iter [68100/80000]\tlr: 1.882e-03, eta: 2 days, 15:24:25, time: 2.441, data_time: 0.064, memory: 9169, decode.loss_ce: 0.0151, decode.acc_seg: 99.3240, aux.loss_ce: 0.0072, aux.acc_seg: 99.2677, loss: 0.0223\n","2023-01-05 05:00:42,695 - mmseg - INFO - Iter [68150/80000]\tlr: 1.875e-03, eta: 1 day, 20:53:44, time: 2.443, data_time: 0.069, memory: 9169, decode.loss_ce: 0.0146, decode.acc_seg: 99.3464, aux.loss_ce: 0.0068, aux.acc_seg: 99.2951, loss: 0.0215\n","2023-01-05 05:02:41,965 - mmseg - INFO - Iter [68200/80000]\tlr: 1.868e-03, eta: 1 day, 11:31:48, time: 2.385, data_time: 0.007, memory: 9169, decode.loss_ce: 0.0147, decode.acc_seg: 99.3143, aux.loss_ce: 0.0070, aux.acc_seg: 99.2530, loss: 0.0217\n","2023-01-05 05:04:43,659 - mmseg - INFO - Iter [68250/80000]\tlr: 1.862e-03, eta: 1 day, 5:54:51, time: 2.434, data_time: 0.058, memory: 9169, decode.loss_ce: 0.0150, decode.acc_seg: 99.3148, aux.loss_ce: 0.0071, aux.acc_seg: 99.2554, loss: 0.0221\n","2023-01-05 05:06:45,474 - mmseg - INFO - Iter [68300/80000]\tlr: 1.855e-03, eta: 1 day, 2:09:15, time: 2.436, data_time: 0.059, memory: 9169, decode.loss_ce: 0.0153, decode.acc_seg: 99.3342, aux.loss_ce: 0.0072, aux.acc_seg: 99.2804, loss: 0.0225\n","2023-01-05 05:08:44,312 - mmseg - INFO - Iter [68350/80000]\tlr: 1.848e-03, eta: 23:25:42, time: 2.377, data_time: 0.005, memory: 9169, decode.loss_ce: 0.0145, decode.acc_seg: 99.3583, aux.loss_ce: 0.0068, aux.acc_seg: 99.3072, loss: 0.0214\n","2023-01-05 05:10:45,957 - mmseg - INFO - Iter [68400/80000]\tlr: 1.841e-03, eta: 21:23:48, time: 2.433, data_time: 0.057, memory: 9169, decode.loss_ce: 0.0145, decode.acc_seg: 99.3557, aux.loss_ce: 0.0069, aux.acc_seg: 99.2995, loss: 0.0214\n","2023-01-05 05:12:47,620 - mmseg - INFO - Iter [68450/80000]\tlr: 1.835e-03, eta: 19:48:28, time: 2.433, data_time: 0.058, memory: 9169, decode.loss_ce: 0.0147, decode.acc_seg: 99.3381, aux.loss_ce: 0.0070, aux.acc_seg: 99.2788, loss: 0.0217\n","2023-01-05 05:14:46,674 - mmseg - INFO - Iter [68500/80000]\tlr: 1.828e-03, eta: 18:30:47, time: 2.381, data_time: 0.006, memory: 9169, decode.loss_ce: 0.0150, decode.acc_seg: 99.3247, aux.loss_ce: 0.0071, aux.acc_seg: 99.2712, loss: 0.0221\n","2023-01-05 05:16:48,293 - mmseg - INFO - Iter [68550/80000]\tlr: 1.821e-03, eta: 17:27:43, time: 2.432, data_time: 0.058, memory: 9169, decode.loss_ce: 0.0147, decode.acc_seg: 99.3481, aux.loss_ce: 0.0070, aux.acc_seg: 99.2917, loss: 0.0217\n","2023-01-05 05:18:50,198 - mmseg - INFO - Iter [68600/80000]\tlr: 1.814e-03, eta: 16:34:53, time: 2.438, data_time: 0.062, memory: 9169, decode.loss_ce: 0.0150, decode.acc_seg: 99.3520, aux.loss_ce: 0.0072, aux.acc_seg: 99.3001, loss: 0.0222\n","2023-01-05 05:20:52,009 - mmseg - INFO - Iter [68650/80000]\tlr: 1.808e-03, eta: 15:49:51, time: 2.436, data_time: 0.060, memory: 9169, decode.loss_ce: 0.0152, decode.acc_seg: 99.3467, aux.loss_ce: 0.0072, aux.acc_seg: 99.2970, loss: 0.0224\n","2023-01-05 05:22:50,947 - mmseg - INFO - Iter [68700/80000]\tlr: 1.801e-03, eta: 15:10:10, time: 2.379, data_time: 0.006, memory: 9169, decode.loss_ce: 0.0146, decode.acc_seg: 99.3446, aux.loss_ce: 0.0068, aux.acc_seg: 99.2900, loss: 0.0214\n","2023-01-05 05:24:53,065 - mmseg - INFO - Iter [68750/80000]\tlr: 1.794e-03, eta: 14:36:18, time: 2.442, data_time: 0.066, memory: 9169, decode.loss_ce: 0.0150, decode.acc_seg: 99.3351, aux.loss_ce: 0.0071, aux.acc_seg: 99.2862, loss: 0.0221\n","2023-01-05 05:26:54,778 - mmseg - INFO - Iter [68800/80000]\tlr: 1.787e-03, eta: 14:06:18, time: 2.434, data_time: 0.061, memory: 9169, decode.loss_ce: 0.0145, decode.acc_seg: 99.3364, aux.loss_ce: 0.0068, aux.acc_seg: 99.2748, loss: 0.0213\n","2023-01-05 05:28:53,795 - mmseg - INFO - Iter [68850/80000]\tlr: 1.780e-03, eta: 13:39:01, time: 2.380, data_time: 0.007, memory: 9169, decode.loss_ce: 0.0145, decode.acc_seg: 99.3385, aux.loss_ce: 0.0068, aux.acc_seg: 99.2835, loss: 0.0214\n","2023-01-05 05:30:55,174 - mmseg - INFO - Iter [68900/80000]\tlr: 1.774e-03, eta: 13:15:01, time: 2.428, data_time: 0.053, memory: 9169, decode.loss_ce: 0.0152, decode.acc_seg: 99.3440, aux.loss_ce: 0.0072, aux.acc_seg: 99.2944, loss: 0.0224\n","2023-01-05 05:32:57,450 - mmseg - INFO - Iter [68950/80000]\tlr: 1.767e-03, eta: 12:53:30, time: 2.446, data_time: 0.067, memory: 9169, decode.loss_ce: 0.0150, decode.acc_seg: 99.3490, aux.loss_ce: 0.0072, aux.acc_seg: 99.2959, loss: 0.0223\n","2023-01-05 05:34:56,307 - mmseg - INFO - Saving checkpoint at 69000 iterations\n","2023-01-05 05:34:59,848 - mmseg - INFO - Exp name: my_pspnet_r101-d8_512x512_80k_ade20k.py\n","2023-01-05 05:34:59,848 - mmseg - INFO - Iter [69000/80000]\tlr: 1.760e-03, eta: 12:33:58, time: 2.448, data_time: 0.006, memory: 9169, decode.loss_ce: 0.0146, decode.acc_seg: 99.3612, aux.loss_ce: 0.0070, aux.acc_seg: 99.3049, loss: 0.0216\n","[>>] 36/36, 3.5 task/s, elapsed: 10s, ETA:     0s\n","\n","2023-01-05 05:35:10,240 - mmseg - INFO - per class results:\n","2023-01-05 05:35:10,241 - mmseg - INFO - \n","+------------+-------+-------+-------+--------+-----------+--------+\n","|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |\n","+------------+-------+-------+-------+--------+-----------+--------+\n","| Background | 99.28 | 99.72 | 99.64 | 99.64  |   99.55   | 99.72  |\n","|    Head    | 91.52 | 96.06 | 95.57 | 95.57  |   95.09   | 96.06  |\n","|    Body    | 94.21 | 96.63 | 97.02 | 97.02  |   97.41   | 96.63  |\n","|    Fins    | 79.38 | 87.23 |  88.5 |  88.5  |   89.81   | 87.23  |\n","|    Tail    | 83.55 | 89.87 | 91.04 | 91.04  |   92.23   | 89.87  |\n","+------------+-------+-------+-------+--------+-----------+--------+\n","2023-01-05 05:35:10,241 - mmseg - INFO - Summary:\n","2023-01-05 05:35:10,242 - mmseg - INFO - \n","+-------+-------+------+-------+---------+------------+---------+\n","|  aAcc |  mIoU | mAcc | mDice | mFscore | mPrecision | mRecall |\n","+-------+-------+------+-------+---------+------------+---------+\n","| 98.96 | 89.59 | 93.9 | 94.35 |  94.35  |   94.82    |   93.9  |\n","+-------+-------+------+-------+---------+------------+---------+\n","2023-01-05 05:35:10,242 - mmseg - INFO - Exp name: my_pspnet_r101-d8_512x512_80k_ade20k.py\n","2023-01-05 05:35:10,242 - mmseg - INFO - Iter(val) [36]\taAcc: 0.9896, mIoU: 0.8959, mAcc: 0.9390, mDice: 0.9435, mFscore: 0.9435, mPrecision: 0.9482, mRecall: 0.9390, IoU.Background: 0.9928, IoU.Head: 0.9152, IoU.Body: 0.9421, IoU.Fins: 0.7938, IoU.Tail: 0.8355, Acc.Background: 0.9972, Acc.Head: 0.9606, Acc.Body: 0.9663, Acc.Fins: 0.8723, Acc.Tail: 0.8987, Dice.Background: 0.9964, Dice.Head: 0.9557, Dice.Body: 0.9702, Dice.Fins: 0.8850, Dice.Tail: 0.9104, Fscore.Background: 0.9964, Fscore.Head: 0.9557, Fscore.Body: 0.9702, Fscore.Fins: 0.8850, Fscore.Tail: 0.9104, Precision.Background: 0.9955, Precision.Head: 0.9509, Precision.Body: 0.9741, Precision.Fins: 0.8981, Precision.Tail: 0.9223, Recall.Background: 0.9972, Recall.Head: 0.9606, Recall.Body: 0.9663, Recall.Fins: 0.8723, Recall.Tail: 0.8987\n","2023-01-05 05:37:11,952 - mmseg - INFO - Iter [69050/80000]\tlr: 1.753e-03, eta: 12:17:46, time: 2.642, data_time: 0.266, memory: 9169, decode.loss_ce: 0.0142, decode.acc_seg: 99.3416, aux.loss_ce: 0.0067, aux.acc_seg: 99.2827, loss: 0.0209\n","2023-01-05 05:39:13,679 - mmseg - INFO - Iter [69100/80000]\tlr: 1.747e-03, eta: 12:01:08, time: 2.435, data_time: 0.060, memory: 9169, decode.loss_ce: 0.0143, decode.acc_seg: 99.3637, aux.loss_ce: 0.0067, aux.acc_seg: 99.3163, loss: 0.0210\n","2023-01-05 05:41:12,619 - mmseg - INFO - Iter [69150/80000]\tlr: 1.740e-03, eta: 11:45:20, time: 2.379, data_time: 0.006, memory: 9169, decode.loss_ce: 0.0145, decode.acc_seg: 99.3467, aux.loss_ce: 0.0069, aux.acc_seg: 99.2939, loss: 0.0214\n","2023-01-05 05:43:14,267 - mmseg - INFO - Iter [69200/80000]\tlr: 1.733e-03, eta: 11:31:05, time: 2.433, data_time: 0.057, memory: 9169, decode.loss_ce: 0.0151, decode.acc_seg: 99.3112, aux.loss_ce: 0.0073, aux.acc_seg: 99.2406, loss: 0.0224\n","2023-01-05 05:45:16,296 - mmseg - INFO - Iter [69250/80000]\tlr: 1.726e-03, eta: 11:17:52, time: 2.441, data_time: 0.062, memory: 9169, decode.loss_ce: 0.0152, decode.acc_seg: 99.3442, aux.loss_ce: 0.0073, aux.acc_seg: 99.2797, loss: 0.0225\n","2023-01-05 05:47:17,773 - mmseg - INFO - Iter [69300/80000]\tlr: 1.719e-03, eta: 11:05:26, time: 2.430, data_time: 0.059, memory: 9169, decode.loss_ce: 0.0149, decode.acc_seg: 99.3324, aux.loss_ce: 0.0071, aux.acc_seg: 99.2807, loss: 0.0219\n","2023-01-05 05:49:16,789 - mmseg - INFO - Iter [69350/80000]\tlr: 1.713e-03, eta: 10:53:27, time: 2.380, data_time: 0.006, memory: 9169, decode.loss_ce: 0.0152, decode.acc_seg: 99.3407, aux.loss_ce: 0.0073, aux.acc_seg: 99.2809, loss: 0.0225\n","2023-01-05 05:51:18,372 - mmseg - INFO - Iter [69400/80000]\tlr: 1.706e-03, eta: 10:42:30, time: 2.432, data_time: 0.058, memory: 9169, decode.loss_ce: 0.0145, decode.acc_seg: 99.3568, aux.loss_ce: 0.0069, aux.acc_seg: 99.3023, loss: 0.0214\n","2023-01-05 05:53:20,169 - mmseg - INFO - Iter [69450/80000]\tlr: 1.699e-03, eta: 10:32:11, time: 2.436, data_time: 0.060, memory: 9169, decode.loss_ce: 0.0145, decode.acc_seg: 99.3466, aux.loss_ce: 0.0068, aux.acc_seg: 99.2888, loss: 0.0213\n","2023-01-05 05:55:19,176 - mmseg - INFO - Iter [69500/80000]\tlr: 1.692e-03, eta: 10:22:07, time: 2.380, data_time: 0.006, memory: 9169, decode.loss_ce: 0.0142, decode.acc_seg: 99.3645, aux.loss_ce: 0.0067, aux.acc_seg: 99.3103, loss: 0.0210\n","2023-01-05 05:57:21,010 - mmseg - INFO - Iter [69550/80000]\tlr: 1.685e-03, eta: 10:12:52, time: 2.437, data_time: 0.061, memory: 9169, decode.loss_ce: 0.0144, decode.acc_seg: 99.3636, aux.loss_ce: 0.0068, aux.acc_seg: 99.3104, loss: 0.0212\n","2023-01-05 05:59:22,737 - mmseg - INFO - Iter [69600/80000]\tlr: 1.678e-03, eta: 10:04:04, time: 2.435, data_time: 0.058, memory: 9169, decode.loss_ce: 0.0145, decode.acc_seg: 99.3462, aux.loss_ce: 0.0069, aux.acc_seg: 99.2857, loss: 0.0214\n","2023-01-05 06:01:21,836 - mmseg - INFO - Iter [69650/80000]\tlr: 1.672e-03, eta: 9:55:24, time: 2.382, data_time: 0.007, memory: 9169, decode.loss_ce: 0.0148, decode.acc_seg: 99.3479, aux.loss_ce: 0.0070, aux.acc_seg: 99.2929, loss: 0.0217\n","2023-01-05 06:03:23,315 - mmseg - INFO - Iter [69700/80000]\tlr: 1.665e-03, eta: 9:47:22, time: 2.430, data_time: 0.058, memory: 9169, decode.loss_ce: 0.0146, decode.acc_seg: 99.3496, aux.loss_ce: 0.0069, aux.acc_seg: 99.3009, loss: 0.0214\n","2023-01-05 06:05:25,065 - mmseg - INFO - Iter [69750/80000]\tlr: 1.658e-03, eta: 9:39:42, time: 2.435, data_time: 0.060, memory: 9169, decode.loss_ce: 0.0142, decode.acc_seg: 99.3467, aux.loss_ce: 0.0068, aux.acc_seg: 99.2882, loss: 0.0210\n","2023-01-05 06:07:26,460 - mmseg - INFO - Iter [69800/80000]\tlr: 1.651e-03, eta: 9:32:19, time: 2.428, data_time: 0.056, memory: 9169, decode.loss_ce: 0.0141, decode.acc_seg: 99.3559, aux.loss_ce: 0.0066, aux.acc_seg: 99.3043, loss: 0.0207\n","2023-01-05 06:09:25,445 - mmseg - INFO - Iter [69850/80000]\tlr: 1.644e-03, eta: 9:25:00, time: 2.380, data_time: 0.007, memory: 9169, decode.loss_ce: 0.0140, decode.acc_seg: 99.3721, aux.loss_ce: 0.0066, aux.acc_seg: 99.3190, loss: 0.0206\n","2023-01-05 06:11:27,122 - mmseg - INFO - Iter [69900/80000]\tlr: 1.637e-03, eta: 9:18:12, time: 2.434, data_time: 0.060, memory: 9169, decode.loss_ce: 0.0141, decode.acc_seg: 99.3712, aux.loss_ce: 0.0067, aux.acc_seg: 99.3147, loss: 0.0208\n","2023-01-05 06:13:28,673 - mmseg - INFO - Iter [69950/80000]\tlr: 1.631e-03, eta: 9:11:38, time: 2.431, data_time: 0.059, memory: 9169, decode.loss_ce: 0.0143, decode.acc_seg: 99.3603, aux.loss_ce: 0.0067, aux.acc_seg: 99.3073, loss: 0.0210\n","2023-01-05 06:15:27,547 - mmseg - INFO - Saving checkpoint at 70000 iterations\n","2023-01-05 06:15:30,683 - mmseg - INFO - Exp name: my_pspnet_r101-d8_512x512_80k_ade20k.py\n","2023-01-05 06:15:30,683 - mmseg - INFO - Iter [70000/80000]\tlr: 1.624e-03, eta: 9:05:21, time: 2.440, data_time: 0.005, memory: 9169, decode.loss_ce: 0.0145, decode.acc_seg: 99.3568, aux.loss_ce: 0.0069, aux.acc_seg: 99.2986, loss: 0.0215\n","[>>] 36/36, 3.8 task/s, elapsed: 9s, ETA:     0s\n","\n","2023-01-05 06:15:40,200 - mmseg - INFO - per class results:\n","2023-01-05 06:15:40,201 - mmseg - INFO - \n","+------------+-------+-------+-------+--------+-----------+--------+\n","|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |\n","+------------+-------+-------+-------+--------+-----------+--------+\n","| Background | 99.28 | 99.69 | 99.64 | 99.64  |   99.59   | 99.69  |\n","|    Head    | 91.88 | 96.47 | 95.77 | 95.77  |   95.07   | 96.47  |\n","|    Body    | 94.37 | 96.73 |  97.1 |  97.1  |   97.47   | 96.73  |\n","|    Fins    | 79.64 | 88.08 | 88.67 | 88.67  |   89.26   | 88.08  |\n","|    Tail    | 83.45 | 90.48 | 90.98 | 90.98  |   91.49   | 90.48  |\n","+------------+-------+-------+-------+--------+-----------+--------+\n","2023-01-05 06:15:40,201 - mmseg - INFO - Summary:\n","2023-01-05 06:15:40,202 - mmseg - INFO - \n","+-------+-------+-------+-------+---------+------------+---------+\n","|  aAcc |  mIoU |  mAcc | mDice | mFscore | mPrecision | mRecall |\n","+-------+-------+-------+-------+---------+------------+---------+\n","| 98.98 | 89.72 | 94.29 | 94.43 |  94.43  |   94.58    |  94.29  |\n","+-------+-------+-------+-------+---------+------------+---------+\n","2023-01-05 06:15:40,202 - mmseg - INFO - Exp name: my_pspnet_r101-d8_512x512_80k_ade20k.py\n","2023-01-05 06:15:40,202 - mmseg - INFO - Iter(val) [36]\taAcc: 0.9898, mIoU: 0.8972, mAcc: 0.9429, mDice: 0.9443, mFscore: 0.9443, mPrecision: 0.9458, mRecall: 0.9429, IoU.Background: 0.9928, IoU.Head: 0.9188, IoU.Body: 0.9437, IoU.Fins: 0.7964, IoU.Tail: 0.8345, Acc.Background: 0.9969, Acc.Head: 0.9647, Acc.Body: 0.9673, Acc.Fins: 0.8808, Acc.Tail: 0.9048, Dice.Background: 0.9964, Dice.Head: 0.9577, Dice.Body: 0.9710, Dice.Fins: 0.8867, Dice.Tail: 0.9098, Fscore.Background: 0.9964, Fscore.Head: 0.9577, Fscore.Body: 0.9710, Fscore.Fins: 0.8867, Fscore.Tail: 0.9098, Precision.Background: 0.9959, Precision.Head: 0.9507, Precision.Body: 0.9747, Precision.Fins: 0.8926, Precision.Tail: 0.9149, Recall.Background: 0.9969, Recall.Head: 0.9647, Recall.Body: 0.9673, Recall.Fins: 0.8808, Recall.Tail: 0.9048\n","2023-01-05 06:17:41,850 - mmseg - INFO - Iter [70050/80000]\tlr: 1.617e-03, eta: 9:00:00, time: 2.623, data_time: 0.248, memory: 9169, decode.loss_ce: 0.0142, decode.acc_seg: 99.3687, aux.loss_ce: 0.0068, aux.acc_seg: 99.3134, loss: 0.0210\n","2023-01-05 06:19:43,192 - mmseg - INFO - Iter [70100/80000]\tlr: 1.610e-03, eta: 8:54:01, time: 2.427, data_time: 0.052, memory: 9169, decode.loss_ce: 0.0147, decode.acc_seg: 99.3440, aux.loss_ce: 0.0070, aux.acc_seg: 99.2864, loss: 0.0217\n","2023-01-05 06:21:42,122 - mmseg - INFO - Iter [70150/80000]\tlr: 1.603e-03, eta: 8:48:03, time: 2.379, data_time: 0.006, memory: 9169, decode.loss_ce: 0.0144, decode.acc_seg: 99.3490, aux.loss_ce: 0.0067, aux.acc_seg: 99.2985, loss: 0.0211\n","2023-01-05 06:23:43,698 - mmseg - INFO - Iter [70200/80000]\tlr: 1.596e-03, eta: 8:42:27, time: 2.431, data_time: 0.057, memory: 9169, decode.loss_ce: 0.0144, decode.acc_seg: 99.3663, aux.loss_ce: 0.0068, aux.acc_seg: 99.3119, loss: 0.0213\n","2023-01-05 06:25:45,241 - mmseg - INFO - Iter [70250/80000]\tlr: 1.589e-03, eta: 8:37:01, time: 2.431, data_time: 0.058, memory: 9169, decode.loss_ce: 0.0146, decode.acc_seg: 99.3721, aux.loss_ce: 0.0069, aux.acc_seg: 99.3249, loss: 0.0215\n","2023-01-05 06:27:44,064 - mmseg - INFO - Iter [70300/80000]\tlr: 1.582e-03, eta: 8:31:32, time: 2.376, data_time: 0.005, memory: 9169, decode.loss_ce: 0.0143, decode.acc_seg: 99.3639, aux.loss_ce: 0.0068, aux.acc_seg: 99.3125, loss: 0.0211\n","2023-01-05 06:29:45,520 - mmseg - INFO - Iter [70350/80000]\tlr: 1.576e-03, eta: 8:26:23, time: 2.429, data_time: 0.057, memory: 9169, decode.loss_ce: 0.0142, decode.acc_seg: 99.3773, aux.loss_ce: 0.0068, aux.acc_seg: 99.3257, loss: 0.0209\n","2023-01-05 06:31:46,833 - mmseg - INFO - Iter [70400/80000]\tlr: 1.569e-03, eta: 8:21:22, time: 2.426, data_time: 0.053, memory: 9169, decode.loss_ce: 0.0139, decode.acc_seg: 99.3756, aux.loss_ce: 0.0066, aux.acc_seg: 99.3299, loss: 0.0205\n","2023-01-05 06:33:48,214 - mmseg - INFO - Iter [70450/80000]\tlr: 1.562e-03, eta: 8:16:27, time: 2.428, data_time: 0.055, memory: 9169, decode.loss_ce: 0.0141, decode.acc_seg: 99.3755, aux.loss_ce: 0.0067, aux.acc_seg: 99.3217, loss: 0.0208\n","2023-01-05 06:35:47,096 - mmseg - INFO - Iter [70500/80000]\tlr: 1.555e-03, eta: 8:11:31, time: 2.378, data_time: 0.006, memory: 9169, decode.loss_ce: 0.0145, decode.acc_seg: 99.3635, aux.loss_ce: 0.0069, aux.acc_seg: 99.3107, loss: 0.0214\n","2023-01-05 06:37:48,776 - mmseg - INFO - Iter [70550/80000]\tlr: 1.548e-03, eta: 8:06:51, time: 2.434, data_time: 0.058, memory: 9169, decode.loss_ce: 0.0144, decode.acc_seg: 99.3631, aux.loss_ce: 0.0069, aux.acc_seg: 99.3046, loss: 0.0213\n","2023-01-05 06:39:50,019 - mmseg - INFO - Iter [70600/80000]\tlr: 1.541e-03, eta: 8:02:16, time: 2.425, data_time: 0.054, memory: 9169, decode.loss_ce: 0.0139, decode.acc_seg: 99.3768, aux.loss_ce: 0.0065, aux.acc_seg: 99.3239, loss: 0.0204\n","2023-01-05 06:41:48,742 - mmseg - INFO - Iter [70650/80000]\tlr: 1.534e-03, eta: 7:57:38, time: 2.374, data_time: 0.005, memory: 9169, decode.loss_ce: 0.0137, decode.acc_seg: 99.3586, aux.loss_ce: 0.0065, aux.acc_seg: 99.3005, loss: 0.0203\n","2023-01-05 06:43:50,161 - mmseg - INFO - Iter [70700/80000]\tlr: 1.527e-03, eta: 7:53:15, time: 2.428, data_time: 0.056, memory: 9169, decode.loss_ce: 0.0137, decode.acc_seg: 99.3823, aux.loss_ce: 0.0065, aux.acc_seg: 99.3260, loss: 0.0202\n","2023-01-05 06:45:51,540 - mmseg - INFO - Iter [70750/80000]\tlr: 1.520e-03, eta: 7:48:57, time: 2.428, data_time: 0.056, memory: 9169, decode.loss_ce: 0.0143, decode.acc_seg: 99.3625, aux.loss_ce: 0.0067, aux.acc_seg: 99.3102, loss: 0.0210\n","2023-01-05 06:47:50,250 - mmseg - INFO - Iter [70800/80000]\tlr: 1.514e-03, eta: 7:44:36, time: 2.374, data_time: 0.005, memory: 9169, decode.loss_ce: 0.0146, decode.acc_seg: 99.3666, aux.loss_ce: 0.0069, aux.acc_seg: 99.3137, loss: 0.0215\n","2023-01-05 06:49:51,716 - mmseg - INFO - Iter [70850/80000]\tlr: 1.507e-03, eta: 7:40:28, time: 2.429, data_time: 0.057, memory: 9169, decode.loss_ce: 0.0144, decode.acc_seg: 99.3650, aux.loss_ce: 0.0068, aux.acc_seg: 99.3182, loss: 0.0212\n","2023-01-05 06:51:53,045 - mmseg - INFO - Iter [70900/80000]\tlr: 1.500e-03, eta: 7:36:24, time: 2.427, data_time: 0.055, memory: 9169, decode.loss_ce: 0.0138, decode.acc_seg: 99.3649, aux.loss_ce: 0.0065, aux.acc_seg: 99.3108, loss: 0.0204\n","2023-01-05 06:53:51,881 - mmseg - INFO - Iter [70950/80000]\tlr: 1.493e-03, eta: 7:32:16, time: 2.377, data_time: 0.007, memory: 9169, decode.loss_ce: 0.0141, decode.acc_seg: 99.3665, aux.loss_ce: 0.0067, aux.acc_seg: 99.3101, loss: 0.0209\n","2023-01-05 06:55:53,436 - mmseg - INFO - Saving checkpoint at 71000 iterations\n","2023-01-05 06:55:56,713 - mmseg - INFO - Exp name: my_pspnet_r101-d8_512x512_80k_ade20k.py\n","2023-01-05 06:55:56,714 - mmseg - INFO - Iter [71000/80000]\tlr: 1.486e-03, eta: 7:28:31, time: 2.497, data_time: 0.058, memory: 9169, decode.loss_ce: 0.0141, decode.acc_seg: 99.3631, aux.loss_ce: 0.0067, aux.acc_seg: 99.3113, loss: 0.0209\n","[>>] 36/36, 3.9 task/s, elapsed: 9s, ETA:     0s\n","\n","2023-01-05 06:56:05,933 - mmseg - INFO - per class results:\n","2023-01-05 06:56:05,935 - mmseg - INFO - \n","+------------+-------+-------+-------+--------+-----------+--------+\n","|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |\n","+------------+-------+-------+-------+--------+-----------+--------+\n","| Background | 99.29 |  99.7 | 99.64 | 99.64  |   99.59   |  99.7  |\n","|    Head    | 91.72 | 96.37 | 95.68 | 95.68  |    95.0   | 96.37  |\n","|    Body    | 94.36 | 96.58 |  97.1 |  97.1  |   97.61   | 96.58  |\n","|    Fins    | 79.74 | 88.31 | 88.73 | 88.73  |   89.15   | 88.31  |\n","|    Tail    | 83.22 | 90.55 | 90.84 | 90.84  |   91.14   | 90.55  |\n","+------------+-------+-------+-------+--------+-----------+--------+\n","2023-01-05 06:56:05,935 - mmseg - INFO - Summary:\n","2023-01-05 06:56:05,936 - mmseg - INFO - \n","+-------+-------+------+-------+---------+------------+---------+\n","|  aAcc |  mIoU | mAcc | mDice | mFscore | mPrecision | mRecall |\n","+-------+-------+------+-------+---------+------------+---------+\n","| 98.98 | 89.66 | 94.3 |  94.4 |   94.4  |    94.5    |   94.3  |\n","+-------+-------+------+-------+---------+------------+---------+\n","2023-01-05 06:56:05,937 - mmseg - INFO - Exp name: my_pspnet_r101-d8_512x512_80k_ade20k.py\n","2023-01-05 06:56:05,938 - mmseg - INFO - Iter(val) [36]\taAcc: 0.9898, mIoU: 0.8966, mAcc: 0.9430, mDice: 0.9440, mFscore: 0.9440, mPrecision: 0.9450, mRecall: 0.9430, IoU.Background: 0.9929, IoU.Head: 0.9172, IoU.Body: 0.9436, IoU.Fins: 0.7974, IoU.Tail: 0.8322, Acc.Background: 0.9970, Acc.Head: 0.9637, Acc.Body: 0.9658, Acc.Fins: 0.8831, Acc.Tail: 0.9055, Dice.Background: 0.9964, Dice.Head: 0.9568, Dice.Body: 0.9710, Dice.Fins: 0.8873, Dice.Tail: 0.9084, Fscore.Background: 0.9964, Fscore.Head: 0.9568, Fscore.Body: 0.9710, Fscore.Fins: 0.8873, Fscore.Tail: 0.9084, Precision.Background: 0.9959, Precision.Head: 0.9500, Precision.Body: 0.9761, Precision.Fins: 0.8915, Precision.Tail: 0.9114, Recall.Background: 0.9970, Recall.Head: 0.9637, Recall.Body: 0.9658, Recall.Fins: 0.8831, Recall.Tail: 0.9055\n","2023-01-05 06:58:07,480 - mmseg - INFO - Iter [71050/80000]\tlr: 1.479e-03, eta: 7:25:07, time: 2.615, data_time: 0.240, memory: 9169, decode.loss_ce: 0.0143, decode.acc_seg: 99.3687, aux.loss_ce: 0.0067, aux.acc_seg: 99.3183, loss: 0.0211\n","2023-01-05 07:00:09,043 - mmseg - INFO - Iter [71100/80000]\tlr: 1.472e-03, eta: 7:21:18, time: 2.431, data_time: 0.060, memory: 9169, decode.loss_ce: 0.0139, decode.acc_seg: 99.3729, aux.loss_ce: 0.0066, aux.acc_seg: 99.3199, loss: 0.0205\n","2023-01-05 07:02:07,902 - mmseg - INFO - Iter [71150/80000]\tlr: 1.465e-03, eta: 7:17:25, time: 2.377, data_time: 0.006, memory: 9169, decode.loss_ce: 0.0143, decode.acc_seg: 99.3747, aux.loss_ce: 0.0068, aux.acc_seg: 99.3193, loss: 0.0211\n","2023-01-05 07:04:09,403 - mmseg - INFO - Iter [71200/80000]\tlr: 1.458e-03, eta: 7:13:43, time: 2.430, data_time: 0.058, memory: 9169, decode.loss_ce: 0.0144, decode.acc_seg: 99.3737, aux.loss_ce: 0.0069, aux.acc_seg: 99.3179, loss: 0.0213\n","2023-01-05 07:06:10,700 - mmseg - INFO - Iter [71250/80000]\tlr: 1.451e-03, eta: 7:10:04, time: 2.426, data_time: 0.055, memory: 9169, decode.loss_ce: 0.0143, decode.acc_seg: 99.3662, aux.loss_ce: 0.0068, aux.acc_seg: 99.3137, loss: 0.0211\n","2023-01-05 07:08:09,438 - mmseg - INFO - Iter [71300/80000]\tlr: 1.444e-03, eta: 7:06:21, time: 2.375, data_time: 0.006, memory: 9169, decode.loss_ce: 0.0144, decode.acc_seg: 99.3761, aux.loss_ce: 0.0069, aux.acc_seg: 99.3266, loss: 0.0213\n","2023-01-05 07:10:10,915 - mmseg - INFO - Iter [71350/80000]\tlr: 1.437e-03, eta: 7:02:48, time: 2.430, data_time: 0.058, memory: 9169, decode.loss_ce: 0.0142, decode.acc_seg: 99.3689, aux.loss_ce: 0.0068, aux.acc_seg: 99.3193, loss: 0.0210\n","2023-01-05 07:12:12,226 - mmseg - INFO - Iter [71400/80000]\tlr: 1.430e-03, eta: 6:59:17, time: 2.426, data_time: 0.054, memory: 9169, decode.loss_ce: 0.0143, decode.acc_seg: 99.3829, aux.loss_ce: 0.0068, aux.acc_seg: 99.3296, loss: 0.0211\n","2023-01-05 07:14:10,996 - mmseg - INFO - Iter [71450/80000]\tlr: 1.423e-03, eta: 6:55:43, time: 2.375, data_time: 0.006, memory: 9169, decode.loss_ce: 0.0137, decode.acc_seg: 99.3758, aux.loss_ce: 0.0065, aux.acc_seg: 99.3190, loss: 0.0201\n","2023-01-05 07:16:12,406 - mmseg - INFO - Iter [71500/80000]\tlr: 1.416e-03, eta: 6:52:18, time: 2.428, data_time: 0.059, memory: 9169, decode.loss_ce: 0.0145, decode.acc_seg: 99.3651, aux.loss_ce: 0.0069, aux.acc_seg: 99.3161, loss: 0.0213\n","2023-01-05 07:18:14,040 - mmseg - INFO - Iter [71550/80000]\tlr: 1.409e-03, eta: 6:48:55, time: 2.433, data_time: 0.059, memory: 9169, decode.loss_ce: 0.0148, decode.acc_seg: 99.3637, aux.loss_ce: 0.0071, aux.acc_seg: 99.3107, loss: 0.0219\n","2023-01-05 07:20:15,361 - mmseg - INFO - Iter [71600/80000]\tlr: 1.402e-03, eta: 6:45:34, time: 2.426, data_time: 0.055, memory: 9169, decode.loss_ce: 0.0140, decode.acc_seg: 99.3757, aux.loss_ce: 0.0066, aux.acc_seg: 99.3267, loss: 0.0206\n","2023-01-05 07:22:14,159 - mmseg - INFO - Iter [71650/80000]\tlr: 1.395e-03, eta: 6:42:10, time: 2.376, data_time: 0.005, memory: 9169, decode.loss_ce: 0.0136, decode.acc_seg: 99.3965, aux.loss_ce: 0.0065, aux.acc_seg: 99.3436, loss: 0.0201\n","2023-01-05 07:24:15,851 - mmseg - INFO - Iter [71700/80000]\tlr: 1.388e-03, eta: 6:38:54, time: 2.434, data_time: 0.060, memory: 9169, decode.loss_ce: 0.0143, decode.acc_seg: 99.3658, aux.loss_ce: 0.0068, aux.acc_seg: 99.3172, loss: 0.0212\n","2023-01-05 07:26:17,289 - mmseg - INFO - Iter [71750/80000]\tlr: 1.381e-03, eta: 6:35:40, time: 2.429, data_time: 0.057, memory: 9169, decode.loss_ce: 0.0132, decode.acc_seg: 99.4066, aux.loss_ce: 0.0063, aux.acc_seg: 99.3545, loss: 0.0195\n","2023-01-05 07:28:16,099 - mmseg - INFO - Iter [71800/80000]\tlr: 1.374e-03, eta: 6:32:22, time: 2.376, data_time: 0.005, memory: 9169, decode.loss_ce: 0.0142, decode.acc_seg: 99.3688, aux.loss_ce: 0.0067, aux.acc_seg: 99.3160, loss: 0.0209\n","2023-01-05 07:30:17,470 - mmseg - INFO - Iter [71850/80000]\tlr: 1.367e-03, eta: 6:29:12, time: 2.427, data_time: 0.056, memory: 9169, decode.loss_ce: 0.0139, decode.acc_seg: 99.3682, aux.loss_ce: 0.0066, aux.acc_seg: 99.3168, loss: 0.0205\n","2023-01-05 07:32:18,819 - mmseg - INFO - Iter [71900/80000]\tlr: 1.360e-03, eta: 6:26:03, time: 2.427, data_time: 0.057, memory: 9169, decode.loss_ce: 0.0138, decode.acc_seg: 99.3858, aux.loss_ce: 0.0066, aux.acc_seg: 99.3307, loss: 0.0205\n","2023-01-05 07:34:17,598 - mmseg - INFO - Iter [71950/80000]\tlr: 1.353e-03, eta: 6:22:51, time: 2.376, data_time: 0.005, memory: 9169, decode.loss_ce: 0.0145, decode.acc_seg: 99.3665, aux.loss_ce: 0.0069, aux.acc_seg: 99.3195, loss: 0.0215\n","2023-01-05 07:36:18,969 - mmseg - INFO - Saving checkpoint at 72000 iterations\n","2023-01-05 07:36:22,023 - mmseg - INFO - Exp name: my_pspnet_r101-d8_512x512_80k_ade20k.py\n","2023-01-05 07:36:22,024 - mmseg - INFO - Iter [72000/80000]\tlr: 1.346e-03, eta: 6:19:51, time: 2.489, data_time: 0.055, memory: 9169, decode.loss_ce: 0.0134, decode.acc_seg: 99.3897, aux.loss_ce: 0.0064, aux.acc_seg: 99.3328, loss: 0.0198\n","[>>] 36/36, 3.9 task/s, elapsed: 9s, ETA:     0s\n","\n","2023-01-05 07:36:31,422 - mmseg - INFO - per class results:\n","2023-01-05 07:36:31,423 - mmseg - INFO - \n","+------------+-------+-------+-------+--------+-----------+--------+\n","|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |\n","+------------+-------+-------+-------+--------+-----------+--------+\n","| Background | 99.29 | 99.72 | 99.64 | 99.64  |   99.57   | 99.72  |\n","|    Head    | 91.74 | 96.11 | 95.69 | 95.69  |   95.28   | 96.11  |\n","|    Body    | 94.34 | 96.62 | 97.09 | 97.09  |   97.56   | 96.62  |\n","|    Fins    | 79.87 | 88.06 | 88.81 | 88.81  |   89.58   | 88.06  |\n","|    Tail    | 83.37 |  90.1 | 90.93 | 90.93  |   91.78   |  90.1  |\n","+------------+-------+-------+-------+--------+-----------+--------+\n","2023-01-05 07:36:31,423 - mmseg - INFO - Summary:\n","2023-01-05 07:36:31,424 - mmseg - INFO - \n","+-------+-------+-------+-------+---------+------------+---------+\n","|  aAcc |  mIoU |  mAcc | mDice | mFscore | mPrecision | mRecall |\n","+-------+-------+-------+-------+---------+------------+---------+\n","| 98.98 | 89.72 | 94.12 | 94.43 |  94.43  |   94.75    |  94.12  |\n","+-------+-------+-------+-------+---------+------------+---------+\n","2023-01-05 07:36:31,424 - mmseg - INFO - Exp name: my_pspnet_r101-d8_512x512_80k_ade20k.py\n","2023-01-05 07:36:31,425 - mmseg - INFO - Iter(val) [36]\taAcc: 0.9898, mIoU: 0.8972, mAcc: 0.9412, mDice: 0.9443, mFscore: 0.9443, mPrecision: 0.9475, mRecall: 0.9412, IoU.Background: 0.9929, IoU.Head: 0.9174, IoU.Body: 0.9434, IoU.Fins: 0.7987, IoU.Tail: 0.8337, Acc.Background: 0.9972, Acc.Head: 0.9611, Acc.Body: 0.9662, Acc.Fins: 0.8806, Acc.Tail: 0.9010, Dice.Background: 0.9964, Dice.Head: 0.9569, Dice.Body: 0.9709, Dice.Fins: 0.8881, Dice.Tail: 0.9093, Fscore.Background: 0.9964, Fscore.Head: 0.9569, Fscore.Body: 0.9709, Fscore.Fins: 0.8881, Fscore.Tail: 0.9093, Precision.Background: 0.9957, Precision.Head: 0.9528, Precision.Body: 0.9756, Precision.Fins: 0.8958, Precision.Tail: 0.9178, Recall.Background: 0.9972, Recall.Head: 0.9611, Recall.Body: 0.9662, Recall.Fins: 0.8806, Recall.Tail: 0.9010\n","2023-01-05 07:38:33,180 - mmseg - INFO - Iter [72050/80000]\tlr: 1.339e-03, eta: 6:17:07, time: 2.623, data_time: 0.248, memory: 9169, decode.loss_ce: 0.0144, decode.acc_seg: 99.3830, aux.loss_ce: 0.0069, aux.acc_seg: 99.3312, loss: 0.0212\n","2023-01-05 07:40:32,031 - mmseg - INFO - Iter [72100/80000]\tlr: 1.332e-03, eta: 6:13:59, time: 2.377, data_time: 0.005, memory: 9169, decode.loss_ce: 0.0140, decode.acc_seg: 99.3738, aux.loss_ce: 0.0067, aux.acc_seg: 99.3183, loss: 0.0206\n","2023-01-05 07:42:33,579 - mmseg - INFO - Iter [72150/80000]\tlr: 1.325e-03, eta: 6:10:59, time: 2.431, data_time: 0.059, memory: 9169, decode.loss_ce: 0.0135, decode.acc_seg: 99.3811, aux.loss_ce: 0.0064, aux.acc_seg: 99.3283, loss: 0.0199\n","2023-01-05 07:44:35,179 - mmseg - INFO - Iter [72200/80000]\tlr: 1.318e-03, eta: 6:07:59, time: 2.432, data_time: 0.058, memory: 9169, decode.loss_ce: 0.0139, decode.acc_seg: 99.3824, aux.loss_ce: 0.0066, aux.acc_seg: 99.3296, loss: 0.0205\n","2023-01-05 07:46:36,527 - mmseg - INFO - Iter [72250/80000]\tlr: 1.311e-03, eta: 6:05:01, time: 2.427, data_time: 0.056, memory: 9169, decode.loss_ce: 0.0141, decode.acc_seg: 99.3808, aux.loss_ce: 0.0067, aux.acc_seg: 99.3314, loss: 0.0208\n","2023-01-05 07:48:35,458 - mmseg - INFO - Iter [72300/80000]\tlr: 1.304e-03, eta: 6:02:00, time: 2.379, data_time: 0.005, memory: 9169, decode.loss_ce: 0.0141, decode.acc_seg: 99.3835, aux.loss_ce: 0.0067, aux.acc_seg: 99.3300, loss: 0.0208\n","2023-01-05 07:50:36,974 - mmseg - INFO - Iter [72350/80000]\tlr: 1.297e-03, eta: 5:59:04, time: 2.430, data_time: 0.055, memory: 9169, decode.loss_ce: 0.0145, decode.acc_seg: 99.3735, aux.loss_ce: 0.0069, aux.acc_seg: 99.3166, loss: 0.0214\n","2023-01-05 07:52:38,492 - mmseg - INFO - Iter [72400/80000]\tlr: 1.290e-03, eta: 5:56:10, time: 2.430, data_time: 0.056, memory: 9169, decode.loss_ce: 0.0133, decode.acc_seg: 99.3947, aux.loss_ce: 0.0063, aux.acc_seg: 99.3438, loss: 0.0196\n","2023-01-05 07:54:37,561 - mmseg - INFO - Iter [72450/80000]\tlr: 1.283e-03, eta: 5:53:13, time: 2.381, data_time: 0.006, memory: 9169, decode.loss_ce: 0.0140, decode.acc_seg: 99.3945, aux.loss_ce: 0.0067, aux.acc_seg: 99.3431, loss: 0.0208\n","2023-01-05 07:56:39,196 - mmseg - INFO - Iter [72500/80000]\tlr: 1.276e-03, eta: 5:50:21, time: 2.433, data_time: 0.060, memory: 9169, decode.loss_ce: 0.0141, decode.acc_seg: 99.3752, aux.loss_ce: 0.0066, aux.acc_seg: 99.3252, loss: 0.0207\n","2023-01-05 07:58:40,864 - mmseg - INFO - Iter [72550/80000]\tlr: 1.269e-03, eta: 5:47:31, time: 2.433, data_time: 0.059, memory: 9169, decode.loss_ce: 0.0139, decode.acc_seg: 99.3921, aux.loss_ce: 0.0067, aux.acc_seg: 99.3366, loss: 0.0206\n","2023-01-05 08:00:39,719 - mmseg - INFO - Iter [72600/80000]\tlr: 1.262e-03, eta: 5:44:37, time: 2.377, data_time: 0.006, memory: 9169, decode.loss_ce: 0.0137, decode.acc_seg: 99.3866, aux.loss_ce: 0.0065, aux.acc_seg: 99.3316, loss: 0.0203\n","2023-01-05 08:02:41,327 - mmseg - INFO - Iter [72650/80000]\tlr: 1.255e-03, eta: 5:41:49, time: 2.432, data_time: 0.059, memory: 9169, decode.loss_ce: 0.0141, decode.acc_seg: 99.3727, aux.loss_ce: 0.0067, aux.acc_seg: 99.3221, loss: 0.0208\n","2023-01-05 08:04:42,991 - mmseg - INFO - Iter [72700/80000]\tlr: 1.248e-03, eta: 5:39:02, time: 2.433, data_time: 0.059, memory: 9169, decode.loss_ce: 0.0138, decode.acc_seg: 99.3852, aux.loss_ce: 0.0065, aux.acc_seg: 99.3330, loss: 0.0203\n","2023-01-05 08:06:41,829 - mmseg - INFO - Iter [72750/80000]\tlr: 1.241e-03, eta: 5:36:11, time: 2.377, data_time: 0.006, memory: 9169, decode.loss_ce: 0.0139, decode.acc_seg: 99.3901, aux.loss_ce: 0.0066, aux.acc_seg: 99.3414, loss: 0.0204\n","2023-01-05 08:08:43,242 - mmseg - INFO - Iter [72800/80000]\tlr: 1.234e-03, eta: 5:33:25, time: 2.428, data_time: 0.057, memory: 9169, decode.loss_ce: 0.0136, decode.acc_seg: 99.4044, aux.loss_ce: 0.0065, aux.acc_seg: 99.3544, loss: 0.0200\n","2023-01-05 08:10:45,012 - mmseg - INFO - Iter [72850/80000]\tlr: 1.227e-03, eta: 5:30:41, time: 2.435, data_time: 0.058, memory: 9169, decode.loss_ce: 0.0142, decode.acc_seg: 99.3736, aux.loss_ce: 0.0068, aux.acc_seg: 99.3203, loss: 0.0210\n","2023-01-05 08:12:46,329 - mmseg - INFO - Iter [72900/80000]\tlr: 1.220e-03, eta: 5:27:57, time: 2.426, data_time: 0.057, memory: 9169, decode.loss_ce: 0.0138, decode.acc_seg: 99.3770, aux.loss_ce: 0.0065, aux.acc_seg: 99.3298, loss: 0.0203\n","2023-01-05 08:14:45,294 - mmseg - INFO - Iter [72950/80000]\tlr: 1.212e-03, eta: 5:25:11, time: 2.379, data_time: 0.006, memory: 9169, decode.loss_ce: 0.0138, decode.acc_seg: 99.4010, aux.loss_ce: 0.0066, aux.acc_seg: 99.3484, loss: 0.0205\n","2023-01-05 08:16:46,949 - mmseg - INFO - Saving checkpoint at 73000 iterations\n","2023-01-05 08:16:50,165 - mmseg - INFO - Exp name: my_pspnet_r101-d8_512x512_80k_ade20k.py\n","2023-01-05 08:16:50,165 - mmseg - INFO - Iter [73000/80000]\tlr: 1.205e-03, eta: 5:22:33, time: 2.498, data_time: 0.059, memory: 9169, decode.loss_ce: 0.0137, decode.acc_seg: 99.3842, aux.loss_ce: 0.0065, aux.acc_seg: 99.3304, loss: 0.0202\n","[>>] 36/36, 3.9 task/s, elapsed: 9s, ETA:     0s\n","\n","2023-01-05 08:16:59,448 - mmseg - INFO - per class results:\n","2023-01-05 08:16:59,448 - mmseg - INFO - \n","+------------+-------+-------+-------+--------+-----------+--------+\n","|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |\n","+------------+-------+-------+-------+--------+-----------+--------+\n","| Background | 99.29 | 99.73 | 99.64 | 99.64  |   99.56   | 99.73  |\n","|    Head    | 91.63 | 95.93 | 95.63 | 95.63  |   95.34   | 95.93  |\n","|    Body    | 94.46 | 96.69 | 97.15 | 97.15  |   97.61   | 96.69  |\n","|    Fins    | 79.81 | 87.98 | 88.77 | 88.77  |   89.58   | 87.98  |\n","|    Tail    | 83.61 | 89.96 | 91.07 | 91.07  |   92.22   | 89.96  |\n","+------------+-------+-------+-------+--------+-----------+--------+\n","2023-01-05 08:16:59,449 - mmseg - INFO - Summary:\n","2023-01-05 08:16:59,449 - mmseg - INFO - \n","+-------+-------+-------+-------+---------+------------+---------+\n","|  aAcc |  mIoU |  mAcc | mDice | mFscore | mPrecision | mRecall |\n","+-------+-------+-------+-------+---------+------------+---------+\n","| 98.99 | 89.76 | 94.06 | 94.46 |  94.46  |   94.86    |  94.06  |\n","+-------+-------+-------+-------+---------+------------+---------+\n","2023-01-05 08:16:59,450 - mmseg - INFO - Exp name: my_pspnet_r101-d8_512x512_80k_ade20k.py\n","2023-01-05 08:16:59,450 - mmseg - INFO - Iter(val) [36]\taAcc: 0.9899, mIoU: 0.8976, mAcc: 0.9406, mDice: 0.9446, mFscore: 0.9446, mPrecision: 0.9486, mRecall: 0.9406, IoU.Background: 0.9929, IoU.Head: 0.9163, IoU.Body: 0.9446, IoU.Fins: 0.7981, IoU.Tail: 0.8361, Acc.Background: 0.9973, Acc.Head: 0.9593, Acc.Body: 0.9669, Acc.Fins: 0.8798, Acc.Tail: 0.8996, Dice.Background: 0.9964, Dice.Head: 0.9563, Dice.Body: 0.9715, Dice.Fins: 0.8877, Dice.Tail: 0.9107, Fscore.Background: 0.9964, Fscore.Head: 0.9563, Fscore.Body: 0.9715, Fscore.Fins: 0.8877, Fscore.Tail: 0.9107, Precision.Background: 0.9956, Precision.Head: 0.9534, Precision.Body: 0.9761, Precision.Fins: 0.8958, Precision.Tail: 0.9222, Recall.Background: 0.9973, Recall.Head: 0.9593, Recall.Body: 0.9669, Recall.Fins: 0.8798, Recall.Tail: 0.8996\n","2023-01-05 08:19:00,879 - mmseg - INFO - Iter [73050/80000]\tlr: 1.198e-03, eta: 5:20:05, time: 2.614, data_time: 0.239, memory: 9169, decode.loss_ce: 0.0144, decode.acc_seg: 99.3846, aux.loss_ce: 0.0069, aux.acc_seg: 99.3346, loss: 0.0212\n","2023-01-05 08:20:59,574 - mmseg - INFO - Iter [73100/80000]\tlr: 1.191e-03, eta: 5:17:20, time: 2.374, data_time: 0.006, memory: 9169, decode.loss_ce: 0.0138, decode.acc_seg: 99.3811, aux.loss_ce: 0.0066, aux.acc_seg: 99.3297, loss: 0.0204\n","2023-01-05 08:23:01,215 - mmseg - INFO - Iter [73150/80000]\tlr: 1.184e-03, eta: 5:14:41, time: 2.433, data_time: 0.060, memory: 9169, decode.loss_ce: 0.0138, decode.acc_seg: 99.3851, aux.loss_ce: 0.0066, aux.acc_seg: 99.3316, loss: 0.0205\n","2023-01-05 08:25:03,498 - mmseg - INFO - Iter [73200/80000]\tlr: 1.177e-03, eta: 5:12:02, time: 2.446, data_time: 0.070, memory: 9169, decode.loss_ce: 0.0142, decode.acc_seg: 99.3797, aux.loss_ce: 0.0067, aux.acc_seg: 99.3349, loss: 0.0208\n","2023-01-05 08:27:02,264 - mmseg - INFO - Iter [73250/80000]\tlr: 1.170e-03, eta: 5:09:20, time: 2.375, data_time: 0.005, memory: 9169, decode.loss_ce: 0.0142, decode.acc_seg: 99.3873, aux.loss_ce: 0.0068, aux.acc_seg: 99.3327, loss: 0.0211\n","2023-01-05 08:29:03,757 - mmseg - INFO - Iter [73300/80000]\tlr: 1.163e-03, eta: 5:06:43, time: 2.430, data_time: 0.058, memory: 9169, decode.loss_ce: 0.0142, decode.acc_seg: 99.3824, aux.loss_ce: 0.0068, aux.acc_seg: 99.3295, loss: 0.0211\n","2023-01-05 08:31:05,497 - mmseg - INFO - Iter [73350/80000]\tlr: 1.155e-03, eta: 5:04:06, time: 2.435, data_time: 0.062, memory: 9169, decode.loss_ce: 0.0143, decode.acc_seg: 99.3943, aux.loss_ce: 0.0069, aux.acc_seg: 99.3486, loss: 0.0212\n","2023-01-05 08:33:06,875 - mmseg - INFO - Iter [73400/80000]\tlr: 1.148e-03, eta: 5:01:30, time: 2.428, data_time: 0.055, memory: 9169, decode.loss_ce: 0.0135, decode.acc_seg: 99.3978, aux.loss_ce: 0.0064, aux.acc_seg: 99.3479, loss: 0.0199\n","2023-01-05 08:35:05,908 - mmseg - INFO - Iter [73450/80000]\tlr: 1.141e-03, eta: 4:58:51, time: 2.381, data_time: 0.007, memory: 9169, decode.loss_ce: 0.0132, decode.acc_seg: 99.3995, aux.loss_ce: 0.0063, aux.acc_seg: 99.3449, loss: 0.0195\n","2023-01-05 08:37:07,329 - mmseg - INFO - Iter [73500/80000]\tlr: 1.134e-03, eta: 4:56:16, time: 2.428, data_time: 0.057, memory: 9169, decode.loss_ce: 0.0147, decode.acc_seg: 99.3654, aux.loss_ce: 0.0070, aux.acc_seg: 99.3164, loss: 0.0217\n","2023-01-05 08:39:08,889 - mmseg - INFO - Iter [73550/80000]\tlr: 1.127e-03, eta: 4:53:41, time: 2.431, data_time: 0.059, memory: 9169, decode.loss_ce: 0.0137, decode.acc_seg: 99.3937, aux.loss_ce: 0.0065, aux.acc_seg: 99.3429, loss: 0.0203\n","2023-01-05 08:41:07,851 - mmseg - INFO - Iter [73600/80000]\tlr: 1.120e-03, eta: 4:51:05, time: 2.379, data_time: 0.007, memory: 9169, decode.loss_ce: 0.0138, decode.acc_seg: 99.3905, aux.loss_ce: 0.0066, aux.acc_seg: 99.3363, loss: 0.0204\n","2023-01-05 08:43:09,354 - mmseg - INFO - Iter [73650/80000]\tlr: 1.113e-03, eta: 4:48:31, time: 2.430, data_time: 0.056, memory: 9169, decode.loss_ce: 0.0136, decode.acc_seg: 99.4016, aux.loss_ce: 0.0064, aux.acc_seg: 99.3540, loss: 0.0200\n","2023-01-05 08:45:10,948 - mmseg - INFO - Iter [73700/80000]\tlr: 1.105e-03, eta: 4:45:59, time: 2.432, data_time: 0.058, memory: 9169, decode.loss_ce: 0.0137, decode.acc_seg: 99.3936, aux.loss_ce: 0.0066, aux.acc_seg: 99.3414, loss: 0.0203\n","2023-01-05 08:47:09,937 - mmseg - INFO - Iter [73750/80000]\tlr: 1.098e-03, eta: 4:43:24, time: 2.380, data_time: 0.006, memory: 9169, decode.loss_ce: 0.0138, decode.acc_seg: 99.3970, aux.loss_ce: 0.0066, aux.acc_seg: 99.3453, loss: 0.0204\n","2023-01-05 08:49:11,584 - mmseg - INFO - Iter [73800/80000]\tlr: 1.091e-03, eta: 4:40:52, time: 2.433, data_time: 0.057, memory: 9169, decode.loss_ce: 0.0138, decode.acc_seg: 99.3842, aux.loss_ce: 0.0066, aux.acc_seg: 99.3300, loss: 0.0204\n","2023-01-05 08:51:13,363 - mmseg - INFO - Iter [73850/80000]\tlr: 1.084e-03, eta: 4:38:22, time: 2.436, data_time: 0.061, memory: 9169, decode.loss_ce: 0.0141, decode.acc_seg: 99.3825, aux.loss_ce: 0.0068, aux.acc_seg: 99.3242, loss: 0.0209\n","2023-01-05 08:53:12,159 - mmseg - INFO - Iter [73900/80000]\tlr: 1.077e-03, eta: 4:35:48, time: 2.376, data_time: 0.005, memory: 9169, decode.loss_ce: 0.0135, decode.acc_seg: 99.4098, aux.loss_ce: 0.0065, aux.acc_seg: 99.3619, loss: 0.0200\n","2023-01-05 08:55:13,624 - mmseg - INFO - Iter [73950/80000]\tlr: 1.069e-03, eta: 4:33:18, time: 2.429, data_time: 0.056, memory: 9169, decode.loss_ce: 0.0136, decode.acc_seg: 99.3979, aux.loss_ce: 0.0065, aux.acc_seg: 99.3457, loss: 0.0201\n","2023-01-05 08:57:15,129 - mmseg - INFO - Saving checkpoint at 74000 iterations\n","2023-01-05 08:57:18,320 - mmseg - INFO - Exp name: my_pspnet_r101-d8_512x512_80k_ade20k.py\n","2023-01-05 08:57:18,321 - mmseg - INFO - Iter [74000/80000]\tlr: 1.062e-03, eta: 4:30:52, time: 2.494, data_time: 0.059, memory: 9169, decode.loss_ce: 0.0139, decode.acc_seg: 99.3978, aux.loss_ce: 0.0067, aux.acc_seg: 99.3426, loss: 0.0206\n","[>>] 36/36, 3.9 task/s, elapsed: 9s, ETA:     0s\n","\n","2023-01-05 08:57:27,602 - mmseg - INFO - per class results:\n","2023-01-05 08:57:27,602 - mmseg - INFO - \n","+------------+-------+-------+-------+--------+-----------+--------+\n","|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |\n","+------------+-------+-------+-------+--------+-----------+--------+\n","| Background |  99.3 | 99.71 | 99.65 | 99.65  |   99.59   | 99.71  |\n","|    Head    | 91.93 |  96.4 | 95.79 | 95.79  |   95.19   |  96.4  |\n","|    Body    | 94.51 | 96.66 | 97.18 | 97.18  |    97.7   | 96.66  |\n","|    Fins    |  80.1 | 88.41 | 88.95 | 88.95  |   89.51   | 88.41  |\n","|    Tail    | 83.82 | 90.75 |  91.2 |  91.2  |   91.66   | 90.75  |\n","+------------+-------+-------+-------+--------+-----------+--------+\n","2023-01-05 08:57:27,603 - mmseg - INFO - Summary:\n","2023-01-05 08:57:27,603 - mmseg - INFO - \n","+------+-------+-------+-------+---------+------------+---------+\n","| aAcc |  mIoU |  mAcc | mDice | mFscore | mPrecision | mRecall |\n","+------+-------+-------+-------+---------+------------+---------+\n","| 99.0 | 89.93 | 94.39 | 94.55 |  94.55  |   94.73    |  94.39  |\n","+------+-------+-------+-------+---------+------------+---------+\n","2023-01-05 08:57:27,603 - mmseg - INFO - Exp name: my_pspnet_r101-d8_512x512_80k_ade20k.py\n","2023-01-05 08:57:27,604 - mmseg - INFO - Iter(val) [36]\taAcc: 0.9900, mIoU: 0.8993, mAcc: 0.9439, mDice: 0.9455, mFscore: 0.9455, mPrecision: 0.9473, mRecall: 0.9439, IoU.Background: 0.9930, IoU.Head: 0.9193, IoU.Body: 0.9451, IoU.Fins: 0.8010, IoU.Tail: 0.8382, Acc.Background: 0.9971, Acc.Head: 0.9640, Acc.Body: 0.9666, Acc.Fins: 0.8841, Acc.Tail: 0.9075, Dice.Background: 0.9965, Dice.Head: 0.9579, Dice.Body: 0.9718, Dice.Fins: 0.8895, Dice.Tail: 0.9120, Fscore.Background: 0.9965, Fscore.Head: 0.9579, Fscore.Body: 0.9718, Fscore.Fins: 0.8895, Fscore.Tail: 0.9120, Precision.Background: 0.9959, Precision.Head: 0.9519, Precision.Body: 0.9770, Precision.Fins: 0.8951, Precision.Tail: 0.9166, Recall.Background: 0.9971, Recall.Head: 0.9640, Recall.Body: 0.9666, Recall.Fins: 0.8841, Recall.Tail: 0.9075\n","2023-01-05 08:59:29,491 - mmseg - INFO - Iter [74050/80000]\tlr: 1.055e-03, eta: 4:28:32, time: 2.623, data_time: 0.247, memory: 9169, decode.loss_ce: 0.0136, decode.acc_seg: 99.4124, aux.loss_ce: 0.0065, aux.acc_seg: 99.3645, loss: 0.0200\n","2023-01-05 09:01:28,457 - mmseg - INFO - Iter [74100/80000]\tlr: 1.048e-03, eta: 4:26:01, time: 2.379, data_time: 0.006, memory: 9169, decode.loss_ce: 0.0133, decode.acc_seg: 99.3927, aux.loss_ce: 0.0063, aux.acc_seg: 99.3471, loss: 0.0196\n","2023-01-05 09:03:29,970 - mmseg - INFO - Iter [74150/80000]\tlr: 1.041e-03, eta: 4:23:33, time: 2.430, data_time: 0.057, memory: 9169, decode.loss_ce: 0.0135, decode.acc_seg: 99.4085, aux.loss_ce: 0.0064, aux.acc_seg: 99.3589, loss: 0.0200\n","2023-01-05 09:05:31,605 - mmseg - INFO - Iter [74200/80000]\tlr: 1.033e-03, eta: 4:21:05, time: 2.433, data_time: 0.057, memory: 9169, decode.loss_ce: 0.0135, decode.acc_seg: 99.3888, aux.loss_ce: 0.0065, aux.acc_seg: 99.3368, loss: 0.0200\n","2023-01-05 09:07:30,587 - mmseg - INFO - Iter [74250/80000]\tlr: 1.026e-03, eta: 4:18:35, time: 2.380, data_time: 0.006, memory: 9169, decode.loss_ce: 0.0139, decode.acc_seg: 99.3879, aux.loss_ce: 0.0066, aux.acc_seg: 99.3321, loss: 0.0205\n","2023-01-05 09:09:32,253 - mmseg - INFO - Iter [74300/80000]\tlr: 1.019e-03, eta: 4:16:08, time: 2.433, data_time: 0.059, memory: 9169, decode.loss_ce: 0.0133, decode.acc_seg: 99.4099, aux.loss_ce: 0.0063, aux.acc_seg: 99.3639, loss: 0.0195\n","2023-01-05 09:11:33,770 - mmseg - INFO - Iter [74350/80000]\tlr: 1.012e-03, eta: 4:13:41, time: 2.430, data_time: 0.056, memory: 9169, decode.loss_ce: 0.0136, decode.acc_seg: 99.4067, aux.loss_ce: 0.0066, aux.acc_seg: 99.3507, loss: 0.0202\n","2023-01-05 09:13:32,623 - mmseg - INFO - Iter [74400/80000]\tlr: 1.004e-03, eta: 4:11:13, time: 2.377, data_time: 0.007, memory: 9169, decode.loss_ce: 0.0135, decode.acc_seg: 99.3970, aux.loss_ce: 0.0065, aux.acc_seg: 99.3476, loss: 0.0200\n","2023-01-05 09:15:34,077 - mmseg - INFO - Iter [74450/80000]\tlr: 9.970e-04, eta: 4:08:47, time: 2.429, data_time: 0.056, memory: 9169, decode.loss_ce: 0.0136, decode.acc_seg: 99.4023, aux.loss_ce: 0.0065, aux.acc_seg: 99.3502, loss: 0.0201\n","2023-01-05 09:17:35,626 - mmseg - INFO - Iter [74500/80000]\tlr: 9.897e-04, eta: 4:06:22, time: 2.431, data_time: 0.058, memory: 9169, decode.loss_ce: 0.0132, decode.acc_seg: 99.4013, aux.loss_ce: 0.0063, aux.acc_seg: 99.3473, loss: 0.0194\n","2023-01-05 09:19:34,586 - mmseg - INFO - Iter [74550/80000]\tlr: 9.824e-04, eta: 4:03:54, time: 2.379, data_time: 0.007, memory: 9169, decode.loss_ce: 0.0139, decode.acc_seg: 99.3873, aux.loss_ce: 0.0066, aux.acc_seg: 99.3336, loss: 0.0205\n","2023-01-05 09:21:35,941 - mmseg - INFO - Iter [74600/80000]\tlr: 9.751e-04, eta: 4:01:30, time: 2.427, data_time: 0.056, memory: 9169, decode.loss_ce: 0.0132, decode.acc_seg: 99.4080, aux.loss_ce: 0.0062, aux.acc_seg: 99.3612, loss: 0.0194\n","2023-01-05 09:23:37,480 - mmseg - INFO - Iter [74650/80000]\tlr: 9.679e-04, eta: 3:59:05, time: 2.431, data_time: 0.058, memory: 9169, decode.loss_ce: 0.0134, decode.acc_seg: 99.4063, aux.loss_ce: 0.0063, aux.acc_seg: 99.3592, loss: 0.0197\n","2023-01-05 09:25:38,865 - mmseg - INFO - Iter [74700/80000]\tlr: 9.606e-04, eta: 3:56:41, time: 2.428, data_time: 0.058, memory: 9169, decode.loss_ce: 0.0137, decode.acc_seg: 99.4007, aux.loss_ce: 0.0065, aux.acc_seg: 99.3489, loss: 0.0202\n","2023-01-05 09:27:37,747 - mmseg - INFO - Iter [74750/80000]\tlr: 9.532e-04, eta: 3:54:15, time: 2.378, data_time: 0.005, memory: 9169, decode.loss_ce: 0.0138, decode.acc_seg: 99.3992, aux.loss_ce: 0.0065, aux.acc_seg: 99.3461, loss: 0.0203\n","2023-01-05 09:29:39,697 - mmseg - INFO - Iter [74800/80000]\tlr: 9.459e-04, eta: 3:51:52, time: 2.439, data_time: 0.065, memory: 9169, decode.loss_ce: 0.0137, decode.acc_seg: 99.4002, aux.loss_ce: 0.0065, aux.acc_seg: 99.3560, loss: 0.0201\n","2023-01-05 09:31:41,022 - mmseg - INFO - Iter [74850/80000]\tlr: 9.386e-04, eta: 3:49:29, time: 2.426, data_time: 0.055, memory: 9169, decode.loss_ce: 0.0135, decode.acc_seg: 99.3958, aux.loss_ce: 0.0064, aux.acc_seg: 99.3424, loss: 0.0199\n","2023-01-05 09:33:39,895 - mmseg - INFO - Iter [74900/80000]\tlr: 9.313e-04, eta: 3:47:05, time: 2.377, data_time: 0.005, memory: 9169, decode.loss_ce: 0.0134, decode.acc_seg: 99.4133, aux.loss_ce: 0.0064, aux.acc_seg: 99.3601, loss: 0.0198\n","2023-01-05 09:35:41,586 - mmseg - INFO - Iter [74950/80000]\tlr: 9.239e-04, eta: 3:44:42, time: 2.434, data_time: 0.061, memory: 9169, decode.loss_ce: 0.0135, decode.acc_seg: 99.3906, aux.loss_ce: 0.0065, aux.acc_seg: 99.3370, loss: 0.0200\n","2023-01-05 09:37:43,424 - mmseg - INFO - Saving checkpoint at 75000 iterations\n","2023-01-05 09:37:46,587 - mmseg - INFO - Exp name: my_pspnet_r101-d8_512x512_80k_ade20k.py\n","2023-01-05 09:37:46,587 - mmseg - INFO - Iter [75000/80000]\tlr: 9.166e-04, eta: 3:42:23, time: 2.500, data_time: 0.063, memory: 9169, decode.loss_ce: 0.0134, decode.acc_seg: 99.3930, aux.loss_ce: 0.0063, aux.acc_seg: 99.3486, loss: 0.0198\n","[>>] 36/36, 3.6 task/s, elapsed: 10s, ETA:     0s\n","\n","2023-01-05 09:37:56,733 - mmseg - INFO - per class results:\n","2023-01-05 09:37:56,734 - mmseg - INFO - \n","+------------+-------+-------+-------+--------+-----------+--------+\n","|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |\n","+------------+-------+-------+-------+--------+-----------+--------+\n","| Background |  99.3 | 99.69 | 99.65 | 99.65  |    99.6   | 99.69  |\n","|    Head    | 91.79 | 96.35 | 95.72 | 95.72  |   95.09   | 96.35  |\n","|    Body    | 94.36 | 96.66 |  97.1 |  97.1  |   97.54   | 96.66  |\n","|    Fins    | 79.97 | 88.55 | 88.87 | 88.87  |    89.2   | 88.55  |\n","|    Tail    | 83.57 | 90.67 | 91.05 | 91.05  |   91.43   | 90.67  |\n","+------------+-------+-------+-------+--------+-----------+--------+\n","2023-01-05 09:37:56,735 - mmseg - INFO - Summary:\n","2023-01-05 09:37:56,735 - mmseg - INFO - \n","+-------+------+-------+-------+---------+------------+---------+\n","|  aAcc | mIoU |  mAcc | mDice | mFscore | mPrecision | mRecall |\n","+-------+------+-------+-------+---------+------------+---------+\n","| 98.98 | 89.8 | 94.39 | 94.48 |  94.48  |   94.57    |  94.39  |\n","+-------+------+-------+-------+---------+------------+---------+\n","2023-01-05 09:37:56,736 - mmseg - INFO - Exp name: my_pspnet_r101-d8_512x512_80k_ade20k.py\n","2023-01-05 09:37:56,736 - mmseg - INFO - Iter(val) [36]\taAcc: 0.9898, mIoU: 0.8980, mAcc: 0.9439, mDice: 0.9448, mFscore: 0.9448, mPrecision: 0.9457, mRecall: 0.9439, IoU.Background: 0.9930, IoU.Head: 0.9179, IoU.Body: 0.9436, IoU.Fins: 0.7997, IoU.Tail: 0.8357, Acc.Background: 0.9969, Acc.Head: 0.9635, Acc.Body: 0.9666, Acc.Fins: 0.8855, Acc.Tail: 0.9067, Dice.Background: 0.9965, Dice.Head: 0.9572, Dice.Body: 0.9710, Dice.Fins: 0.8887, Dice.Tail: 0.9105, Fscore.Background: 0.9965, Fscore.Head: 0.9572, Fscore.Body: 0.9710, Fscore.Fins: 0.8887, Fscore.Tail: 0.9105, Precision.Background: 0.9960, Precision.Head: 0.9509, Precision.Body: 0.9754, Precision.Fins: 0.8920, Precision.Tail: 0.9143, Recall.Background: 0.9969, Recall.Head: 0.9635, Recall.Body: 0.9666, Recall.Fins: 0.8855, Recall.Tail: 0.9067\n","2023-01-05 09:39:55,405 - mmseg - INFO - Iter [75050/80000]\tlr: 9.092e-04, eta: 3:40:06, time: 2.576, data_time: 0.208, memory: 9169, decode.loss_ce: 0.0137, decode.acc_seg: 99.3907, aux.loss_ce: 0.0066, aux.acc_seg: 99.3424, loss: 0.0202\n","2023-01-05 09:41:56,751 - mmseg - INFO - Iter [75100/80000]\tlr: 9.019e-04, eta: 3:37:44, time: 2.427, data_time: 0.056, memory: 9169, decode.loss_ce: 0.0137, decode.acc_seg: 99.3902, aux.loss_ce: 0.0066, aux.acc_seg: 99.3381, loss: 0.0203\n","2023-01-05 09:43:58,148 - mmseg - INFO - Iter [75150/80000]\tlr: 8.945e-04, eta: 3:35:23, time: 2.428, data_time: 0.058, memory: 9169, decode.loss_ce: 0.0134, decode.acc_seg: 99.3981, aux.loss_ce: 0.0064, aux.acc_seg: 99.3455, loss: 0.0198\n","2023-01-05 09:45:59,589 - mmseg - INFO - Iter [75200/80000]\tlr: 8.871e-04, eta: 3:33:02, time: 2.429, data_time: 0.058, memory: 9169, decode.loss_ce: 0.0131, decode.acc_seg: 99.3950, aux.loss_ce: 0.0062, aux.acc_seg: 99.3430, loss: 0.0194\n","2023-01-05 09:47:58,395 - mmseg - INFO - Iter [75250/80000]\tlr: 8.798e-04, eta: 3:30:39, time: 2.376, data_time: 0.006, memory: 9169, decode.loss_ce: 0.0142, decode.acc_seg: 99.3835, aux.loss_ce: 0.0067, aux.acc_seg: 99.3359, loss: 0.0209\n","2023-01-05 09:49:59,897 - mmseg - INFO - Iter [75300/80000]\tlr: 8.724e-04, eta: 3:28:19, time: 2.430, data_time: 0.056, memory: 9169, decode.loss_ce: 0.0129, decode.acc_seg: 99.4030, aux.loss_ce: 0.0062, aux.acc_seg: 99.3469, loss: 0.0191\n","2023-01-05 09:52:01,204 - mmseg - INFO - Iter [75350/80000]\tlr: 8.650e-04, eta: 3:25:59, time: 2.426, data_time: 0.054, memory: 9169, decode.loss_ce: 0.0136, decode.acc_seg: 99.3963, aux.loss_ce: 0.0065, aux.acc_seg: 99.3442, loss: 0.0200\n","2023-01-05 09:54:00,088 - mmseg - INFO - Iter [75400/80000]\tlr: 8.576e-04, eta: 3:23:37, time: 2.378, data_time: 0.006, memory: 9169, decode.loss_ce: 0.0137, decode.acc_seg: 99.4118, aux.loss_ce: 0.0066, aux.acc_seg: 99.3647, loss: 0.0202\n","2023-01-05 09:56:01,557 - mmseg - INFO - Iter [75450/80000]\tlr: 8.502e-04, eta: 3:21:17, time: 2.429, data_time: 0.057, memory: 9169, decode.loss_ce: 0.0140, decode.acc_seg: 99.3897, aux.loss_ce: 0.0067, aux.acc_seg: 99.3377, loss: 0.0207\n","2023-01-05 09:58:03,033 - mmseg - INFO - Iter [75500/80000]\tlr: 8.427e-04, eta: 3:18:58, time: 2.429, data_time: 0.058, memory: 9169, decode.loss_ce: 0.0141, decode.acc_seg: 99.4036, aux.loss_ce: 0.0068, aux.acc_seg: 99.3487, loss: 0.0208\n","2023-01-05 10:00:01,867 - mmseg - INFO - Iter [75550/80000]\tlr: 8.353e-04, eta: 3:16:37, time: 2.377, data_time: 0.006, memory: 9169, decode.loss_ce: 0.0133, decode.acc_seg: 99.3964, aux.loss_ce: 0.0063, aux.acc_seg: 99.3453, loss: 0.0196\n","2023-01-05 10:02:03,445 - mmseg - INFO - Iter [75600/80000]\tlr: 8.279e-04, eta: 3:14:18, time: 2.432, data_time: 0.061, memory: 9169, decode.loss_ce: 0.0130, decode.acc_seg: 99.4109, aux.loss_ce: 0.0062, aux.acc_seg: 99.3547, loss: 0.0192\n","2023-01-05 10:04:05,101 - mmseg - INFO - Iter [75650/80000]\tlr: 8.204e-04, eta: 3:11:59, time: 2.433, data_time: 0.057, memory: 9169, decode.loss_ce: 0.0132, decode.acc_seg: 99.4126, aux.loss_ce: 0.0063, aux.acc_seg: 99.3640, loss: 0.0195\n","2023-01-05 10:06:03,762 - mmseg - INFO - Iter [75700/80000]\tlr: 8.130e-04, eta: 3:09:39, time: 2.373, data_time: 0.005, memory: 9169, decode.loss_ce: 0.0135, decode.acc_seg: 99.4076, aux.loss_ce: 0.0065, aux.acc_seg: 99.3506, loss: 0.0199\n","2023-01-05 10:08:05,267 - mmseg - INFO - Iter [75750/80000]\tlr: 8.055e-04, eta: 3:07:21, time: 2.430, data_time: 0.061, memory: 9169, decode.loss_ce: 0.0136, decode.acc_seg: 99.4088, aux.loss_ce: 0.0065, aux.acc_seg: 99.3578, loss: 0.0201\n","2023-01-05 10:10:06,776 - mmseg - INFO - Iter [75800/80000]\tlr: 7.980e-04, eta: 3:05:03, time: 2.430, data_time: 0.059, memory: 9169, decode.loss_ce: 0.0138, decode.acc_seg: 99.3968, aux.loss_ce: 0.0066, aux.acc_seg: 99.3471, loss: 0.0205\n","2023-01-05 10:12:08,310 - mmseg - INFO - Iter [75850/80000]\tlr: 7.905e-04, eta: 3:02:45, time: 2.431, data_time: 0.060, memory: 9169, decode.loss_ce: 0.0139, decode.acc_seg: 99.4082, aux.loss_ce: 0.0066, aux.acc_seg: 99.3522, loss: 0.0205\n","2023-01-05 10:14:07,126 - mmseg - INFO - Iter [75900/80000]\tlr: 7.831e-04, eta: 3:00:26, time: 2.376, data_time: 0.006, memory: 9169, decode.loss_ce: 0.0134, decode.acc_seg: 99.4189, aux.loss_ce: 0.0064, aux.acc_seg: 99.3772, loss: 0.0198\n","2023-01-05 10:16:08,470 - mmseg - INFO - Iter [75950/80000]\tlr: 7.756e-04, eta: 2:58:09, time: 2.427, data_time: 0.057, memory: 9169, decode.loss_ce: 0.0134, decode.acc_seg: 99.4211, aux.loss_ce: 0.0065, aux.acc_seg: 99.3719, loss: 0.0198\n","2023-01-05 10:18:09,907 - mmseg - INFO - Saving checkpoint at 76000 iterations\n","2023-01-05 10:18:13,014 - mmseg - INFO - Exp name: my_pspnet_r101-d8_512x512_80k_ade20k.py\n","2023-01-05 10:18:13,014 - mmseg - INFO - Iter [76000/80000]\tlr: 7.680e-04, eta: 2:55:53, time: 2.491, data_time: 0.058, memory: 9169, decode.loss_ce: 0.0133, decode.acc_seg: 99.4233, aux.loss_ce: 0.0063, aux.acc_seg: 99.3732, loss: 0.0196\n","[>>] 36/36, 3.9 task/s, elapsed: 9s, ETA:     0s\n","\n","2023-01-05 10:18:22,341 - mmseg - INFO - per class results:\n","2023-01-05 10:18:22,342 - mmseg - INFO - \n","+------------+-------+-------+-------+--------+-----------+--------+\n","|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |\n","+------------+-------+-------+-------+--------+-----------+--------+\n","| Background |  99.3 | 99.71 | 99.65 | 99.65  |   99.59   | 99.71  |\n","|    Head    | 91.76 | 96.18 |  95.7 |  95.7  |   95.23   | 96.18  |\n","|    Body    | 94.51 | 96.68 | 97.18 | 97.18  |   97.68   | 96.68  |\n","|    Fins    | 80.08 | 88.54 | 88.94 | 88.94  |   89.35   | 88.54  |\n","|    Tail    | 83.61 | 90.55 | 91.07 | 91.07  |    91.6   | 90.55  |\n","+------------+-------+-------+-------+--------+-----------+--------+\n","2023-01-05 10:18:22,342 - mmseg - INFO - Summary:\n","2023-01-05 10:18:22,343 - mmseg - INFO - \n","+------+-------+-------+-------+---------+------------+---------+\n","| aAcc |  mIoU |  mAcc | mDice | mFscore | mPrecision | mRecall |\n","+------+-------+-------+-------+---------+------------+---------+\n","| 99.0 | 89.85 | 94.33 | 94.51 |  94.51  |   94.69    |  94.33  |\n","+------+-------+-------+-------+---------+------------+---------+\n","2023-01-05 10:18:22,343 - mmseg - INFO - Exp name: my_pspnet_r101-d8_512x512_80k_ade20k.py\n","2023-01-05 10:18:22,344 - mmseg - INFO - Iter(val) [36]\taAcc: 0.9900, mIoU: 0.8985, mAcc: 0.9433, mDice: 0.9451, mFscore: 0.9451, mPrecision: 0.9469, mRecall: 0.9433, IoU.Background: 0.9930, IoU.Head: 0.9176, IoU.Body: 0.9451, IoU.Fins: 0.8008, IoU.Tail: 0.8361, Acc.Background: 0.9971, Acc.Head: 0.9618, Acc.Body: 0.9668, Acc.Fins: 0.8854, Acc.Tail: 0.9055, Dice.Background: 0.9965, Dice.Head: 0.9570, Dice.Body: 0.9718, Dice.Fins: 0.8894, Dice.Tail: 0.9107, Fscore.Background: 0.9965, Fscore.Head: 0.9570, Fscore.Body: 0.9718, Fscore.Fins: 0.8894, Fscore.Tail: 0.9107, Precision.Background: 0.9959, Precision.Head: 0.9523, Precision.Body: 0.9768, Precision.Fins: 0.8935, Precision.Tail: 0.9160, Recall.Background: 0.9971, Recall.Head: 0.9618, Recall.Body: 0.9668, Recall.Fins: 0.8854, Recall.Tail: 0.9055\n","2023-01-05 10:20:21,095 - mmseg - INFO - Iter [76050/80000]\tlr: 7.605e-04, eta: 2:53:39, time: 2.561, data_time: 0.192, memory: 9169, decode.loss_ce: 0.0135, decode.acc_seg: 99.4062, aux.loss_ce: 0.0064, aux.acc_seg: 99.3596, loss: 0.0200\n","2023-01-05 10:22:22,572 - mmseg - INFO - Iter [76100/80000]\tlr: 7.530e-04, eta: 2:51:22, time: 2.430, data_time: 0.058, memory: 9169, decode.loss_ce: 0.0130, decode.acc_seg: 99.4246, aux.loss_ce: 0.0063, aux.acc_seg: 99.3745, loss: 0.0193\n","2023-01-05 10:24:24,137 - mmseg - INFO - Iter [76150/80000]\tlr: 7.455e-04, eta: 2:49:06, time: 2.431, data_time: 0.059, memory: 9169, decode.loss_ce: 0.0135, decode.acc_seg: 99.4118, aux.loss_ce: 0.0064, aux.acc_seg: 99.3618, loss: 0.0199\n","2023-01-05 10:26:23,065 - mmseg - INFO - Iter [76200/80000]\tlr: 7.379e-04, eta: 2:46:48, time: 2.379, data_time: 0.007, memory: 9169, decode.loss_ce: 0.0127, decode.acc_seg: 99.4149, aux.loss_ce: 0.0060, aux.acc_seg: 99.3671, loss: 0.0188\n","2023-01-05 10:28:24,329 - mmseg - INFO - Iter [76250/80000]\tlr: 7.304e-04, eta: 2:44:32, time: 2.425, data_time: 0.054, memory: 9169, decode.loss_ce: 0.0134, decode.acc_seg: 99.4029, aux.loss_ce: 0.0064, aux.acc_seg: 99.3461, loss: 0.0198\n","2023-01-05 10:30:25,799 - mmseg - INFO - Iter [76300/80000]\tlr: 7.228e-04, eta: 2:42:15, time: 2.429, data_time: 0.057, memory: 9169, decode.loss_ce: 0.0133, decode.acc_seg: 99.4089, aux.loss_ce: 0.0064, aux.acc_seg: 99.3606, loss: 0.0197\n","2023-01-05 10:32:24,464 - mmseg - INFO - Iter [76350/80000]\tlr: 7.152e-04, eta: 2:39:58, time: 2.373, data_time: 0.005, memory: 9169, decode.loss_ce: 0.0135, decode.acc_seg: 99.4038, aux.loss_ce: 0.0065, aux.acc_seg: 99.3536, loss: 0.0200\n","2023-01-05 10:34:25,790 - mmseg - INFO - Iter [76400/80000]\tlr: 7.076e-04, eta: 2:37:42, time: 2.427, data_time: 0.056, memory: 9169, decode.loss_ce: 0.0131, decode.acc_seg: 99.4190, aux.loss_ce: 0.0064, aux.acc_seg: 99.3613, loss: 0.0195\n","2023-01-05 10:36:27,473 - mmseg - INFO - Iter [76450/80000]\tlr: 7.000e-04, eta: 2:35:27, time: 2.434, data_time: 0.061, memory: 9169, decode.loss_ce: 0.0132, decode.acc_seg: 99.4163, aux.loss_ce: 0.0063, aux.acc_seg: 99.3680, loss: 0.0195\n","2023-01-05 10:38:28,812 - mmseg - INFO - Iter [76500/80000]\tlr: 6.924e-04, eta: 2:33:11, time: 2.427, data_time: 0.057, memory: 9169, decode.loss_ce: 0.0136, decode.acc_seg: 99.4131, aux.loss_ce: 0.0065, aux.acc_seg: 99.3614, loss: 0.0201\n","2023-01-05 10:40:27,582 - mmseg - INFO - Iter [76550/80000]\tlr: 6.848e-04, eta: 2:30:55, time: 2.375, data_time: 0.005, memory: 9169, decode.loss_ce: 0.0133, decode.acc_seg: 99.4093, aux.loss_ce: 0.0063, aux.acc_seg: 99.3605, loss: 0.0196\n","2023-01-05 10:42:29,191 - mmseg - INFO - Iter [76600/80000]\tlr: 6.772e-04, eta: 2:28:40, time: 2.432, data_time: 0.058, memory: 9169, decode.loss_ce: 0.0137, decode.acc_seg: 99.4051, aux.loss_ce: 0.0065, aux.acc_seg: 99.3567, loss: 0.0202\n","2023-01-05 10:44:30,658 - mmseg - INFO - Iter [76650/80000]\tlr: 6.695e-04, eta: 2:26:25, time: 2.429, data_time: 0.059, memory: 9169, decode.loss_ce: 0.0137, decode.acc_seg: 99.4193, aux.loss_ce: 0.0065, aux.acc_seg: 99.3732, loss: 0.0202\n","2023-01-05 10:46:29,412 - mmseg - INFO - Iter [76700/80000]\tlr: 6.619e-04, eta: 2:24:09, time: 2.375, data_time: 0.005, memory: 9169, decode.loss_ce: 0.0137, decode.acc_seg: 99.4010, aux.loss_ce: 0.0065, aux.acc_seg: 99.3538, loss: 0.0202\n","2023-01-05 10:48:30,743 - mmseg - INFO - Iter [76750/80000]\tlr: 6.542e-04, eta: 2:21:54, time: 2.427, data_time: 0.055, memory: 9169, decode.loss_ce: 0.0136, decode.acc_seg: 99.4146, aux.loss_ce: 0.0065, aux.acc_seg: 99.3655, loss: 0.0201\n","2023-01-05 10:50:32,182 - mmseg - INFO - Iter [76800/80000]\tlr: 6.465e-04, eta: 2:19:40, time: 2.429, data_time: 0.057, memory: 9169, decode.loss_ce: 0.0133, decode.acc_seg: 99.4099, aux.loss_ce: 0.0063, aux.acc_seg: 99.3604, loss: 0.0197\n","2023-01-05 10:52:30,852 - mmseg - INFO - Iter [76850/80000]\tlr: 6.388e-04, eta: 2:17:25, time: 2.373, data_time: 0.005, memory: 9169, decode.loss_ce: 0.0133, decode.acc_seg: 99.4147, aux.loss_ce: 0.0063, aux.acc_seg: 99.3605, loss: 0.0196\n","2023-01-05 10:54:32,181 - mmseg - INFO - Iter [76900/80000]\tlr: 6.311e-04, eta: 2:15:10, time: 2.427, data_time: 0.058, memory: 9169, decode.loss_ce: 0.0130, decode.acc_seg: 99.4149, aux.loss_ce: 0.0062, aux.acc_seg: 99.3609, loss: 0.0193\n","2023-01-05 10:56:33,602 - mmseg - INFO - Iter [76950/80000]\tlr: 6.234e-04, eta: 2:12:56, time: 2.428, data_time: 0.057, memory: 9169, decode.loss_ce: 0.0139, decode.acc_seg: 99.4098, aux.loss_ce: 0.0067, aux.acc_seg: 99.3580, loss: 0.0206\n","2023-01-05 10:58:35,088 - mmseg - INFO - Saving checkpoint at 77000 iterations\n","2023-01-05 10:58:38,303 - mmseg - INFO - Exp name: my_pspnet_r101-d8_512x512_80k_ade20k.py\n","2023-01-05 10:58:38,304 - mmseg - INFO - Iter [77000/80000]\tlr: 6.157e-04, eta: 2:10:44, time: 2.494, data_time: 0.058, memory: 9169, decode.loss_ce: 0.0137, decode.acc_seg: 99.4131, aux.loss_ce: 0.0066, aux.acc_seg: 99.3624, loss: 0.0202\n","[>>] 36/36, 3.9 task/s, elapsed: 9s, ETA:     0s\n","\n","2023-01-05 10:58:47,613 - mmseg - INFO - per class results:\n","2023-01-05 10:58:47,614 - mmseg - INFO - \n","+------------+-------+-------+-------+--------+-----------+--------+\n","|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |\n","+------------+-------+-------+-------+--------+-----------+--------+\n","| Background |  99.3 | 99.72 | 99.65 | 99.65  |   99.57   | 99.72  |\n","|    Head    | 91.92 | 96.31 | 95.79 | 95.79  |   95.27   | 96.31  |\n","|    Body    | 94.43 | 96.69 | 97.14 | 97.14  |   97.59   | 96.69  |\n","|    Fins    |  79.8 | 87.88 | 88.76 | 88.76  |   89.67   | 87.88  |\n","|    Tail    | 83.59 | 90.28 | 91.06 | 91.06  |   91.86   | 90.28  |\n","+------------+-------+-------+-------+--------+-----------+--------+\n","2023-01-05 10:58:47,614 - mmseg - INFO - Summary:\n","2023-01-05 10:58:47,615 - mmseg - INFO - \n","+-------+-------+-------+-------+---------+------------+---------+\n","|  aAcc |  mIoU |  mAcc | mDice | mFscore | mPrecision | mRecall |\n","+-------+-------+-------+-------+---------+------------+---------+\n","| 98.99 | 89.81 | 94.17 | 94.48 |  94.48  |   94.79    |  94.17  |\n","+-------+-------+-------+-------+---------+------------+---------+\n","2023-01-05 10:58:47,615 - mmseg - INFO - Exp name: my_pspnet_r101-d8_512x512_80k_ade20k.py\n","2023-01-05 10:58:47,615 - mmseg - INFO - Iter(val) [36]\taAcc: 0.9899, mIoU: 0.8981, mAcc: 0.9417, mDice: 0.9448, mFscore: 0.9448, mPrecision: 0.9479, mRecall: 0.9417, IoU.Background: 0.9930, IoU.Head: 0.9192, IoU.Body: 0.9443, IoU.Fins: 0.7980, IoU.Tail: 0.8359, Acc.Background: 0.9972, Acc.Head: 0.9631, Acc.Body: 0.9669, Acc.Fins: 0.8788, Acc.Tail: 0.9028, Dice.Background: 0.9965, Dice.Head: 0.9579, Dice.Body: 0.9714, Dice.Fins: 0.8876, Dice.Tail: 0.9106, Fscore.Background: 0.9965, Fscore.Head: 0.9579, Fscore.Body: 0.9714, Fscore.Fins: 0.8876, Fscore.Tail: 0.9106, Precision.Background: 0.9957, Precision.Head: 0.9527, Precision.Body: 0.9759, Precision.Fins: 0.8967, Precision.Tail: 0.9186, Recall.Background: 0.9972, Recall.Head: 0.9631, Recall.Body: 0.9669, Recall.Fins: 0.8788, Recall.Tail: 0.9028\n","2023-01-05 11:00:46,694 - mmseg - INFO - Iter [77050/80000]\tlr: 6.080e-04, eta: 2:08:32, time: 2.568, data_time: 0.192, memory: 9169, decode.loss_ce: 0.0132, decode.acc_seg: 99.4254, aux.loss_ce: 0.0064, aux.acc_seg: 99.3753, loss: 0.0196\n","2023-01-05 11:02:48,126 - mmseg - INFO - Iter [77100/80000]\tlr: 6.002e-04, eta: 2:06:18, time: 2.429, data_time: 0.057, memory: 9169, decode.loss_ce: 0.0130, decode.acc_seg: 99.4216, aux.loss_ce: 0.0062, aux.acc_seg: 99.3733, loss: 0.0193\n","2023-01-05 11:04:49,478 - mmseg - INFO - Iter [77150/80000]\tlr: 5.924e-04, eta: 2:04:05, time: 2.427, data_time: 0.056, memory: 9169, decode.loss_ce: 0.0130, decode.acc_seg: 99.4182, aux.loss_ce: 0.0062, aux.acc_seg: 99.3680, loss: 0.0193\n","2023-01-05 11:06:48,247 - mmseg - INFO - Iter [77200/80000]\tlr: 5.847e-04, eta: 2:01:51, time: 2.375, data_time: 0.005, memory: 9169, decode.loss_ce: 0.0135, decode.acc_seg: 99.4088, aux.loss_ce: 0.0065, aux.acc_seg: 99.3594, loss: 0.0201\n","2023-01-05 11:08:49,681 - mmseg - INFO - Iter [77250/80000]\tlr: 5.769e-04, eta: 1:59:37, time: 2.429, data_time: 0.060, memory: 9169, decode.loss_ce: 0.0135, decode.acc_seg: 99.4126, aux.loss_ce: 0.0064, aux.acc_seg: 99.3709, loss: 0.0199\n","2023-01-05 11:10:51,088 - mmseg - INFO - Iter [77300/80000]\tlr: 5.691e-04, eta: 1:57:24, time: 2.428, data_time: 0.056, memory: 9169, decode.loss_ce: 0.0131, decode.acc_seg: 99.4313, aux.loss_ce: 0.0063, aux.acc_seg: 99.3710, loss: 0.0194\n","2023-01-05 11:12:49,840 - mmseg - INFO - Iter [77350/80000]\tlr: 5.612e-04, eta: 1:55:10, time: 2.375, data_time: 0.006, memory: 9169, decode.loss_ce: 0.0132, decode.acc_seg: 99.4162, aux.loss_ce: 0.0063, aux.acc_seg: 99.3679, loss: 0.0195\n","2023-01-05 11:14:51,237 - mmseg - INFO - Iter [77400/80000]\tlr: 5.534e-04, eta: 1:52:58, time: 2.428, data_time: 0.057, memory: 9169, decode.loss_ce: 0.0137, decode.acc_seg: 99.3909, aux.loss_ce: 0.0066, aux.acc_seg: 99.3386, loss: 0.0203\n","2023-01-05 11:16:52,695 - mmseg - INFO - Iter [77450/80000]\tlr: 5.455e-04, eta: 1:50:45, time: 2.429, data_time: 0.056, memory: 9169, decode.loss_ce: 0.0134, decode.acc_seg: 99.4177, aux.loss_ce: 0.0064, aux.acc_seg: 99.3709, loss: 0.0198\n","2023-01-05 11:18:51,380 - mmseg - INFO - Iter [77500/80000]\tlr: 5.377e-04, eta: 1:48:31, time: 2.374, data_time: 0.005, memory: 9169, decode.loss_ce: 0.0132, decode.acc_seg: 99.4185, aux.loss_ce: 0.0063, aux.acc_seg: 99.3683, loss: 0.0195\n","2023-01-05 11:20:52,722 - mmseg - INFO - Iter [77550/80000]\tlr: 5.298e-04, eta: 1:46:19, time: 2.427, data_time: 0.057, memory: 9169, decode.loss_ce: 0.0133, decode.acc_seg: 99.4183, aux.loss_ce: 0.0064, aux.acc_seg: 99.3687, loss: 0.0196\n","2023-01-05 11:22:54,262 - mmseg - INFO - Iter [77600/80000]\tlr: 5.219e-04, eta: 1:44:07, time: 2.431, data_time: 0.058, memory: 9169, decode.loss_ce: 0.0130, decode.acc_seg: 99.4247, aux.loss_ce: 0.0062, aux.acc_seg: 99.3758, loss: 0.0193\n","2023-01-05 11:24:55,556 - mmseg - INFO - Iter [77650/80000]\tlr: 5.140e-04, eta: 1:41:54, time: 2.426, data_time: 0.057, memory: 9169, decode.loss_ce: 0.0129, decode.acc_seg: 99.4194, aux.loss_ce: 0.0061, aux.acc_seg: 99.3712, loss: 0.0190\n","2023-01-05 11:26:54,315 - mmseg - INFO - Iter [77700/80000]\tlr: 5.060e-04, eta: 1:39:42, time: 2.375, data_time: 0.005, memory: 9169, decode.loss_ce: 0.0137, decode.acc_seg: 99.3971, aux.loss_ce: 0.0066, aux.acc_seg: 99.3413, loss: 0.0202\n","2023-01-05 11:28:55,581 - mmseg - INFO - Iter [77750/80000]\tlr: 4.981e-04, eta: 1:37:29, time: 2.425, data_time: 0.055, memory: 9169, decode.loss_ce: 0.0137, decode.acc_seg: 99.4058, aux.loss_ce: 0.0065, aux.acc_seg: 99.3546, loss: 0.0202\n","2023-01-05 11:30:57,060 - mmseg - INFO - Iter [77800/80000]\tlr: 4.901e-04, eta: 1:35:18, time: 2.430, data_time: 0.060, memory: 9169, decode.loss_ce: 0.0135, decode.acc_seg: 99.4113, aux.loss_ce: 0.0064, aux.acc_seg: 99.3622, loss: 0.0199\n","2023-01-05 11:32:55,822 - mmseg - INFO - Iter [77850/80000]\tlr: 4.821e-04, eta: 1:33:05, time: 2.375, data_time: 0.006, memory: 9169, decode.loss_ce: 0.0134, decode.acc_seg: 99.4245, aux.loss_ce: 0.0065, aux.acc_seg: 99.3690, loss: 0.0198\n","2023-01-05 11:34:57,402 - mmseg - INFO - Iter [77900/80000]\tlr: 4.741e-04, eta: 1:30:53, time: 2.432, data_time: 0.057, memory: 9169, decode.loss_ce: 0.0132, decode.acc_seg: 99.4266, aux.loss_ce: 0.0063, aux.acc_seg: 99.3750, loss: 0.0195\n","2023-01-05 11:36:58,975 - mmseg - INFO - Iter [77950/80000]\tlr: 4.661e-04, eta: 1:28:42, time: 2.431, data_time: 0.058, memory: 9169, decode.loss_ce: 0.0137, decode.acc_seg: 99.4116, aux.loss_ce: 0.0066, aux.acc_seg: 99.3594, loss: 0.0203\n","2023-01-05 11:38:57,712 - mmseg - INFO - Saving checkpoint at 78000 iterations\n","2023-01-05 11:39:00,795 - mmseg - INFO - Exp name: my_pspnet_r101-d8_512x512_80k_ade20k.py\n","2023-01-05 11:39:00,795 - mmseg - INFO - Iter [78000/80000]\tlr: 4.581e-04, eta: 1:26:30, time: 2.437, data_time: 0.006, memory: 9169, decode.loss_ce: 0.0129, decode.acc_seg: 99.4164, aux.loss_ce: 0.0061, aux.acc_seg: 99.3660, loss: 0.0190\n","[>>] 36/36, 3.8 task/s, elapsed: 9s, ETA:     0s\n","\n","2023-01-05 11:39:10,217 - mmseg - INFO - per class results:\n","2023-01-05 11:39:10,220 - mmseg - INFO - \n","+------------+-------+-------+-------+--------+-----------+--------+\n","|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |\n","+------------+-------+-------+-------+--------+-----------+--------+\n","| Background | 99.31 | 99.74 | 99.65 | 99.65  |   99.56   | 99.74  |\n","|    Head    | 91.96 | 96.32 | 95.81 | 95.81  |   95.31   | 96.32  |\n","|    Body    | 94.51 | 96.63 | 97.18 | 97.18  |   97.74   | 96.63  |\n","|    Fins    | 80.14 | 88.04 | 88.98 | 88.98  |   89.93   | 88.04  |\n","|    Tail    | 83.56 | 90.21 | 91.04 | 91.04  |    91.9   | 90.21  |\n","+------------+-------+-------+-------+--------+-----------+--------+\n","2023-01-05 11:39:10,221 - mmseg - INFO - Summary:\n","2023-01-05 11:39:10,223 - mmseg - INFO - \n","+------+------+-------+-------+---------+------------+---------+\n","| aAcc | mIoU |  mAcc | mDice | mFscore | mPrecision | mRecall |\n","+------+------+-------+-------+---------+------------+---------+\n","| 99.0 | 89.9 | 94.19 | 94.53 |  94.53  |   94.89    |  94.19  |\n","+------+------+-------+-------+---------+------------+---------+\n","2023-01-05 11:39:10,224 - mmseg - INFO - Exp name: my_pspnet_r101-d8_512x512_80k_ade20k.py\n","2023-01-05 11:39:10,224 - mmseg - INFO - Iter(val) [36]\taAcc: 0.9900, mIoU: 0.8990, mAcc: 0.9419, mDice: 0.9453, mFscore: 0.9453, mPrecision: 0.9489, mRecall: 0.9419, IoU.Background: 0.9931, IoU.Head: 0.9196, IoU.Body: 0.9451, IoU.Fins: 0.8014, IoU.Tail: 0.8356, Acc.Background: 0.9974, Acc.Head: 0.9632, Acc.Body: 0.9663, Acc.Fins: 0.8804, Acc.Tail: 0.9021, Dice.Background: 0.9965, Dice.Head: 0.9581, Dice.Body: 0.9718, Dice.Fins: 0.8898, Dice.Tail: 0.9104, Fscore.Background: 0.9965, Fscore.Head: 0.9581, Fscore.Body: 0.9718, Fscore.Fins: 0.8898, Fscore.Tail: 0.9104, Precision.Background: 0.9956, Precision.Head: 0.9531, Precision.Body: 0.9774, Precision.Fins: 0.8993, Precision.Tail: 0.9190, Recall.Background: 0.9974, Recall.Head: 0.9632, Recall.Body: 0.9663, Recall.Fins: 0.8804, Recall.Tail: 0.9021\n","2023-01-05 11:41:11,630 - mmseg - INFO - Iter [78050/80000]\tlr: 4.500e-04, eta: 1:24:21, time: 2.616, data_time: 0.243, memory: 9169, decode.loss_ce: 0.0131, decode.acc_seg: 99.4163, aux.loss_ce: 0.0063, aux.acc_seg: 99.3605, loss: 0.0194\n","2023-01-05 11:43:13,080 - mmseg - INFO - Iter [78100/80000]\tlr: 4.419e-04, eta: 1:22:10, time: 2.429, data_time: 0.058, memory: 9169, decode.loss_ce: 0.0131, decode.acc_seg: 99.4098, aux.loss_ce: 0.0063, aux.acc_seg: 99.3604, loss: 0.0194\n","2023-01-05 11:45:11,716 - mmseg - INFO - Iter [78150/80000]\tlr: 4.338e-04, eta: 1:19:58, time: 2.373, data_time: 0.006, memory: 9169, decode.loss_ce: 0.0132, decode.acc_seg: 99.4144, aux.loss_ce: 0.0064, aux.acc_seg: 99.3569, loss: 0.0196\n","2023-01-05 11:47:13,119 - mmseg - INFO - Iter [78200/80000]\tlr: 4.257e-04, eta: 1:17:47, time: 2.428, data_time: 0.057, memory: 9169, decode.loss_ce: 0.0135, decode.acc_seg: 99.4124, aux.loss_ce: 0.0065, aux.acc_seg: 99.3594, loss: 0.0199\n","2023-01-05 11:49:14,915 - mmseg - INFO - Iter [78250/80000]\tlr: 4.175e-04, eta: 1:15:36, time: 2.436, data_time: 0.061, memory: 9169, decode.loss_ce: 0.0131, decode.acc_seg: 99.4121, aux.loss_ce: 0.0063, aux.acc_seg: 99.3578, loss: 0.0194\n","2023-01-05 11:51:16,345 - mmseg - INFO - Iter [78300/80000]\tlr: 4.094e-04, eta: 1:13:25, time: 2.429, data_time: 0.059, memory: 9169, decode.loss_ce: 0.0132, decode.acc_seg: 99.4134, aux.loss_ce: 0.0063, aux.acc_seg: 99.3604, loss: 0.0196\n","2023-01-05 11:53:15,302 - mmseg - INFO - Iter [78350/80000]\tlr: 4.012e-04, eta: 1:11:13, time: 2.379, data_time: 0.007, memory: 9169, decode.loss_ce: 0.0131, decode.acc_seg: 99.4266, aux.loss_ce: 0.0062, aux.acc_seg: 99.3761, loss: 0.0193\n","2023-01-05 11:55:16,896 - mmseg - INFO - Iter [78400/80000]\tlr: 3.930e-04, eta: 1:09:03, time: 2.432, data_time: 0.059, memory: 9169, decode.loss_ce: 0.0133, decode.acc_seg: 99.4090, aux.loss_ce: 0.0064, aux.acc_seg: 99.3563, loss: 0.0196\n","2023-01-05 11:57:18,554 - mmseg - INFO - Iter [78450/80000]\tlr: 3.847e-04, eta: 1:06:52, time: 2.433, data_time: 0.060, memory: 9169, decode.loss_ce: 0.0136, decode.acc_seg: 99.4163, aux.loss_ce: 0.0065, aux.acc_seg: 99.3649, loss: 0.0201\n","2023-01-05 11:59:17,417 - mmseg - INFO - Iter [78500/80000]\tlr: 3.764e-04, eta: 1:04:41, time: 2.377, data_time: 0.006, memory: 9169, decode.loss_ce: 0.0130, decode.acc_seg: 99.4025, aux.loss_ce: 0.0062, aux.acc_seg: 99.3489, loss: 0.0191\n","2023-01-05 12:01:18,836 - mmseg - INFO - Iter [78550/80000]\tlr: 3.681e-04, eta: 1:02:31, time: 2.428, data_time: 0.056, memory: 9169, decode.loss_ce: 0.0131, decode.acc_seg: 99.4254, aux.loss_ce: 0.0063, aux.acc_seg: 99.3752, loss: 0.0194\n","2023-01-05 12:03:20,288 - mmseg - INFO - Iter [78600/80000]\tlr: 3.598e-04, eta: 1:00:20, time: 2.429, data_time: 0.058, memory: 9169, decode.loss_ce: 0.0133, decode.acc_seg: 99.4147, aux.loss_ce: 0.0064, aux.acc_seg: 99.3683, loss: 0.0196\n","2023-01-05 12:05:19,071 - mmseg - INFO - Iter [78650/80000]\tlr: 3.514e-04, eta: 0:58:10, time: 2.376, data_time: 0.005, memory: 9169, decode.loss_ce: 0.0130, decode.acc_seg: 99.4201, aux.loss_ce: 0.0062, aux.acc_seg: 99.3678, loss: 0.0192\n","2023-01-05 12:07:20,470 - mmseg - INFO - Iter [78700/80000]\tlr: 3.431e-04, eta: 0:55:59, time: 2.428, data_time: 0.056, memory: 9169, decode.loss_ce: 0.0131, decode.acc_seg: 99.4160, aux.loss_ce: 0.0063, aux.acc_seg: 99.3629, loss: 0.0194\n","2023-01-05 12:09:22,080 - mmseg - INFO - Iter [78750/80000]\tlr: 3.346e-04, eta: 0:53:49, time: 2.432, data_time: 0.056, memory: 9169, decode.loss_ce: 0.0134, decode.acc_seg: 99.4208, aux.loss_ce: 0.0064, aux.acc_seg: 99.3702, loss: 0.0199\n","2023-01-05 12:11:23,466 - mmseg - INFO - Iter [78800/80000]\tlr: 3.262e-04, eta: 0:51:39, time: 2.428, data_time: 0.057, memory: 9169, decode.loss_ce: 0.0135, decode.acc_seg: 99.4129, aux.loss_ce: 0.0065, aux.acc_seg: 99.3558, loss: 0.0200\n","2023-01-05 12:13:22,334 - mmseg - INFO - Iter [78850/80000]\tlr: 3.177e-04, eta: 0:49:29, time: 2.377, data_time: 0.006, memory: 9169, decode.loss_ce: 0.0133, decode.acc_seg: 99.4150, aux.loss_ce: 0.0064, aux.acc_seg: 99.3624, loss: 0.0197\n","2023-01-05 12:15:23,818 - mmseg - INFO - Iter [78900/80000]\tlr: 3.092e-04, eta: 0:47:19, time: 2.430, data_time: 0.056, memory: 9169, decode.loss_ce: 0.0130, decode.acc_seg: 99.4263, aux.loss_ce: 0.0063, aux.acc_seg: 99.3764, loss: 0.0193\n","2023-01-05 12:17:25,393 - mmseg - INFO - Iter [78950/80000]\tlr: 3.006e-04, eta: 0:45:09, time: 2.431, data_time: 0.057, memory: 9169, decode.loss_ce: 0.0135, decode.acc_seg: 99.4090, aux.loss_ce: 0.0065, aux.acc_seg: 99.3580, loss: 0.0200\n","2023-01-05 12:19:24,217 - mmseg - INFO - Saving checkpoint at 79000 iterations\n","2023-01-05 12:19:27,470 - mmseg - INFO - Exp name: my_pspnet_r101-d8_512x512_80k_ade20k.py\n","2023-01-05 12:19:27,470 - mmseg - INFO - Iter [79000/80000]\tlr: 2.920e-04, eta: 0:43:00, time: 2.442, data_time: 0.006, memory: 9169, decode.loss_ce: 0.0133, decode.acc_seg: 99.4183, aux.loss_ce: 0.0064, aux.acc_seg: 99.3716, loss: 0.0197\n","[>>] 36/36, 3.9 task/s, elapsed: 9s, ETA:     0s\n","\n","2023-01-05 12:19:36,882 - mmseg - INFO - per class results:\n","2023-01-05 12:19:36,884 - mmseg - INFO - \n","+------------+-------+-------+-------+--------+-----------+--------+\n","|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |\n","+------------+-------+-------+-------+--------+-----------+--------+\n","| Background |  99.3 | 99.72 | 99.65 | 99.65  |   99.57   | 99.72  |\n","|    Head    | 91.85 | 96.25 | 95.75 | 95.75  |   95.26   | 96.25  |\n","|    Body    | 94.43 | 96.71 | 97.13 | 97.13  |   97.57   | 96.71  |\n","|    Fins    | 79.86 | 87.67 |  88.8 |  88.8  |   89.97   | 87.67  |\n","|    Tail    | 83.51 | 90.29 | 91.01 | 91.01  |   91.75   | 90.29  |\n","+------------+-------+-------+-------+--------+-----------+--------+\n","2023-01-05 12:19:36,884 - mmseg - INFO - Summary:\n","2023-01-05 12:19:36,885 - mmseg - INFO - \n","+-------+-------+-------+-------+---------+------------+---------+\n","|  aAcc |  mIoU |  mAcc | mDice | mFscore | mPrecision | mRecall |\n","+-------+-------+-------+-------+---------+------------+---------+\n","| 98.99 | 89.79 | 94.13 | 94.47 |  94.47  |   94.82    |  94.13  |\n","+-------+-------+-------+-------+---------+------------+---------+\n","2023-01-05 12:19:36,886 - mmseg - INFO - Exp name: my_pspnet_r101-d8_512x512_80k_ade20k.py\n","2023-01-05 12:19:36,886 - mmseg - INFO - Iter(val) [36]\taAcc: 0.9899, mIoU: 0.8979, mAcc: 0.9413, mDice: 0.9447, mFscore: 0.9447, mPrecision: 0.9482, mRecall: 0.9413, IoU.Background: 0.9930, IoU.Head: 0.9185, IoU.Body: 0.9443, IoU.Fins: 0.7986, IoU.Tail: 0.8351, Acc.Background: 0.9972, Acc.Head: 0.9625, Acc.Body: 0.9671, Acc.Fins: 0.8767, Acc.Tail: 0.9029, Dice.Background: 0.9965, Dice.Head: 0.9575, Dice.Body: 0.9713, Dice.Fins: 0.8880, Dice.Tail: 0.9101, Fscore.Background: 0.9965, Fscore.Head: 0.9575, Fscore.Body: 0.9713, Fscore.Fins: 0.8880, Fscore.Tail: 0.9101, Precision.Background: 0.9957, Precision.Head: 0.9526, Precision.Body: 0.9757, Precision.Fins: 0.8997, Precision.Tail: 0.9175, Recall.Background: 0.9972, Recall.Head: 0.9625, Recall.Body: 0.9671, Recall.Fins: 0.8767, Recall.Tail: 0.9029\n","2023-01-05 12:21:38,485 - mmseg - INFO - Iter [79050/80000]\tlr: 2.833e-04, eta: 0:40:51, time: 2.620, data_time: 0.246, memory: 9169, decode.loss_ce: 0.0130, decode.acc_seg: 99.4305, aux.loss_ce: 0.0063, aux.acc_seg: 99.3779, loss: 0.0193\n","2023-01-05 12:23:40,167 - mmseg - INFO - Iter [79100/80000]\tlr: 2.746e-04, eta: 0:38:41, time: 2.434, data_time: 0.060, memory: 9169, decode.loss_ce: 0.0131, decode.acc_seg: 99.4188, aux.loss_ce: 0.0063, aux.acc_seg: 99.3727, loss: 0.0194\n","2023-01-05 12:25:38,981 - mmseg - INFO - Iter [79150/80000]\tlr: 2.659e-04, eta: 0:36:31, time: 2.376, data_time: 0.006, memory: 9169, decode.loss_ce: 0.0131, decode.acc_seg: 99.4276, aux.loss_ce: 0.0062, aux.acc_seg: 99.3802, loss: 0.0193\n","2023-01-05 12:27:40,407 - mmseg - INFO - Iter [79200/80000]\tlr: 2.571e-04, eta: 0:34:22, time: 2.429, data_time: 0.054, memory: 9169, decode.loss_ce: 0.0134, decode.acc_seg: 99.4075, aux.loss_ce: 0.0064, aux.acc_seg: 99.3538, loss: 0.0198\n","2023-01-05 12:29:41,981 - mmseg - INFO - Iter [79250/80000]\tlr: 2.482e-04, eta: 0:32:13, time: 2.431, data_time: 0.057, memory: 9169, decode.loss_ce: 0.0131, decode.acc_seg: 99.4187, aux.loss_ce: 0.0062, aux.acc_seg: 99.3712, loss: 0.0193\n","2023-01-05 12:31:40,820 - mmseg - INFO - Iter [79300/80000]\tlr: 2.393e-04, eta: 0:30:03, time: 2.377, data_time: 0.006, memory: 9169, decode.loss_ce: 0.0128, decode.acc_seg: 99.4125, aux.loss_ce: 0.0062, aux.acc_seg: 99.3589, loss: 0.0190\n","2023-01-05 12:33:42,260 - mmseg - INFO - Iter [79350/80000]\tlr: 2.303e-04, eta: 0:27:54, time: 2.429, data_time: 0.056, memory: 9169, decode.loss_ce: 0.0136, decode.acc_seg: 99.4221, aux.loss_ce: 0.0065, aux.acc_seg: 99.3736, loss: 0.0201\n","2023-01-05 12:35:43,825 - mmseg - INFO - Iter [79400/80000]\tlr: 2.213e-04, eta: 0:25:45, time: 2.431, data_time: 0.060, memory: 9169, decode.loss_ce: 0.0129, decode.acc_seg: 99.4344, aux.loss_ce: 0.0062, aux.acc_seg: 99.3829, loss: 0.0192\n","2023-01-05 12:37:45,414 - mmseg - INFO - Iter [79450/80000]\tlr: 2.122e-04, eta: 0:23:36, time: 2.432, data_time: 0.061, memory: 9169, decode.loss_ce: 0.0128, decode.acc_seg: 99.4130, aux.loss_ce: 0.0061, aux.acc_seg: 99.3664, loss: 0.0189\n","2023-01-05 12:39:44,134 - mmseg - INFO - Iter [79500/80000]\tlr: 2.030e-04, eta: 0:21:26, time: 2.374, data_time: 0.005, memory: 9169, decode.loss_ce: 0.0132, decode.acc_seg: 99.4272, aux.loss_ce: 0.0064, aux.acc_seg: 99.3775, loss: 0.0196\n","2023-01-05 12:41:45,515 - mmseg - INFO - Iter [79550/80000]\tlr: 1.937e-04, eta: 0:19:17, time: 2.428, data_time: 0.057, memory: 9169, decode.loss_ce: 0.0134, decode.acc_seg: 99.4241, aux.loss_ce: 0.0065, aux.acc_seg: 99.3735, loss: 0.0198\n","2023-01-05 12:43:46,964 - mmseg - INFO - Iter [79600/80000]\tlr: 1.843e-04, eta: 0:17:09, time: 2.429, data_time: 0.055, memory: 9169, decode.loss_ce: 0.0134, decode.acc_seg: 99.4190, aux.loss_ce: 0.0065, aux.acc_seg: 99.3678, loss: 0.0199\n","2023-01-05 12:45:45,790 - mmseg - INFO - Iter [79650/80000]\tlr: 1.748e-04, eta: 0:15:00, time: 2.376, data_time: 0.006, memory: 9169, decode.loss_ce: 0.0131, decode.acc_seg: 99.4065, aux.loss_ce: 0.0063, aux.acc_seg: 99.3546, loss: 0.0194\n","2023-01-05 12:47:47,203 - mmseg - INFO - Iter [79700/80000]\tlr: 1.651e-04, eta: 0:12:51, time: 2.428, data_time: 0.055, memory: 9169, decode.loss_ce: 0.0126, decode.acc_seg: 99.4182, aux.loss_ce: 0.0060, aux.acc_seg: 99.3623, loss: 0.0186\n","2023-01-05 12:49:48,784 - mmseg - INFO - Iter [79750/80000]\tlr: 1.553e-04, eta: 0:10:42, time: 2.432, data_time: 0.061, memory: 9169, decode.loss_ce: 0.0132, decode.acc_seg: 99.4056, aux.loss_ce: 0.0063, aux.acc_seg: 99.3566, loss: 0.0194\n","2023-01-05 12:51:47,551 - mmseg - INFO - Iter [79800/80000]\tlr: 1.453e-04, eta: 0:08:33, time: 2.375, data_time: 0.006, memory: 9169, decode.loss_ce: 0.0135, decode.acc_seg: 99.4003, aux.loss_ce: 0.0064, aux.acc_seg: 99.3478, loss: 0.0200\n","2023-01-05 12:53:48,956 - mmseg - INFO - Iter [79850/80000]\tlr: 1.350e-04, eta: 0:06:25, time: 2.428, data_time: 0.056, memory: 9169, decode.loss_ce: 0.0130, decode.acc_seg: 99.4314, aux.loss_ce: 0.0062, aux.acc_seg: 99.3836, loss: 0.0192\n","2023-01-05 12:55:50,330 - mmseg - INFO - Iter [79900/80000]\tlr: 1.244e-04, eta: 0:04:16, time: 2.427, data_time: 0.055, memory: 9169, decode.loss_ce: 0.0129, decode.acc_seg: 99.4275, aux.loss_ce: 0.0062, aux.acc_seg: 99.3739, loss: 0.0192\n","2023-01-05 12:57:49,058 - mmseg - INFO - Iter [79950/80000]\tlr: 1.132e-04, eta: 0:02:08, time: 2.375, data_time: 0.006, memory: 9169, decode.loss_ce: 0.0130, decode.acc_seg: 99.4376, aux.loss_ce: 0.0063, aux.acc_seg: 99.3874, loss: 0.0194\n","2023-01-05 12:59:50,477 - mmseg - INFO - Saving checkpoint at 80000 iterations\n","2023-01-05 12:59:53,680 - mmseg - INFO - Exp name: my_pspnet_r101-d8_512x512_80k_ade20k.py\n","2023-01-05 12:59:53,681 - mmseg - INFO - Iter [80000/80000]\tlr: 1.004e-04, eta: 0:00:00, time: 2.493, data_time: 0.057, memory: 9169, decode.loss_ce: 0.0129, decode.acc_seg: 99.4340, aux.loss_ce: 0.0062, aux.acc_seg: 99.3838, loss: 0.0190\n","[>>] 36/36, 3.9 task/s, elapsed: 9s, ETA:     0s\n","\n","2023-01-05 13:00:03,018 - mmseg - INFO - per class results:\n","2023-01-05 13:00:03,019 - mmseg - INFO - \n","+------------+-------+-------+-------+--------+-----------+--------+\n","|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |\n","+------------+-------+-------+-------+--------+-----------+--------+\n","| Background | 99.29 | 99.72 | 99.65 | 99.65  |   99.57   | 99.72  |\n","|    Head    |  91.9 | 96.24 | 95.78 | 95.78  |   95.32   | 96.24  |\n","|    Body    | 94.45 |  96.7 | 97.15 | 97.15  |    97.6   |  96.7  |\n","|    Fins    | 79.89 | 87.89 | 88.82 | 88.82  |   89.77   | 87.89  |\n","|    Tail    | 83.37 | 90.18 | 90.93 | 90.93  |   91.69   | 90.18  |\n","+------------+-------+-------+-------+--------+-----------+--------+\n","2023-01-05 13:00:03,019 - mmseg - INFO - Summary:\n","2023-01-05 13:00:03,020 - mmseg - INFO - \n","+-------+-------+-------+-------+---------+------------+---------+\n","|  aAcc |  mIoU |  mAcc | mDice | mFscore | mPrecision | mRecall |\n","+-------+-------+-------+-------+---------+------------+---------+\n","| 98.99 | 89.78 | 94.15 | 94.46 |  94.46  |   94.79    |  94.15  |\n","+-------+-------+-------+-------+---------+------------+---------+\n","2023-01-05 13:00:03,020 - mmseg - INFO - Exp name: my_pspnet_r101-d8_512x512_80k_ade20k.py\n","2023-01-05 13:00:03,020 - mmseg - INFO - Iter(val) [36]\taAcc: 0.9899, mIoU: 0.8978, mAcc: 0.9415, mDice: 0.9446, mFscore: 0.9446, mPrecision: 0.9479, mRecall: 0.9415, IoU.Background: 0.9929, IoU.Head: 0.9190, IoU.Body: 0.9445, IoU.Fins: 0.7989, IoU.Tail: 0.8337, Acc.Background: 0.9972, Acc.Head: 0.9624, Acc.Body: 0.9670, Acc.Fins: 0.8789, Acc.Tail: 0.9018, Dice.Background: 0.9965, Dice.Head: 0.9578, Dice.Body: 0.9715, Dice.Fins: 0.8882, Dice.Tail: 0.9093, Fscore.Background: 0.9965, Fscore.Head: 0.9578, Fscore.Body: 0.9715, Fscore.Fins: 0.8882, Fscore.Tail: 0.9093, Precision.Background: 0.9957, Precision.Head: 0.9532, Precision.Body: 0.9760, Precision.Fins: 0.8977, Precision.Tail: 0.9169, Recall.Background: 0.9972, Recall.Head: 0.9624, Recall.Body: 0.9670, Recall.Fins: 0.8789, Recall.Tail: 0.9018\n"]}],"source":["\n","!bash /content/drive/MyDrive/catfish/tianqi/code/mmsegmentation/tools/dist_train.sh \\\n","    /content/drive/MyDrive/catfish/tianqi/code/mmsegmentation/configs/pspnet/my_pspnet_r101-d8_512x512_80k_ade20k.py 1 \\\n","    --resume-from /content/drive/MyDrive/catfish/tianqi/code/mmsegmentation/checkpoints_pspnet/iter_68000.pth \\\n","    --deterministic \n"]},{"cell_type":"markdown","metadata":{"id":"O8M_yTMg30zp"},"source":["# test\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C-7W2gAj30IE"},"outputs":[],"source":["!python \\\n","    /content/drive/MyDrive/catfish/tianqi/code/mmsegmentation/demo/image_demo.py \\\n","    /content/drive/MyDrive/catfish/tianqi/code/mmsegmentation/data/ade/ADEChallengeData2016/test/cl8i0klwwdbme08140gykc8xp_3.jpg \\\n","    /content/drive/MyDrive/catfish/tianqi/code/mmsegmentation/save01/upernet_beit-base_640x640_160k_ade20k_ms.py \\\n","    /content/drive/MyDrive/catfish/tianqi/code/mmsegmentation/save01/iter_20000.pth --device cuda --out-file /content/drive/MyDrive/catfish/tianqi/code/mmsegmentation/result/result.jpg"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"APMI2CKmySp8"},"outputs":[],"source":["CONFIG_FILE=\"/content/drive/MyDrive/catfish/tianqi/code/mmsegmentation/save/upernet_beit-base_640x640_160k_ade20k_ms.py\"\n","MODEL_FILE=\"/content/drive/MyDrive/catfish/tianqi/code/mmsegmentation/save/iter_3000.pth\"\n","OUTPUT_FILE=\"/content/drive/MyDrive/catfish/tianqi/code/mmsegmentation/result\"\n","!python /home/masters/twitterDir/demo/mmsegmentation/tools/test.py \\\n","    ${CONFIG_FILE} \\\n","    ${MODEL_FILE}  \\\n","    --out ${OUTPUT_FILE}/results.pkl \\\n","    --eval mIoU cityscapes \\"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ff4k5tqjyX_c"},"outputs":[],"source":["# mIoU, mAcc, aAcc \n","\n","logPath = \"save-del/20221209_005605.log.json\"\n","\n","!python /content/drive/MyDrive/catfish/tianqi/code/mmsegmentation/tools/analyze_logs.py /content/drive/MyDrive/catfish/tianqi/code/mmsegmentation/${logPath} --keys mIoU mAcc aAcc --legend mIoU mAcc aAcc --out /content/drive/MyDrive/catfish/tianqi/code/mmsegmentation/result/chart.jpg\n","\n","\n","# loss \n","!python /content/drive/MyDrive/catfish/tianqi/code/mmsegmentation/tools/analyze_logs.py /content/drive/MyDrive/catfish/tianqi/code/mmsegmentation/${logPath} --keys loss --legend loss --out /content/drive/MyDrive/catfish/tianqi/code/mmsegmentation/result/chart_loss.jpg"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"mount_file_id":"1iAPtdoJ--8fPn1_5aClD05RgrN0qvq8Q","authorship_tag":"ABX9TyMWCqj3cgkmmxtTfvh1qD20"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}